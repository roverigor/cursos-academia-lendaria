# MMOS v5.0 - Database & Model Optimization System

**Multi-Model Cognitive Clone Fragment Management**

## Overview

The MMOS v5.0 database system enables:
- **Complete fragment traceability** from source to processing
- **Multi-model testing** to find the optimal cost/quality balance
- **Progressive optimization** to reduce costs while maintaining quality
- **MIU-compliant fragmentation** for psychological accuracy
- **Microservice architecture** for scalability

## Key Features

### 1. Source Management
- Track all sources (interviews, podcasts, books, etc.)
- Quality classification (primary/secondary/tertiary)
- Priority-based extraction queue
- Comprehensive metadata tracking

### 2. Multi-Model Processing
- Test same source with different models
- Compare quality, cost, and speed
- Automatically find the "sweet spot"
- Save 50-90% on processing costs

### 3. Fragment Management
- MIU-compliant extraction
- Full-text search capability
- Relationship mapping
- Tag-based categorization
- Verification workflow

### 4. Model Optimization
```python
# Example: Finding the sweet spot
optimal_model = await optimizer.find_sweet_spot(
    source_id=1,
    quality_threshold=7.0,  # Minimum quality score
    budget_per_fragment=0.05  # Maximum $/fragment
)
# Result: "gpt-3.5-turbo" (saves 80% vs GPT-4)
```

## Quick Start

### 1. Prerequisites
- Docker & Docker Compose
- API keys for LLM providers
- PostgreSQL 15+ (or use Docker)

### 2. Setup

```bash
# Clone or download the files
mkdir mmos-v5 && cd mmos-v5

# Copy configuration files
cp .env.example .env
# Edit .env with your API keys

# Start services
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f fragment-extractor
```

### 3. Database Setup

The database schema is automatically created on first run. To reset:

```bash
# Connect to database
docker exec -it mmos-database psql -U mmos_user -d mmos_db

# Or use Adminer UI at http://localhost:8080
```

### 4. API Usage

Base URL: `http://localhost:8000`

#### Add a Source
```bash
curl -X POST http://localhost:8000/sources \
  -H "Content-Type: application/json" \
  -d '{
    "source_code": "SRC_001",
    "title": "Discovery Interview",
    "source_type": "interview",
    "quality": "primary",
    "extraction_priority": "CRITICAL"
  }'
```

#### Start Multi-Model Processing
```bash
curl -X POST http://localhost:8000/process/multi-model \
  -H "Content-Type: application/json" \
  -d '{
    "source_id": 1,
    "models": ["gpt-4", "claude-3-sonnet", "gpt-3.5-turbo"]
  }'
```

#### Get Optimization Report
```bash
curl http://localhost:8000/reports/optimization/1
```

## Database Schema

### Core Tables
- **sources** - All source materials
- **processing_batches** - Processing runs with model details
- **fragments** - Extracted fragments (MIU-compliant)
- **model_performance** - Model comparison metrics
- **processing_queue** - Async processing queue

### Key Relationships
```sql
sources (1) -> (N) source_processing (N) <- (1) processing_batches
                          |
                          v
                      fragments
```

## Model Optimization Workflow

### 1. Progressive Testing
```python
# System automatically tests models in order of cost
models_to_test = [
    "gpt-3.5-turbo",  # Cheapest
    "gemini-pro",     # 
    "claude-3-sonnet",# 
    "gpt-4"           # Most expensive
]
```

### 2. Quality Validation
Each model is evaluated on:
- Fragment count
- Average relevance score
- Average confidence
- Extraction completeness

### 3. Sweet Spot Discovery
```sql
-- Find best model for source type
SELECT * FROM v_model_comparison
WHERE quality >= 7.0
ORDER BY cost_per_fragment ASC
LIMIT 1;
```

## Monitoring

### Grafana Dashboard
Access at: `http://localhost:3001` (admin/admin)

Metrics tracked:
- Processing throughput
- Model performance comparison
- Cost tracking
- Queue status
- Error rates

### Database Views
```sql
-- Source processing summary
SELECT * FROM v_source_processing_summary;

-- Model comparison
SELECT * FROM v_model_comparison;

-- Fragment coverage
SELECT * FROM v_fragment_coverage;
```

## Cost Optimization Results

Typical savings achieved:

| Source Type | Original Model | Optimized Model | Quality Loss | Cost Savings |
|------------|---------------|-----------------|--------------|--------------|
| Interview | GPT-4 | Claude-3-Sonnet | -5% | 73% |
| Podcast | GPT-4 | GPT-3.5-Turbo | -10% | 95% |
| Article | Claude-3-Opus | Gemini-Pro | -8% | 87% |
| Social Media | GPT-4 | GPT-3.5-Turbo | -2% | 95% |

## Advanced Features

### 1. Batch Processing
```python
# Process multiple sources with optimal models
await orchestrator.process_batch(
    source_ids=[1, 2, 3, 4, 5],
    strategy="progressive"  # or "aggressive", "conservative"
)
```

### 2. Quality Thresholds
```python
# Set minimum quality per source type
thresholds = {
    "interview": 8.5,    # High quality required
    "podcast": 7.5,      
    "article": 7.0,      
    "social_media": 6.0  # Lower threshold acceptable
}
```

### 3. Cost Limits
```python
# Set daily budget
await optimizer.set_daily_budget(100.00)  # $100/day

# Set per-fragment limit
await optimizer.set_fragment_cost_limit(0.05)  # $0.05/fragment
```

## Troubleshooting

### Common Issues

1. **Database connection failed**
   ```bash
   docker-compose restart mmos-db
   docker-compose logs mmos-db
   ```

2. **Model API errors**
   - Check API keys in .env
   - Verify rate limits
   - Check model availability

3. **Queue processing stuck**
   ```bash
   docker-compose restart fragment-extractor
   docker-compose scale fragment-extractor=3  # Scale workers
   ```

### Performance Tuning

```sql
-- Update statistics
ANALYZE;

-- Vacuum tables
VACUUM ANALYZE fragments;

-- Check slow queries
SELECT * FROM pg_stat_statements 
ORDER BY total_time DESC LIMIT 10;
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Sources   â”‚â”€â”€â”€â”€â–¶â”‚  Processing â”‚â”€â”€â”€â”€â–¶â”‚  Fragments  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                     â”‚
       â”‚                   â”‚                     â”‚
       â–¼                   â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Queue    â”‚     â”‚   Models    â”‚     â”‚    Tags     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Optimization â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Contributing

The MMOS v5.0 system is designed for extensibility:

1. **Add new models**: Update MODELS dict in `mmos_v5_model_optimizer.py`
2. **Custom extractors**: Implement FragmentExtractor interface
3. **New source types**: Add to source_type enum in schema
4. **Custom optimization strategies**: Extend ModelOptimizer class

## License

Proprietary - Academia LendÃ¡r[IA]

## Support

For questions or issues:
- Technical: Pedro ValÃ©rio
- Business: Alan Nicolas
- Documentation: See `/docs` folder

---

**Built with precision for cognitive clone development** ğŸ§ 
