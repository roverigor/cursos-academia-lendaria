# CreatorOS → InnerLens Integration Contract
# CreatorOS consulta fragmentos via RAG durante geração de conteúdo
# Version: 1.0.0
# Status: Stable
# Last Updated: 2025-10-27

metadata:
  contract_name: "creator-os-innerlens"
  version: "1.0.0"
  status: "stable"
  created_at: "2025-10-27"
  updated_at: "2025-10-27"

orchestrator:
  pack: "CreatorOS"
  version: "2.0.0"
  role: "Orquestrador do processo de criação de conteúdo"
  pipeline: "Educational Content Generation"

service:
  pack: "InnerLens"
  version: "1.1.0"
  role: "Serviço de consulta de fragmentos comportamentais"
  provides: "RAG query over MIU fragments for contextual enrichment"

---

# INTEGRATION OVERVIEW

purpose: |
  CreatorOS consulta InnerLens para obter fragmentos comportamentais relevantes
  durante geração de conteúdo educacional. Via RAG (Retrieval-Augmented Generation),
  CreatorOS busca MIU fragments que contextualizem lições com exemplos autênticos
  do instrutor, aumentando fidelidade de voz e relevância pedagógica.

orchestration_context: |
  Pipeline de Conteúdo CreatorOS:

  Phase 3: Lesson Generation (with RAG enrichment)
    → CreatorOS generating lesson on "Building Leverage"
    → CreatorOS queries: InnerLens.query_fragments(
        slug="naval_ravikant",
        query="building leverage specific knowledge",
        top_k=5
      )
    → InnerLens executes:
        1. Query fragments table (semantic/keyword search)
        2. Rank by relevance (similarity score)
        3. Return top K fragments with metadata
    → CreatorOS receives: 5 relevant fragments
    → CreatorOS injects fragments as examples in lesson
    → Result: Lesson with authentic instructor examples (98%+ fidelity)

integration_type: "rag-query-service"
call_direction: "CreatorOS queries InnerLens"
optional: true  # CreatorOS pode gerar sem RAG (90% fidelity vs 98% com RAG)

---

# INTERFACE SPECIFICATION

## How CreatorOS Queries InnerLens

### Method 1: Python API (Current)
```python
from creator_os.lib import LessonGenerator
from innerlens.lib import FragmentRetriever

generator = LessonGenerator()
retriever = FragmentRetriever()

# CreatorOS consulta durante geração de lição
fragments = generator.query_context(
    slug="naval_ravikant",
    query="building leverage specific knowledge",
    top_k=5,
    retriever=retriever
)

# Injeta fragmentos como exemplos
lesson_content = generator.generate_with_context(
    topic="Building Leverage",
    fragments=fragments
)
```

### Method 2: SQL Direct (Alternative)
```python
# CreatorOS query direto no banco
cursor.execute("""
    SELECT id, raw_excerpt, content
    FROM fragments
    WHERE mind_id = ? AND raw_excerpt LIKE ?
    ORDER BY created_at DESC
    LIMIT ?
""", (mind_id, f"%{query}%", top_k))

fragments = cursor.fetchall()
```

### Method 3: Future Vector RAG
```python
# Future: Embedding-based semantic search
fragments = retriever.semantic_search(
    mind_id=mind_id,
    query_embedding=embed(query),
    top_k=5,
    similarity_threshold=0.7
)
```

---

# REQUEST CONTRACT

## Input: CreatorOS → InnerLens

**CreatorOS provides:**
```yaml
request:
  slug: "naval_ravikant"  # Mind identifier

  query:
    text: "building leverage specific knowledge"
    query_type: "keyword | semantic"  # Search type

  filters:
    source_types: ["podcast", "article"]  # Optional: filter by source
    min_word_count: 10  # Minimum fragment size
    max_results: 5  # top_k

  ranking:
    strategy: "relevance | recency | diversity"
    boost_high_confidence: true  # Prioritize high-confidence fragments
```

---

# RESPONSE CONTRACT

## Output: InnerLens → CreatorOS

**InnerLens returns:**
```yaml
result:
  status: "completed | no_results | error"

  query_summary:
    query: "building leverage specific knowledge"
    mind_slug: "naval_ravikant"
    total_fragments_searched: 42
    results_returned: 5

  fragments:
    - fragment_id: "f_naval_012"
      verbatim: "Specific knowledge is knowledge you can't be trained for. If society can train you, it can train someone else, and replace you."
      word_count: 23
      source:
        type: "podcast"
        title: "Lex Fridman Podcast #123"
        timestamp: "[01:23:45]"
      relevance:
        score: 0.95
        reason: "Directly discusses leverage through specific knowledge"
      metadata:
        extraction_method: "llm_claude_sonnet_4"
        confidence: 1.0
        created_at: "2025-10-27T14:30:00Z"

    - fragment_id: "f_naval_027"
      verbatim: "The really smart thinkers are clear thinkers. They understand the basics at a very, very fundamental level."
      word_count: 19
      source:
        type: "article"
        title: "How to Get Rich"
      relevance:
        score: 0.82
        reason: "Related to knowledge depth and leverage"

    # ... (3 more fragments)

  usage_suggestions:
    - "Use fragments as direct quotes in lesson"
    - "Paraphrase fragments to illustrate concepts"
    - "Reference sources for additional context"
```

---

# FRAGMENT SCHEMA

## What InnerLens Returns

**Fragment structure:**
```json
{
  "fragment_id": "f_naval_012",
  "content": {
    "verbatim": "Exact quote from source...",
    "word_count": 23,
    "clause_count": 2,
    "structure": {
      "pronouns": ["you"],
      "verbs": ["train", "replace"],
      "tenses": ["present"]
    }
  },
  "source": {
    "type": "podcast_transcript",
    "title": "Lex Fridman Podcast #123",
    "file_path": "outputs/minds/naval_ravikant/sources/downloads/podcasts/...",
    "timestamp": "[01:23:45]",
    "char_position": [12500, 12700]
  },
  "extraction": {
    "method": "llm_claude_sonnet_4",
    "version": "1.0.0",
    "pipeline": "innerlens_v1.1",
    "timestamp": "2025-10-27T14:30:00Z"
  },
  "relevance": {
    "score": 0.95,  # 0.0-1.0
    "reason": "Semantic match with query"
  },
  "metadata": {
    "confidence": 1.0,
    "evidence_type": "explicit_statement"
  }
}
```

---

# SEARCH STRATEGIES

## 1. Keyword Search (Current)

**SQL-based:**
```sql
SELECT id, raw_excerpt as verbatim, content
FROM fragments
WHERE mind_id = ?
  AND (
    raw_excerpt LIKE ?
    OR content LIKE ?
  )
ORDER BY created_at DESC
LIMIT ?
```

**Pros:** Fast, simple, exact matches
**Cons:** Misses semantic similarity

---

## 2. Semantic Search (Future v1.1+)

**Vector embedding-based:**
```python
# 1. Embed query
query_embedding = embed("building leverage specific knowledge")

# 2. Search vector DB
results = vector_db.search(
    collection="fragments",
    query_vector=query_embedding,
    filter={"mind_id": 1},
    top_k=5,
    similarity_threshold=0.7
)

# 3. Return fragments with similarity scores
```

**Pros:** Semantic matching, finds related concepts
**Cons:** Requires embedding model, vector DB

---

## 3. Hybrid Search (Future v1.2+)

**Combines keyword + semantic:**
```python
# 1. Keyword search (fast, precise)
keyword_results = keyword_search(query, top_k=10)

# 2. Semantic search (broad, contextual)
semantic_results = semantic_search(query_embedding, top_k=10)

# 3. Merge and re-rank
final_results = rerank(
    candidates=keyword_results + semantic_results,
    strategy="reciprocal_rank_fusion",
    top_k=5
)
```

**Pros:** Best of both worlds
**Cons:** More complex, slower

---

# VALIDATION

## InnerLens Responsibilities (Service Provider)

**MUST guarantee:**
1. All returned fragments exist in database
2. Fragment IDs are valid
3. Relevance scores in 0.0-1.0 range
4. No duplicate fragments
5. Results sorted by relevance

**MUST handle:**
1. Empty query (return error)
2. No matching fragments (return no_results)
3. Mind has no fragments (return no_results)
4. Invalid mind_id (return error)

**Quality Standards:**
```yaml
rag_query_quality:
  min_relevance_score: 0.5
  max_results: 20
  response_time_target: <500ms
  accuracy_target: 90%  # Relevant results
```

## CreatorOS Responsibilities (Orchestrator)

**MUST handle:**
1. InnerLens returning "no_results" (proceed without fragments)
2. Low relevance scores (< 0.5) - filter out
3. Empty response (generate lesson without RAG context)
4. Query errors (log, proceed without RAG)

**MUST verify:**
1. Fragments are relevant to lesson topic
2. Verbatim text is not empty
3. Sources are properly attributed
4. Relevance scores reasonable

**SHOULD do:**
1. Log RAG queries (query, results count, average relevance)
2. Cache frequent queries
3. Validate fragment quality before injection
4. Track fidelity improvement from RAG usage

---

# USAGE PATTERNS

## Pattern 1: Direct Quotes

**CreatorOS uses fragments as quotes:**
```markdown
# Lesson: Building Leverage

## What is Specific Knowledge?

As Naval Ravikant explains:

> "Specific knowledge is knowledge you can't be trained for. If society
> can train you, it can train someone else, and replace you."
>
> — Naval Ravikant, Lex Fridman Podcast #123

This concept is fundamental to building leverage...
```

**Fidelity:** 98%+ (direct instructor voice)

---

## Pattern 2: Paraphrased Examples

**CreatorOS paraphrases fragments:**
```markdown
# Lesson: Building Leverage

## Finding Your Unique Edge

Naval emphasizes that true leverage comes from knowledge that can't be
easily replicated. He uses the metaphor that if something can be taught
in a classroom, it becomes commoditized. The real value lies in unique
insights that come from your specific combination of experiences and interests.
```

**Fidelity:** 95% (paraphrased but contextually accurate)

---

## Pattern 3: Concept Illustration

**CreatorOS uses fragments to illustrate concepts:**
```markdown
# Lesson: Building Leverage

## Exercise: Identify Your Specific Knowledge

Think about Naval's approach to knowledge:
- "The really smart thinkers are clear thinkers."
- They understand basics at a fundamental level.

Your task: What basic concepts in your field do you understand deeply?
```

**Fidelity:** 92% (concept-level, not direct voice)

---

# ERROR SCENARIOS

## Scenario 1: No Fragments Available

**CreatorOS query:**
```python
fragments = query_fragments("new_mind", "building leverage", top_k=5)
```

**InnerLens response:**
```yaml
status: "no_results"
reason: "Mind 'new_mind' has no fragments (InnerLens not run)"
suggestion: "Run InnerLens analysis first"
```

**CreatorOS decision:**
```python
warn_user("No fragments available, generating without RAG context")
proceed_without_rag()
fidelity_expected: 90%  # vs 98% with RAG
```

---

## Scenario 2: Low Relevance Results

**CreatorOS query:**
```python
fragments = query_fragments("naval", "quantum physics", top_k=5)
```

**InnerLens response:**
```yaml
status: "completed"
results_returned: 2  # Only 2 found
average_relevance: 0.35  # Low relevance
```

**CreatorOS decision:**
```python
if average_relevance < 0.5:
    info("Low relevance fragments, skipping RAG")
    proceed_without_rag()
```

---

## Scenario 3: Query Performance

**CreatorOS query:**
```python
# Heavy query during lesson generation
for topic in lesson_topics:
    fragments = query_fragments(slug, topic, top_k=3)
    # 10 topics = 10 queries
```

**Optimization:**
```python
# Batch query
all_topics = " ".join(lesson_topics)
fragments = query_fragments(slug, all_topics, top_k=20)

# Distribute fragments across topics
distribute_fragments_by_relevance(fragments, lesson_topics)
```

---

# VERSIONING

## Semantic Versioning

**Current version:** 1.0.0

**MAJOR (breaking):**
- Change fragment schema
- Remove keyword search
- Change relevance scoring

**MINOR (compatible):**
- Add semantic search (embedding-based)
- Add filters (source_type, date_range)
- Add ranking strategies

**PATCH (fixes):**
- Improve relevance scoring
- Performance optimization
- Bug fixes

---

# TESTING

## Integration Test

```bash
# 1. Garantir fragments no Supabase
psql "$SUPABASE_DB_URL" <<'SQL'
SELECT COUNT(*)
FROM fragments
WHERE mind_id = (SELECT id FROM minds WHERE slug = 'naval_ravikant');
SQL

# 2. Gerar lições com RAG habilitado
@course-architect
*generate-lessons startup-fundamentals --use-rag

# 3. Validar conteúdo recuperado
# Conferir citações / exemplos no output final

# 4. Verificar fidelidade
# Revisão manual: lições devem manter voz do mind (≥98%)
```

---

# EXAMPLES

## Example 1: Successful RAG Query

```yaml
# CreatorOS query
fragments = query_fragments(
    slug="naval_ravikant",
    query="building leverage specific knowledge",
    top_k=5
)

# InnerLens returns:
status: "completed"
results: 5
average_relevance: 0.87

fragments[0]:
  verbatim: "Specific knowledge is knowledge you can't be trained for..."
  relevance: 0.95
  source: "Lex Fridman Podcast #123"

# CreatorOS injects as quote in lesson
# Fidelity: 98%
```

## Example 2: No Results

```yaml
# CreatorOS query obscure topic
fragments = query_fragments("naval", "Byzantine architecture", top_k=5)

# InnerLens returns:
status: "no_results"
reason: "No fragments matching query"

# CreatorOS proceeds without RAG
# Fidelity: 90%
```

---

# RELATED CONTRACTS

- `mmos-innerlens-v1.0.0.yaml` - MMOS orquestra InnerLens (creates fragments)
- `creator-os-mmos-v1.0.0.yaml` - CreatorOS solicita professor prompt

---

# CONTACTS

**Contract Maintainer:** Alan Nicolas (alan@academialendaria.ai)
**CreatorOS Orchestrator Owner:** CreatorOS Team
**InnerLens Service Owner:** InnerLens Team
**Database Owner:** DB Sage (SuperAgentes)

---

# CHANGELOG

## v1.0.0 (2025-10-27)
- Initial contract - CreatorOS consulta InnerLens (RAG)
- Keyword search specification
- Fragment schema defined
- Request/response contracts
- Usage patterns documented
- Future: semantic search planned
