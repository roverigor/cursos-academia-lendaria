# ğŸ”„ InnerLens â†’ Supabase: Fluxo de Dados Completo

**Pergunta:** "Onde o InnerLens vai processar os dados e gerar fragmentos?"

---

## ğŸ“ Mapeamento de Dados: De Onde Vem, Para Onde Vai

### ğŸ—‚ï¸ Estrutura Atual

```
outputs/minds/
â”œâ”€â”€ alan_nicolas/
â”‚   â”œâ”€â”€ sources/              â† ğŸ“¥ INPUT: Aqui estÃ£o os textos
â”‚   â”‚   â”œâ”€â”€ modelo-do-eu.md
â”‚   â”‚   â”œâ”€â”€ Q&A.md
â”‚   â”‚   â”œâ”€â”€ profile.json
â”‚   â”‚   â””â”€â”€ ... (outros arquivos .txt, .md)
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/             â† (nÃ£o usado pelo InnerLens)
â”‚   â”œâ”€â”€ synthesis/            â† (nÃ£o usado pelo InnerLens)
â”‚   â””â”€â”€ kb/                   â† (KB manual - vamos SUBSTITUIR)
â”‚
â”œâ”€â”€ adriano_de_marqui/
â”‚   â””â”€â”€ sources/              â† ğŸ“¥ INPUT
â”‚
â””â”€â”€ ... (37 minds no total)
```

---

## ğŸ”„ Fluxo Completo de Dados

### Etapa por Etapa

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1ï¸âƒ£ ENTRADA: Sources (Filesystem)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   ğŸ“ outputs/minds/{mind}/sources/*.txt
   ğŸ“ outputs/minds/{mind}/sources/*.md
   ğŸ“ outputs/minds/{mind}/sources/*.json

          â†“ [Script lÃª e concatena]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2ï¸âƒ£ TEMP: Source Text Unificado                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   ğŸ“„ temp/{mind}_source.txt (arquivo temporÃ¡rio)
   Exemplo: "Eu valorizo clareza acima de tudo. Sempre busco..."
   Tamanho: 1000-20000 palavras

          â†“ [InnerLens extrai via LLM]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3ï¸âƒ£ PROCESSAMENTO: InnerLens Extraction (Claude Sonnet 4)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   ğŸ¤– Claude Sonnet 4 API
   ğŸ“ Roda em: Anthropic Cloud (via API)

   Prompt para Claude:
   "Extract MIUs from this text following 6 fragmentation rules..."

   Input: temp/{mind}_source.txt
   Output: temp/{mind}_fragments.json

          â†“ [MIUs extraÃ­dos]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4ï¸âƒ£ TEMP: Fragments JSON                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   ğŸ“„ temp/{mind}_fragments.json

   Estrutura:
   {
     "metadata": {
       "subject_id": "alan_nicolas",
       "mius_extracted": 187,
       "source_word_count": 15420
     },
     "fragments": [
       {
         "fragment_id": "f_alan_001",
         "content": {
           "verbatim": "Eu valorizo clareza acima de tudo."
         },
         "structure": { "pronouns": ["eu"], ... }
       },
       ...
     ]
   }

          â†“ [Script Python salva]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5ï¸âƒ£ DATABASE: Supabase PostgreSQL                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â˜ï¸ Supabase Cloud Database
   ğŸ“ URL: uvoikabnkjfvcccjeypi.supabase.co

   Tables:
   - minds (UUID, slug, display_name)
   - sources (UUID, mind_id, title, url, type)
   - fragments (UUID, mind_id, source_id, content, metadata)

          â†“ [OpenAI gera embeddings]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6ï¸âƒ£ EMBEDDINGS: OpenAI API                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   ğŸ¤– OpenAI text-embedding-3-small
   ğŸ“ Roda em: OpenAI Cloud (via API)

   Input: fragment.content (texto)
   Output: vector(1536) [0.123, 0.456, ...]

   Atualiza: fragments.embedding

          â†“ [RAG ready!]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7ï¸âƒ£ FINAL: Fragments RAG-Ready                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   âœ… Supabase: fragments table
   âœ… Content: texto verbatim
   âœ… Embedding: vector 1536d
   âœ… Metadata: InnerLens structure em JSONB

   Pronto para RAG search!
```

---

## ğŸ“ Onde Cada Componente Roda

| Componente | Onde Roda | O Que Precisa |
|------------|-----------|---------------|
| **1. Source Collection** | ğŸ–¥ï¸ Local (script bash) | Filesystem access |
| **2. InnerLens Extraction** | â˜ï¸ Anthropic Cloud | `ANTHROPIC_API_KEY` |
| **3. Fragment Saving** | â˜ï¸ Supabase Cloud | `SUPABASE_DB_URL` |
| **4. Embedding Generation** | â˜ï¸ OpenAI Cloud | `OPENAI_API_KEY` |
| **5. RAG Search** | â˜ï¸ Supabase Cloud | Query com embeddings |

---

## ğŸ” Detalhamento: Onde InnerLens Processa

### InnerLens NÃƒO roda localmente (processamento pesado)

**O que acontece:**
1. **Script local** lÃª arquivos de `outputs/minds/{mind}/sources/`
2. **Envia texto** para Claude Sonnet 4 API (Anthropic Cloud)
3. **Claude processa** (extraÃ§Ã£o de MIUs via LLM)
4. **Retorna JSON** com fragments
5. **Script salva** no Supabase

**Analogia:**
```
Local Machine          Anthropic Cloud        Supabase Cloud
     |                       |                      |
     |--- Envia texto ------>|                      |
     |                       |                      |
     |                [Claude processa]             |
     |                       |                      |
     |<-- Retorna MIUs ------|                      |
     |                       |                      |
     |----------- Salva fragments ---------------->|
     |                       |                      |
```

---

## ğŸ“¦ O Que Precisa Estar Configurado

### 1. VariÃ¡veis de Ambiente (.env)

```bash
# Supabase (PostgreSQL)
SUPABASE_DB_URL=postgresql://postgres.xxx:password@aws-1-us-east-2.pooler.supabase.com:5432/postgres?sslmode=require

# Anthropic (Claude para extraÃ§Ã£o de MIUs)
ANTHROPIC_API_KEY=sk-ant-api03-xxx

# OpenAI (Embeddings)
OPENAI_API_KEY=sk-xxx
```

### 2. Estrutura de Dados de Entrada

```
outputs/minds/{mind_slug}/sources/
â”œâ”€â”€ *.txt   â† Textos em portuguÃªs
â”œâ”€â”€ *.md    â† Markdown files
â””â”€â”€ *.json  â† JSON profiles (opcional)
```

**Requisitos:**
- âœ… Pelo menos 1 arquivo com texto
- âœ… MÃ­nimo 500 palavras (idealmente 1000-2000)
- âœ… PortuguÃªs ou inglÃªs
- âœ… Primeira pessoa ("eu", "I")

### 3. DependÃªncias Python

```bash
# InnerLens dependencies
pip install anthropic psycopg2-binary python-dotenv
```

### 4. DependÃªncias Node.js

```bash
# Para embeddings
npm install pg openai dotenv
```

---

## ğŸ¯ Exemplo PrÃ¡tico: Alan Nicolas

### INPUT (O que existe)

```
outputs/minds/alan_nicolas/sources/
â”œâ”€â”€ modelo-do-eu.md          (51KB, 389 linhas)
â”œâ”€â”€ Q&A.md                   (173KB, 4000+ linhas)
â”œâ”€â”€ alan-nicolas-profile.json (513 linhas)
â””â”€â”€ clones-ia.md             (71KB)

Total: ~300KB de texto (~50,000 palavras)
```

### PROCESSING (O que acontece)

```bash
# 1. Script concatena sources
cat outputs/minds/alan_nicolas/sources/*.txt *.md > temp/alan_source.txt

# 2. InnerLens envia para Claude
curl https://api.anthropic.com/v1/messages \
  -d '{
    "model": "claude-sonnet-4-20250514",
    "messages": [{
      "role": "user",
      "content": "Extract MIUs from this text: ..."
    }]
  }'

# 3. Claude retorna MIUs (JSON)
{
  "fragments": [
    { "fragment_id": "f_alan_001", ... },
    { "fragment_id": "f_alan_002", ... },
    ...
  ]
}

# 4. Script salva no Supabase
INSERT INTO fragments (mind_id, content, metadata, ...)
VALUES (...), (...), ...

# 5. OpenAI gera embeddings
curl https://api.openai.com/v1/embeddings \
  -d '{ "model": "text-embedding-3-small", "input": "..." }'

# 6. Atualiza fragments com embeddings
UPDATE fragments SET embedding = [...] WHERE id = ...
```

### OUTPUT (O que fica no Supabase)

```sql
-- Mind entry
INSERT INTO minds (slug, display_name)
VALUES ('alan_nicolas', 'Alan Nicolas');

-- Source entry
INSERT INTO sources (mind_id, title, type)
VALUES (
  uuid_alan,
  'InnerLens Extraction 2025-10-27',
  'self_analysis'
);

-- Fragments (exemplo: 187 fragments)
INSERT INTO fragments (mind_id, source_id, content, metadata, embedding)
VALUES
  (uuid_alan, uuid_source, 'Eu valorizo clareza...', {...}, [0.123, ...]),
  (uuid_alan, uuid_source, 'Sempre busco eficiÃªncia...', {...}, [0.456, ...]),
  ...
```

---

## ğŸ” SeguranÃ§a & Privacy

### Dados que Saem da MÃ¡quina Local

| O Que | Para Onde | Por QuÃª |
|-------|-----------|---------|
| **Texto source** | Anthropic Cloud | ExtraÃ§Ã£o de MIUs |
| **Fragments JSON** | Supabase Cloud | Storage |
| **Fragment text** | OpenAI Cloud | Embeddings |

### Dados que FICAM Locais

| O Que | Onde |
|-------|------|
| **Source files originais** | `outputs/minds/{mind}/sources/` |
| **Temp files** | `temp/` (deletados apÃ³s) |
| **.env secrets** | Local (nÃ£o commitado) |

### Compliance

- âœ… **GDPR:** Dados processados com consentimento
- âœ… **LGPD:** Storage em cloud compliance
- âœ… **Encryption:** TLS em trÃ¢nsito, AES at rest
- âœ… **Data retention:** ConfigurÃ¡vel (pode deletar)

---

## ğŸ“Š MÃ©tricas: Quanto Processa?

### Por Mind (mÃ©dia)

| MÃ©trica | Valor |
|---------|-------|
| **Source words** | 1,000-20,000 |
| **Processing time** | 30-120 segundos |
| **MIUs extracted** | 50-300 |
| **Fragments in DB** | 50-300 rows |
| **Storage used** | ~50KB per mind |
| **API calls** | 1 Claude + N OpenAI (N=fragments) |
| **Cost** | ~$0.15 per mind |

### Para Todas as 37 Minds

| MÃ©trica | Total |
|---------|-------|
| **Total fragments** | ~2,000-5,000 |
| **Storage** | ~2-5 MB |
| **Processing time** | ~1-2 horas (sequencial) |
| **Total cost** | ~$5.55 |

---

## ğŸš¨ O Que Pode Dar Errado

### 1. Sources Vazias

```
âŒ Error: No source text found
```

**Causa:** `outputs/minds/{mind}/sources/` vazio ou sem .txt/.md

**SoluÃ§Ã£o:** Adicionar arquivos de texto nessa pasta

### 2. API Keys InvÃ¡lidas

```
âŒ Error: Anthropic API error: invalid_api_key
```

**SoluÃ§Ã£o:**
```bash
# Verificar .env
cat .env | grep ANTHROPIC_API_KEY

# Testar key
curl https://api.anthropic.com/v1/messages \
  -H "x-api-key: $ANTHROPIC_API_KEY" \
  -H "anthropic-version: 2023-06-01" \
  -d '{"model": "claude-3-5-sonnet-20241022", "max_tokens": 10, "messages": [{"role": "user", "content": "Hi"}]}'
```

### 3. Supabase Connection Failed

```
âŒ Error: psycopg2.OperationalError: could not connect
```

**SoluÃ§Ã£o:**
```bash
# Testar conexÃ£o
psql "$SUPABASE_DB_URL" -c "SELECT 1;"

# Verificar formato
echo $SUPABASE_DB_URL
# Deve ser: postgresql://postgres.xxx:password@...
```

### 4. Rate Limits

```
âŒ Error: Rate limit exceeded (429)
```

**SoluÃ§Ã£o:** Script jÃ¡ tem delays, mas pode aumentar:
```python
# No script Python
import time
time.sleep(2)  # Delay entre requests
```

---

## ğŸ¯ Checklist: O Que InnerLens Precisa Saber

### âœ… PrÃ©-requisitos

- [ ] **Sources location:** `outputs/minds/{mind}/sources/`
- [ ] **Supabase URL:** `.env` â†’ `SUPABASE_DB_URL`
- [ ] **Anthropic key:** `.env` â†’ `ANTHROPIC_API_KEY`
- [ ] **OpenAI key:** `.env` â†’ `OPENAI_API_KEY`
- [ ] **Schema aplicado:** Migration v0.8.1
- [ ] **Python deps:** `anthropic`, `psycopg2`, `dotenv`
- [ ] **Node deps:** `pg`, `openai`, `dotenv`

### âœ… Durante Processamento

- [ ] **Read sources** de `outputs/minds/{mind}/sources/*.{txt,md}`
- [ ] **Concatenate** em temp file
- [ ] **Send to Claude** para extraÃ§Ã£o
- [ ] **Receive MIUs** em JSON
- [ ] **Save to Supabase** (minds, sources, fragments tables)
- [ ] **Generate embeddings** com OpenAI
- [ ] **Update fragments** com embeddings
- [ ] **Cleanup** temp files

### âœ… PÃ³s-processamento

- [ ] **Validate counts:** Fragments no Supabase = MIUs extraÃ­dos
- [ ] **Check embeddings:** Todos fragments tÃªm embedding
- [ ] **Test RAG:** Search funciona
- [ ] **Monitor costs:** API usage dentro do esperado

---

## ğŸ’¡ Resumo Visual

```
ğŸ“ FILESYSTEM (Local)          â˜ï¸ CLOUD SERVICES              ğŸ’¾ DATABASE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

outputs/minds/
â”œâ”€ alan/sources/
â”‚  â”œâ”€ text1.txt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”œâ”€ text2.md â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â””â”€ text3.txt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                          â†“
                    [Concatenate]
                          â†“
                    temp/alan_source.txt
                          â†“
                    [Send to API] â”€â”€â”€â”€â”€â”€â”€â”€â†’  Anthropic Claude
                                                    â†“
                                              [Extract MIUs]
                                                    â†“
                    temp/alan_fragments.json â†â”€â”€â”€â”€â”€â”€â”˜
                          â†“
                    [Parse & Save] â”€â”€â”€â”€â”€â”€â”€â”€â†’  Supabase
                                               â”œâ”€ minds
                                               â”œâ”€ sources
                                               â””â”€ fragments
                          â†“
                    [For each fragment]
                          â†“
                    [Generate embedding] â”€â”€â”€â†’  OpenAI
                                                    â†“
                                            [vector(1536)]
                                                    â†“
                    [Update fragments] â”€â”€â”€â”€â”€â†’  Supabase
                                               â””â”€ fragments.embedding

                                              âœ… RAG Ready!
```

---

## ğŸ—„ï¸ DB Sage Final Answer

**Pergunta:** "Onde vai processar os dados e gerar fragmentos?"

**Resposta:**
1. **Entrada:** `outputs/minds/{mind}/sources/` (local filesystem)
2. **Processamento:** Anthropic Cloud (Claude extrai MIUs via API)
3. **Storage:** Supabase Cloud (PostgreSQL)
4. **Embeddings:** OpenAI Cloud (via API)
5. **Output:** Supabase `fragments` table (RAG-ready)

**Tudo orquestrado por:** `process_mind_to_supabase.sh`

---

**ğŸ—„ï¸ DB Sage - "Data flows from filesystem â†’ Claude â†’ Supabase â†’ OpenAI â†’ RAG."**

**Ãšltima atualizaÃ§Ã£o:** 2025-10-27
