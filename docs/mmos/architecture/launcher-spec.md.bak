# AIOS Launcher MVP - Technical Specification

**Version:** 1.0
**Date:** 05 de Outubro de 2025
**Author:** Winston (Architect) + Alan Nicolas
**Status:** SPEC - Awaiting Approval

---

## ğŸ“‹ Executive Summary

**Purpose:** CLI tool que mapeia automaticamente prompts MMOS â†’ agentes AIOS, injeta contexto relevante e registra execuÃ§Ãµes com zero fricÃ§Ã£o manual.

**Success Criteria MVP:**
- âœ… Reduzir tempo de preparaÃ§Ã£o por prompt em â‰¥30% (baseline: ~5min manual)
- âœ… 100% rastreabilidade (timestamp, agente, prompt, output path)
- âœ… Zero alteraÃ§Ã£o na estrutura ACS V3.0 existente
- âœ… Funcionar em 1 comando para qualquer dos 47 prompts

**Scope MVP:**
- âœ… CLI Python simples (boring tech)
- âœ… File-based (YAML config + Markdown logs)
- âœ… Read-only sobre estrutura existente (nÃ£o modifica minds/)
- âŒ NÃƒO Ã© automation engine (permanece conversacional)
- âŒ NÃƒO executa prompts automaticamente (usuÃ¡rio ainda opera agentes AIOS)

---

## 1. Functional Requirements (MVP)

### FR1: Prompt â†’ Agent Mapping
- Dado `--prompt` ID, carregar definiÃ§Ã£o de `docs/mmos/prompts.yaml`
- Extrair `agent`, `title`, `outputs`, `depends_on`, `parallelizable`
- Exibir agente identificado (#analyst, #pm, #architect, #dev, #qa)

### FR2: Context Injection
- Carregar contexto relevante do mind:
  - `docs/PRD.md` (excerpt: objetivo + viabilidade)
  - `docs/MIND_BRIEF.md` (roadmap atual)
  - `sources/sources_master.yaml` (fontes disponÃ­veis)
- Exibir contexto resumido (max 500 caracteres)

### FR3: Output Path Suggestion
- Ler `outputs[0].path` do prompt (template com `{mind}`, `{timestamp}`)
- Substituir placeholders: `{mind}` â†’ mind name, `{timestamp}` â†’ YYYYMMDD-HHMM
- Validar que diretÃ³rio pai existe (criar se necessÃ¡rio)

### FR4: Execution Logging
- Registrar invocaÃ§Ã£o em `docs/mmos/logs/launcher-history.yaml`
- Campos: timestamp, mind, phase, prompt_id, prompt_title, agent, user, output_path, parallelizable
- Append-only (nunca sobrescreve)

### FR5: CLI Interface
```bash
aios-launcher \
  --mind MIND_NAME \
  --phase PHASE_NAME \
  --prompt PROMPT_ID \
  [--show-context]   # opcional: mostra contexto completo
  [--show-deps]      # opcional: mostra dependÃªncias do prompt
  [--dry-run]        # opcional: simula sem registrar log
```

---

## 2. Technical Architecture

### 2.1 Tech Stack

```yaml
language: Python 3.11+
cli_framework: Click (simple, popular, boring tech)
config_format: YAML
log_format: YAML + Markdown
dependencies:
  - click>=8.0
  - pyyaml>=6.0
  - python-dateutil>=2.8
packaging: Poetry or pip (definir depois)
```

### 2.2 Directory Structure

```
mmos/
â”œâ”€â”€ launcher/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py                    # Click CLI entrypoint
â”‚   â”œâ”€â”€ prompt_loader.py          # Load prompt from prompts.yaml
â”‚   â”œâ”€â”€ context_loader.py         # Load MIND_BRIEF, PRD, sources
â”‚   â”œâ”€â”€ path_resolver.py          # Resolve {mind}, {timestamp} templates
â”‚   â”œâ”€â”€ logger.py                 # Execution logging
â”‚   â””â”€â”€ deps_checker.py           # Check dependencies completion
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ universal/
â”‚       â””â”€â”€ aios-launcher.sh      # Bash wrapper (optional)
â”‚
â””â”€â”€ docs/
    â””â”€â”€ mmos/
        â”œâ”€â”€ prompts.yaml              # Source of truth (47 prompts)
        â””â”€â”€ logs/
            â””â”€â”€ launcher-history.yaml  # Execution log
```

### 2.3 Data Models

#### prompts.yaml (Source of Truth)

**Location:** `docs/mmos/prompts.yaml` (jÃ¡ existe)

**Structure:** Array de prompts com campos:
- `id`: Unique identifier (e.g., `analysis_mental_models`)
- `file`: Path to prompt markdown (e.g., `prompts/analysis_mental_models.md`)
- `phase`: Pipeline phase (viability, research, analysis, synthesis, implementation, testing)
- `title`: Human-readable title (e.g., "Mental Models")
- `order`: Sequencing within phase
- `agent`: AIOS agent (analyst, pm, architect, dev, qa)
- `parallelizable`: Can run in parallel with other prompts (true/false)
- `outputs`: Array of output definitions
  - `path`: Template path with `{mind}`, `{timestamp}`, `{version}`, `{topic}`, `{index}`, `{specialist}`
  - `description`: Human-readable description
- `depends_on`: Array of prompt IDs that must complete first

**Example:**
```yaml
- id: analysis_mental_models
  file: prompts/analysis_mental_models.md
  phase: analysis
  title: Mental Models
  order: 3
  agent: analyst
  parallelizable: true
  outputs:
    - path: minds/{mind}/artifacts/mental_models.md
      description: Modelo mental
  depends_on:
    - analysis_behavioral_patterns
    - analysis_recognition_patterns
    - analysis_linguistic_forensics
```

#### launcher-history.yaml

```yaml
# docs/mmos/logs/launcher-history.yaml
executions:
  - timestamp: "2025-10-05T15:30:45"
    mind: steve_jobs
    phase: analysis
    prompt_id: analysis_mental_models
    prompt_title: Mental Models
    agent: analyst
    user: alan
    output_path: "minds/steve_jobs/artifacts/mental_models.md"
    parallelizable: true
    context_shown: false
    dry_run: false
    duration_ms: 342

  - timestamp: "2025-10-05T16:15:22"
    mind: steve_jobs
    phase: synthesis
    prompt_id: synthesis_template_extractor
    prompt_title: Template Extractor
    agent: analyst
    user: alan
    output_path: "minds/steve_jobs/artifacts/communication_templates.md"
    parallelizable: true
    context_shown: true
    dry_run: false
    duration_ms: 287
```

---

## 3. CLI Interface Specification

### 3.1 Command Signature

```bash
aios-launcher --mind MIND_NAME --phase PHASE --prompt PROMPT_ID [OPTIONS]
```

### 3.2 Arguments

| Argument | Required | Type | Description | Example |
|----------|----------|------|-------------|---------|
| `--mind` | Yes | String | Mind name (must exist in `minds/`) | `steve_jobs` |
| `--phase` | Yes | Enum | Pipeline phase | `viability`, `research`, `analysis`, `synthesis`, `implementation`, `testing` |
| `--prompt` | Yes | String | Prompt ID from prompts.yaml | `analysis_mental_models` |

### 3.3 Options

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `--show-context` | Flag | False | Exibir contexto completo (nÃ£o apenas resumo) |
| `--dry-run` | Flag | False | Simular sem registrar log |
| `--verbose` | Flag | False | Modo verbose (debugging) |
| `--output-dir` | String | `docs/logs/` | DiretÃ³rio de output (override) |

### 3.4 Output Format (stdout)

```
ğŸ—ï¸ AIOS Launcher v1.0

Mind: steve_jobs
Phase: analysis
Prompt: analysis_mental_models
Title: Mental Models

âœ… Agent Identified: #analyst
âš¡ Parallelizable: Yes

ğŸ“‹ Context Summary:
---
PRD Objective: Create authentic cognitive clone of Steve Jobs
Viability: APEX 8.5, ICP 9.0 - APPROVED
Sources Available: 12 books, 23 interviews, 47 articles
Current Phase: Analysis (3/6 checkpoints completed)
---

ğŸ“‚ Suggested Output Path:
   minds/steve_jobs/artifacts/mental_models.md

ğŸ“ Dependencies (must complete first):
   âœ… analysis_behavioral_patterns (completed)
   âœ… analysis_recognition_patterns (completed)
   âœ… analysis_linguistic_forensics (completed)

âš¡ Next Steps:
1. Activate agent: Type '#analyst' in Claude Code
2. Execute prompt: prompts/analysis_mental_models.md
3. Save output to suggested path above
4. Update MIND_BRIEF.md roadmap checkbox

ğŸ“ Execution logged to: docs/mmos/logs/launcher-history.yaml
```

---

## 4. Execution Flow

### 4.1 Happy Path Flow

```
User runs CLI command
    â†“
1. Validate arguments (mind exists? phase valid? prompt ID exists?)
    â†“
2. Load docs/mmos/prompts.yaml
    â†“
3. Find prompt by ID in prompts array
    â†“
4. Extract: agent, title, outputs, depends_on, parallelizable
    â†“
5. Load context files (PRD, MIND_BRIEF, sources_master)
    â†“
6. Resolve output path template ({mind}, {timestamp}, etc.)
    â†“
7. Check dependencies (if --show-deps, display completion status)
    â†“
8. Display formatted output (agent, title, context, path, deps, next steps)
    â†“
9. Log execution to launcher-history.yaml
    â†“
10. Exit with code 0
```

### 4.2 Error Handling

| Error Condition | Behavior | Exit Code |
|-----------------|----------|-----------|
| Mind nÃ£o existe | Print error + list available minds in minds/ | 1 |
| Phase invÃ¡lido | Print error + list valid phases | 1 |
| Prompt ID nÃ£o existe | Print error + list available prompts for phase | 1 |
| docs/mmos/prompts.yaml missing | Print error + suggest fix | 2 |
| prompts.yaml malformed YAML | Print YAML parse error + line number | 2 |
| Context file missing (PRD, MIND_BRIEF) | Warn + continue (nÃ£o Ã© bloqueante) | 0 |
| Output directory nÃ£o existe | Create directory + warn | 0 |
| Unable to write log | Warn + continue (nÃ£o Ã© bloqueante) | 0 |
| Dependencies not completed (--strict mode) | Error + list incomplete deps | 1 |

---

## 5. Context Loading Logic

### 5.1 Files to Load

```python
# Ordem de prioridade (melhor esforÃ§o, nÃ£o bloqueante)
context_files = [
    "minds/{mind}/docs/MIND_BRIEF.md",     # Roadmap + viabilidade
    "minds/{mind}/docs/PRD.md",            # Objetivo + success criteria
    "minds/{mind}/sources/sources_master.yaml",  # Fontes disponÃ­veis
]
```

### 5.2 Context Extraction

**MIND_BRIEF.md:**
- Extract: SeÃ§Ã£o "2. Viabilidade (SCORECARD)" â†’ APEX + ICP scores
- Extract: SeÃ§Ã£o "7. Roadmap" â†’ checkpoints status (quantos completos)

**PRD.md:**
- Extract: Primeira linha after "## 1. Objetivo" â†’ primary use case

**sources_master.yaml:**
- Count: Total sources by type (books, interviews, articles, etc.)

### 5.3 Context Summarization

```
PRD Objective: {first_line_from_prd_objetivo}
Viability: APEX {score}, ICP {score} - {decision}
Sources Available: {count_books} books, {count_interviews} interviews, {count_articles} articles
Current Phase: {stage} ({completed}/{total} checkpoints completed)
```

**Max 500 characters** (truncate if needed)

---

## 6. Implementation Phases

### Phase 1: Core MVP (Days 1-2)

**Day 1 Morning:**
- [x] Setup project structure
- [x] Create prompts-mapping.yaml (47 prompts)
- [x] Implement CLI interface (Click)
- [x] Implement prompt â†’ agent mapping

**Day 1 Afternoon:**
- [x] Implement context loading (MIND_BRIEF, PRD, sources)
- [x] Implement context summarization
- [x] Implement output path generation

**Day 2 Morning:**
- [x] Implement execution logging (launcher-history.yaml)
- [x] Implement formatted output display
- [x] Add error handling

**Day 2 Afternoon:**
- [x] Test with 3 real prompts (different stages)
- [x] Fix bugs
- [x] Document usage in README

### Phase 2: Validation (Day 3)

**Testing:**
- [ ] Test all 6 stages (1 prompt each = 6 tests)
- [ ] Test error conditions (invalid mind, prompt, stage)
- [ ] Test with missing context files (graceful degradation)
- [ ] Measure time saved vs manual (baseline: 5min)

**Success Criteria:**
- âœ… 6/6 prompts executados com sucesso
- âœ… â‰¥30% reduÃ§Ã£o tempo (5min â†’ â‰¤3.5min)
- âœ… 100% logs registrados corretamente
- âœ… Zero modificaÃ§Ãµes em minds/ (read-only)

### Phase 3: Iteration (Days 4-5)

**If successful (â‰¥30% time saved):**
- [ ] Create formal spec for Board & Telemetry
- [ ] Expand launcher features (auto-suggest next prompts, etc.)
- [ ] Integrate with workflow board

**If unsuccessful (<30% time saved):**
- [ ] Investigate bottlenecks (context loading? display?)
- [ ] Pivot: simplify or focus on different pain point
- [ ] Re-evaluate Epic 1 priorities

---

## 7. Non-Functional Requirements (MVP)

### Performance
- Cold start: <1s (first run after boot)
- Warm start: <200ms (subsequent runs)
- Context loading: <500ms (even for large MIND_BRIEF)

### Reliability
- 100% success rate for valid inputs
- Graceful degradation for missing context files
- Never corrupt launcher-history.yaml (atomic writes)

### Usability
- Single command (no multi-step wizard)
- Clear error messages with suggested fixes
- Self-documenting (--help shows examples)

### Maintainability
- <500 LOC total (excluding config YAML)
- 100% type hints (Python typing)
- Unit tests for core logic (mapper, context_loader, logger)

---

## 8. Out of Scope (MVP)

âŒ **NOT Included in MVP:**

1. **Workflow Board Integration** - Story 1.2 (separate implementation)
2. **Parallel Execution Manager** - Fase 2 feature
3. **Auto-execution of prompts** - AIOS permanece conversacional
4. **Context auto-fill no Claude Code** - Requer plugin/extensÃ£o
5. **Brownfield detection** - Story 1.3 (separate implementation)
6. **Notes handoff** - Story 1.4 (separate implementation)
7. **Web UI** - CLI only for MVP
8. **API REST** - File-based only
9. **Database persistence** - YAML files only
10. **Multi-user concurrency** - Single user assumed

---

## 9. Testing Strategy

### 9.1 Unit Tests

```python
# tests/test_prompt_loader.py
def test_load_prompt_by_id():
    prompt = prompt_loader.load("analysis_mental_models")
    assert prompt["agent"] == "analyst"
    assert prompt["title"] == "Mental Models"
    assert prompt["parallelizable"] == True

# tests/test_context_loader.py
def test_load_mind_brief():
    brief = context_loader.load_mind_brief("steve_jobs")
    assert "viability" in brief
    assert "roadmap" in brief

# tests/test_path_resolver.py
def test_resolve_template_path():
    path = path_resolver.resolve(
        "minds/{mind}/artifacts/mental_models.md",
        mind="steve_jobs",
        timestamp="20251005-1530"
    )
    assert path == "minds/steve_jobs/artifacts/mental_models.md"

# tests/test_deps_checker.py
def test_check_dependencies():
    deps = deps_checker.check("analysis_mental_models", "steve_jobs")
    assert "analysis_behavioral_patterns" in deps
    assert deps["analysis_behavioral_patterns"]["completed"] == True

# tests/test_logger.py
def test_log_execution():
    logger.log_execution(mind="test", phase="analysis", ...)
    assert os.path.exists("docs/mmos/logs/launcher-history.yaml")
```

### 9.2 Integration Tests

```bash
# Test 1: Happy path
aios-launcher --mind steve_jobs --phase analysis --prompt analysis_mental_models
# Expected: Success, agent=#analyst, log registered

# Test 2: Invalid mind
aios-launcher --mind invalid_mind --phase analysis --prompt analysis_mental_models
# Expected: Error + list available minds

# Test 3: Invalid prompt ID
aios-launcher --mind steve_jobs --phase analysis --prompt invalid_prompt
# Expected: Error + list prompts for analysis phase

# Test 4: Dry run
aios-launcher --mind steve_jobs --phase analysis --prompt analysis_mental_models --dry-run
# Expected: Success, log NOT registered

# Test 5: Show context
aios-launcher --mind steve_jobs --phase analysis --prompt analysis_mental_models --show-context
# Expected: Full context displayed (not just summary)

# Test 6: Show dependencies
aios-launcher --mind steve_jobs --phase analysis --prompt analysis_mental_models --show-deps
# Expected: Dependencies listed with completion status
```

### 9.3 User Acceptance Test

**Scenario:** Operator precisa executar prompt `03_mental_models` para Steve Jobs

**Manual Process (Baseline):**
1. Consultar documentaÃ§Ã£o ou experiÃªncia para lembrar ID do prompt
2. Abrir `docs/mmos/prompts.yaml` para confirmar agente
3. Abrir `minds/steve_jobs/docs/MIND_BRIEF.md` para contexto
4. Abrir `minds/steve_jobs/docs/PRD.md` para objetivo
5. Verificar manualmente se dependÃªncias foram completadas
6. Ativar agente #analyst manualmente
7. Copiar contexto relevante
8. Executar prompt
9. **Total: ~5 minutos**

**With Launcher:**
1. Run: `aios-launcher --mind steve_jobs --phase analysis --prompt analysis_mental_models`
2. Ler output (agente, contexto, path, dependencies)
3. Ativar agente #analyst
4. Executar prompt
5. **Total: ~3 minutos** (40% reduÃ§Ã£o)

**Success Criteria:**
- âœ… Tempo â‰¤3.5 minutos (â‰¥30% reduÃ§Ã£o)
- âœ… Operador nÃ£o precisa abrir nenhum arquivo manualmente
- âœ… Dependencies automaticamente verificadas
- âœ… Zero erros durante execuÃ§Ã£o

---

## 10. Success Metrics

### Quantitative Metrics (Day 3 Validation)

| Metric | Baseline (Manual) | Target (Launcher) | Measured |
|--------|-------------------|-------------------|----------|
| Tempo mÃ©dio por prompt | 5 min | â‰¤3.5 min (30% reduÃ§Ã£o) | TBD |
| Erros de agente errado | ~10% | 0% | TBD |
| Logs perdidos | ~20% | 0% | TBD |
| Contexto consultado | 50% | 100% | TBD |

### Qualitative Metrics (User Feedback)

- [ ] "Launcher economizou tempo?" (Yes/No)
- [ ] "Contexto exibido foi Ãºtil?" (Yes/No/Partial)
- [ ] "Encontrou alguma fricÃ§Ã£o?" (descritivo)
- [ ] "Usaria launcher para todos os 47 prompts?" (Yes/No)

---

## 11. Risks & Mitigations

### R-LAUNCHER-1: prompts.yaml desatualizado (MÃ‰DIO)
- **Problema:** docs/mmos/prompts.yaml fica desatualizado quando pipeline muda
- **MitigaÃ§Ã£o:**
  - Source of truth jÃ¡ versionado em git
  - Launcher valida que prompt file existe (field `file`)
  - CI/CD pode validar prompts.yaml schema (futuro)

### R-LAUNCHER-2: Context files movidos (BAIXO)
- **Problema:** MIND_BRIEF.md ou PRD.md mudam de localizaÃ§Ã£o
- **MitigaÃ§Ã£o:**
  - Graceful degradation (warn + continue)
  - NÃ£o Ã© bloqueante para MVP
  - Documentar estrutura ACS V3.0 como contrato

### R-LAUNCHER-3: Ganho <30% (ALTO)
- **Problema:** Launcher nÃ£o economiza tempo suficiente (ROI negativo)
- **MitigaÃ§Ã£o:**
  - Validar cedo (Day 3)
  - Pivot rÃ¡pido se nÃ£o funcionar
  - Investigar onde estÃ¡ o bottleneck real (nÃ£o assume Ã© ativaÃ§Ã£o)

---

## 12. Next Steps After MVP

**If Successful (â‰¥30% time saved):**

1. **Week 2:** Story 1.2 - Workflow Board & Telemetry
   - Integrate launcher logs com board
   - Display progress visual

2. **Week 3:** Story 1.3 - Brownfield Assistant
   - Extend launcher para detectar diffs
   - Suggest prompts to re-run

3. **Week 4:** Story 1.4 - Notes & Handoff Engine
   - Launcher populates notes automaticamente
   - Agent handoffs tracked

**If Unsuccessful (<30% time saved):**

1. **Investigate:** Onde estÃ¡ o bottleneck real?
   - Context loading? (otimizar)
   - Display too verbose? (simplificar)
   - Friction em outro lugar? (pivot)

2. **Pivot Options:**
   - Simplificar ainda mais (remove context loading?)
   - Focar em outro pain point (G2: paralelizaÃ§Ã£o?)
   - Reavaliar Epic 1 priorities

---

## 13. Appendix

### A. Example: Full Launcher Output

```bash
$ aios-launcher --mind steve_jobs --phase analysis --prompt analysis_mental_models --show-context --show-deps

ğŸ—ï¸ AIOS Launcher v1.0

Mind: steve_jobs
Phase: analysis
Prompt: analysis_mental_models
Title: Mental Models

âœ… Agent Identified: #analyst
âš¡ Parallelizable: Yes

ğŸ“‹ Context Summary:
---
PRD Objective: Create authentic cognitive clone of Steve Jobs
Viability: APEX 8.5, ICP 9.0 - APPROVED
Sources Available: 12 books, 23 interviews, 47 articles
Current Phase: Analysis (3/6 checkpoints completed)
---

ğŸ“‹ Full Context (--show-context enabled):
---
MIND_BRIEF Roadmap:
  [x] Checkpoint #1: Viability approved (2025-09-28)
  [x] Checkpoint #2: Research validated (2025-10-01)
  [x] Checkpoint #3: Analysis complete (IN PROGRESS)
  [ ] Checkpoint #4: KB synthesized
  [ ] Checkpoint #5: Prompts implemented
  [ ] Checkpoint #6: Testing approved

PRD Objective (full):
  "Create an authentic cognitive clone of Steve Jobs that captures his
   unique product vision, design philosophy, and ability to connect
   technology with liberal arts. Primary use case: product strategy
   consultation for startups building consumer technology."

Sources Master (excerpt):
  Books:
    - Steve Jobs (Walter Isaacson, 2011)
    - The Innovation Secrets of Steve Jobs (Carmine Gallo, 2010)
    - Becoming Steve Jobs (Brent Schlender, 2015)
  Interviews:
    - D8 Conference (2010)
    - WWDC Keynotes (1997-2011)
    - Stanford Commencement (2005)
  [... 47 total sources]
---

ğŸ“‚ Suggested Output Path:
   minds/steve_jobs/artifacts/mental_models.md

ğŸ“ Dependencies (--show-deps enabled):
   âœ… analysis_behavioral_patterns (completed 2025-10-03)
   âœ… analysis_recognition_patterns (completed 2025-10-03)
   âœ… analysis_linguistic_forensics (completed 2025-10-02)

âš¡ Next Steps:
1. Activate agent: Type '#analyst' in Claude Code
2. Execute prompt: prompts/analysis_mental_models.md
3. Save output to suggested path above
4. Update MIND_BRIEF.md roadmap (mark task complete)

ğŸ“ Execution logged to: docs/mmos/logs/launcher-history.yaml

---
ğŸ’¡ Tip: Use --dry-run to simulate without logging
```

### B. prompts.yaml Reference

**Location:** `docs/mmos/prompts.yaml`

**Total Prompts:** 59 (conforme arquivo real)

**Phases:**
- viability: 5 prompts
- research: 6 prompts
- analysis: 18 prompts
- synthesis: 6 prompts
- implementation: 9 prompts
- testing: 2 prompts (+ outros)

**Sample IDs (for testing/reference):**
```
viability_scorecard_apex
viability_icp_match_score
viability_prd_generator
research_source_discovery
research_source_collector
analysis_source_reading
analysis_mental_models
analysis_values_hierarchy
analysis_cognitive_architecture
synthesis_template_extractor
synthesis_kb_chunker
implementation_generalista_compiler
testing_personality_validator
```

**Structure:** Ver seÃ§Ã£o 2.3 para estrutura completa

**Para Consultar:** Abra `docs/mmos/prompts.yaml` para ver todos os prompts disponÃ­veis com campos completos (agent, outputs, depends_on, parallelizable, etc.)

  02_source_collector:
    agent: dev
    output_format: md
    description: "Coletar e organizar fontes"

  03_temporal_mapper:
    agent: analyst
    output_format: yaml
    description: "Mapear contexto temporal"

  03_priority_calculator:
    agent: analyst
    output_format: yaml
    description: "Calcular matriz de prioridades"

  04_sources_master:
    agent: analyst
    output_format: yaml
    description: "Inventory completo de fontes"

analysis:
  # NÃ­vel 1: ExtraÃ§Ã£o Base
  01_source_reading:
    agent: analyst
    output_format: md
    description: "Leitura e anotaÃ§Ã£o de fonte"

  01_quote_extraction:
    agent: analyst
    output_format: yaml
    description: "ExtraÃ§Ã£o de citaÃ§Ãµes-chave"

  01_timeline_mapping:
    agent: analyst
    output_format: yaml
    description: "Mapeamento temporal"

  # NÃ­vel 2: DNA Layers 1-2
  02_recognition_patterns:
    agent: analyst
    output_format: yaml
    description: "PadrÃµes de reconhecimento (Layer 2)"

  02_linguistic_forensics:
    agent: analyst
    output_format: md
    description: "AnÃ¡lise linguÃ­stica (Layer 1)"

  02_behavioral_patterns:
    agent: analyst
    output_format: md
    description: "PadrÃµes comportamentais (Layer 2)"

  01_rotine:
    agent: analyst
    output_format: yaml
    description: "Rotinas e hÃ¡bitos diÃ¡rios"

  # NÃ­vel 3: DNA Layers 3-5
  03_mental_models:
    agent: analyst
    output_format: yaml
    description: "Modelos mentais mestres (Layer 3)"

  03_values_hierarchy:
    agent: analyst
    output_format: yaml
    description: "Hierarquia de valores (Layer 5)"

  03_belief_system:
    agent: analyst
    output_format: yaml
    description: "Sistema de crenÃ§as (Layer 4)"

  03_decision_architecture:
    agent: architect
    output_format: yaml
    description: "Arquitetura de decisÃ£o (Layer 4)"

  03_immune_system:
    agent: analyst
    output_format: md
    description: "Sistema imune cognitivo"

  # NÃ­vel 4: DNA Layer 6
  04_core_obsessions:
    agent: analyst
    output_format: yaml
    description: "ObsessÃµes core (Layer 6)"

  # NÃ­vel 5: DNA Layer 7
  05_unique_algorithm:
    agent: architect
    output_format: md
    description: "Algoritmo cognitivo Ãºnico (Layer 7)"

  05_contradictions_map:
    agent: analyst
    output_format: yaml
    description: "Mapa de contradiÃ§Ãµes (Layer 7)"

  # NÃ­vel 6: DNA Layer 8
  06_cognitive_architecture:
    agent: architect
    output_format: yaml
    description: "Arquitetura cognitiva completa (Layer 8)"

  06_psychometric_analysis:
    agent: analyst
    output_format: json
    description: "AnÃ¡lise psicomÃ©trica"

  06_limitations_doc:
    agent: analyst
    output_format: md
    description: "DocumentaÃ§Ã£o de limitaÃ§Ãµes"

synthesis:
  01_template_extractor:
    agent: analyst
    output_format: md
    description: "Extrair templates de comunicaÃ§Ã£o"

  01_phrases_miner:
    agent: analyst
    output_format: md
    description: "Minerar frases signature"

  01_frameworks_identifier:
    agent: analyst
    output_format: md
    description: "Identificar frameworks"

  01_extract_core:
    agent: analyst
    output_format: yaml
    description: "Extrair essÃªncia core"

  02_kb_chunker:
    agent: dev
    output_format: md
    description: "Chunking da knowledge base"

  03_specialist_recommender:
    agent: architect
    output_format: yaml
    description: "Recomendar specialists"

implementation:
  01_extract_patterns:
    agent: dev
    output_format: yaml
    description: "Extrair padrÃµes"

  02_identity_core:
    agent: architect
    output_format: md
    description: "Core de identidade"

  02_meta_axioms:
    agent: architect
    output_format: yaml
    description: "Meta-axiomas"

  02_instructions_core:
    agent: pm
    output_format: md
    description: "InstruÃ§Ãµes core"

  03_generalista_compiler:
    agent: architect
    output_format: md
    description: "Compilar system prompt generalista"

  04_specialist_creator:
    agent: architect
    output_format: md
    description: "Criar system prompts specialists"

  05_operational_manual:
    agent: pm
    output_format: md
    description: "Manual operacional"

  05_testing_protocol:
    agent: qa
    output_format: md
    description: "Protocolo de testes"

testing:
  01_test_generator:
    agent: qa
    output_format: yaml
    description: "Gerar casos de teste"

  02_personality_validator:
    agent: qa
    output_format: md
    description: "Validar personalidade"

  02_knowledge_tester:
    agent: qa
    output_format: md
    description: "Testar conhecimento"

  02_edge_cases:
    agent: qa
    output_format: md
    description: "Casos extremos"

  03_final_report:
    agent: qa
    output_format: md
    description: "RelatÃ³rio final de testes"

  04_readme_generator:
    agent: pm
    output_format: md
    description: "Gerar README.md"
```

---

## Status: AWAITING APPROVAL

**Next Actions:**
1. âœ… Review spec com Alan Nicolas
2. [ ] Adjust based on feedback
3. [ ] Approve for implementation
4. [ ] Begin Day 1 coding

**Estimated Implementation Time:** 2-3 days (if approved as-is)
