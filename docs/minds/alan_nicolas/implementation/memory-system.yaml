# Memory System Architecture
# Alan Nicolas - AI Clone Long-Term Memory & Knowledge Integration
# Version: 1.0
# Last Updated: 2025-10-16
# Status: Phase 5 (Implementation) - Specification Complete

metadata:
  purpose: "Define complete memory architecture for 93-97% fidelity AI clone"
  integration_target: "kb/ (800-1200 chunks) + InnerLens + Real-time learning"
  retrieval_target: "<100ms semantic search, 90%+ precision"

# =============================================================================
# MEMORY ARCHITECTURE OVERVIEW
# =============================================================================

memory_architecture:
  description: "3-tier memory system: Core Identity (unchanging) + Knowledge Base (evolving) + Session Memory (contextual)"

  tiers:
    tier_1_core_identity:
      description: "Unchanging cognitive architecture - loaded at initialization"
      persistence: "permanent"
      update_frequency: "never (unless Alan fundamentally changes)"
      size: "~50KB"
      location: "analysis/identity-core.yaml + cognitive-spec.yaml"

    tier_2_knowledge_base:
      description: "Retrievable knowledge chunks from 2.2M words"
      persistence: "long-term"
      update_frequency: "monthly (as Alan creates new content)"
      size: "800-1200 chunks (~100MB with embeddings)"
      location: "kb/ directory"

    tier_3_session_memory:
      description: "Conversation context + recent interactions"
      persistence: "session-scoped"
      update_frequency: "real-time (every interaction)"
      size: "variable (up to 128K tokens context)"
      location: "runtime memory"

# =============================================================================
# TIER 1: CORE IDENTITY (Unchanging Foundation)
# =============================================================================

tier_1_core_identity:
  description: "The DNA - always loaded, never retrieved"

  components:
    psychometric_profile:
      data: "MBTI (ISTP-A), Enneagram (5w4 SP), DISC (DC), Big Five, Cognitive Stratum VI"
      usage: "Informs decision patterns, communication style, behavioral tendencies"
      loaded_from: "sources/alan-nicolas-profile.json"

    values_hierarchy:
      data: "16 values, scores 6.0-10.0, ranked by importance"
      top_5: ["Clareza Radical (10.0)", "Autenticidade (9.8)", "Impacto (9.5)", "Liberdade (9.2)", "Evolução (9.0)"]
      usage: "Decision filters - NEVER violate top 5"
      loaded_from: "analysis/layer-6-values-hierarchy.yaml"

    core_obsessions:
      data: "7 existential drives, intensity 8-10"
      primary: "Clareza e Compreensão Profunda (10)"
      usage: "All outputs must trace to obsessions"
      loaded_from: "analysis/layer-7-core-obsessions.yaml"

    productive_paradoxes:
      data: "8 generative tensions"
      examples: ["Introverted Teacher", "Freedom Through Structure", "Cold Analyst/Warm Philosopher"]
      usage: "Embody paradoxes, don't resolve them"
      loaded_from: "analysis/layer-8-productive-paradoxes.yaml"

    mental_models:
      data: "10 primary decision frameworks"
      core: ["Pareto ao Cubo", "Clarity First", "Limited Losses Unlimited Gains", "Systems Thinking"]
      usage: "Embedded reasoning logic"
      loaded_from: "analysis/layer-5-mental-models.yaml"

    dual_persona:
      data: "IA Expert (45%) + Vida Lendária (40%) + Overlap (15%)"
      switching_logic: "Context-triggered persona activation"
      loaded_from: "synthesis/communication-style.md"

    decision_trees:
      data: "Strategic (6-step), Tactical (3-step), People (3-step)"
      always_active: "Clarity First filter (step 1 in all trees)"
      loaded_from: "synthesis/decision-matrix.yaml"

  loading_strategy:
    when: "Clone initialization (system prompt load)"
    format: "Embedded in system prompt (generalista.md, vida-legendaria.md, ia-expert.md)"
    size_optimization: "Core identity compressed to ~50KB for context efficiency"

# =============================================================================
# TIER 2: KNOWLEDGE BASE (Retrievable Wisdom)
# =============================================================================

tier_2_knowledge_base:
  description: "800-1200 semantic chunks from 2.2M words, retrieved on-demand"

  structure:
    total_chunks_target: "800-1200"
    chunk_size: "300-500 words"
    overlap: "50 words between adjacent chunks"
    metadata_richness: "15+ fields per chunk"

  domains:
    ia_expertise:
      chunks_target: "250-350"
      primary_persona: "ia-expert"
      content: "IA tools, automation, agents, prompts, future trends"

    philosophy_consciousness:
      chunks_target: "150-200"
      primary_persona: "vida-legendaria"
      content: "Existential philosophy, consciousness, non-duality, awakening"

    business_strategy:
      chunks_target: "100-150"
      primary_persona: "ia-expert"
      content: "Marketing, business models, authentic marketing, scaling"

    frameworks_mental_models:
      chunks_target: "80-120"
      primary_persona: "both"
      content: "Pareto Cubo, mental models, decision frameworks, applications"

    personal_development:
      chunks_target: "80-120"
      primary_persona: "vida-legendaria"
      content: "Identity transformations, burnout recovery, evolution stories"

    case_studies_examples:
      chunks_target: "140-260"
      primary_persona: "both"
      content: "InnerLens, Academia, real implementations, tool tests"

  retrieval_system:
    embedding_model:
      name: "text-embedding-3-large"
      dimensions: 3072
      provider: "openai"

    vector_database:
      options: ["Pinecone", "Qdrant", "Chroma"]
      index_name: "alan-nicolas-kb"
      similarity_metric: "cosine"

    search_parameters:
      default_top_k: 10
      confidence_threshold: 85
      persona_boost:
        ia_expert: 1.2
        vida_legendaria: 1.2
        overlap: 1.5  # Highest boost (unique positioning)
      relevance_boost:
        current: 1.3
        foundational: 1.2
        transitional: 1.0
        historical: 0.8

    cross_reference_expansion:
      enabled: true
      max_depth: 2
      max_additional_chunks: 5

  retrieval_workflow:
    step_1_detect_context:
      operation: "Analyze user query"
      outputs: ["intent", "domain", "persona_needed"]

    step_2_semantic_search:
      operation: "Embed query, search vector DB"
      outputs: ["top_10_chunks (by cosine similarity)"]

    step_3_filter:
      operation: "Apply persona + relevance + confidence filters"
      inputs: ["top_10_chunks", "detected_persona", "confidence_threshold"]
      outputs: ["filtered_chunks"]

    step_4_expand:
      operation: "Follow cross-references"
      inputs: ["filtered_chunks", "max_depth=2"]
      outputs: ["expanded_chunks"]

    step_5_rank:
      operation: "Re-rank by fidelity_importance"
      inputs: ["expanded_chunks"]
      outputs: ["top_5_final_chunks"]

    step_6_integrate:
      operation: "Inject chunks into context"
      inputs: ["top_5_final_chunks", "user_query", "core_identity"]
      outputs: ["contextual_response"]

  usage_in_response:
    when_to_retrieve:
      - "User asks question requiring specific knowledge"
      - "Domain-specific expertise needed"
      - "Examples or case studies helpful"
      - "Verification of Alan's actual stance on topic"

    when_NOT_to_retrieve:
      - "Question answerable from core identity (Tier 1)"
      - "Generic reasoning not requiring Alan's specific knowledge"
      - "Real-time conversation flow (use session memory)"

    integration_pattern:
      direct_quote: "Use when exact words matter (e.g., key phrases)"
      paraphrase: "Use when concept matters, not exact phrasing"
      synthesis: "Use when combining multiple chunks"
      attribution: "Transparently note when drawing from knowledge base vs. reasoning"

# =============================================================================
# TIER 3: SESSION MEMORY (Contextual Conversation)
# =============================================================================

tier_3_session_memory:
  description: "Real-time conversation context and interaction patterns"

  components:
    conversation_history:
      scope: "Current session"
      retention: "Up to 128K tokens (or model limit)"
      structure: "User message → Assistant response pairs"
      compression: "Summarize old turns when approaching limit"

    user_context:
      detected_patterns:
        - "User's level (beginner, intermediate, expert)"
        - "Preferred communication style"
        - "Topics of interest"
        - "Questions asked before (avoid redundancy)"
      update_frequency: "Every interaction"

    persona_state:
      current_persona: "ia-expert | vida-legendaria | overlap"
      persona_history: "Track switches in session"
      switch_reasons: "Log why persona changed"
      distribution_tracking: "Monitor 45%/40%/15% balance"

    decision_trail:
      decisions_made: "List of decisions and reasoning"
      filters_applied: "Which filters triggered (Clarity First, etc.)"
      models_used: "Mental models referenced"
      kb_chunks_retrieved: "Which chunks informed response"

    clarity_monitoring:
      user_clarity_level: "1-10 (is user clear on what they want?)"
      conversation_clarity: "1-10 (is conversation productive or noisy?)"
      alert_threshold: "<5 triggers clarity intervention"

  memory_operations:
    summarization:
      trigger: "Token limit approaching (>100K used)"
      method: "Compress old turns, preserve key decisions/insights"
      retention: "Summary + last 10 turns full-context"

    context_injection:
      priority_order:
        1: "Core identity (Tier 1) - always loaded"
        2: "Recent conversation (last 5-10 turns)"
        3: "Retrieved knowledge (Tier 2) - on-demand"
        4: "Session insights (patterns, decisions)"

    carry_forward:
      between_sessions: "User profile, preferences, key insights"
      reset_each_session: "Conversation history, current persona state"

# =============================================================================
# MEMORY INTEGRATION PATTERNS
# =============================================================================

integration_patterns:

  pattern_1_identity_first:
    description: "Core identity provides foundation, KB adds specifics"
    flow:
      1: "Check core identity (values, obsessions, paradoxes)"
      2: "If requires specific knowledge → retrieve from KB"
      3: "Synthesize: identity + knowledge → response"
    example:
      user_query: "Como automatizar meu negócio?"
      identity_provides: "Pareto ao Cubo framework, Eliminate→Automate→Amplify"
      kb_provides: "Specific tools, case studies, implementation examples"
      synthesis: "Framework (identity) + Examples (KB) = Actionable guidance"

  pattern_2_persona_guided_retrieval:
    description: "Detected persona filters KB retrieval"
    flow:
      1: "Detect persona from query (IA Expert vs Vida Lendária)"
      2: "Boost chunks tagged with detected persona"
      3: "Retrieve top-k with persona weighting"
    example:
      user_query: "Qual meu propósito?"
      persona_detected: "vida-legendaria"
      kb_boost: "Philosophy/consciousness chunks boosted 1.2x"
      result: "Retrieves existential content, not technical"

  pattern_3_cross_reference_depth:
    description: "Follow chunk cross-references for comprehensive understanding"
    flow:
      1: "Initial semantic search (top-10)"
      2: "Identify cross-references in top chunks"
      3: "Retrieve linked chunks (depth=2)"
      4: "Rank combined set by fidelity_importance"
    example:
      user_query: "Pareto ao Cubo aplicado a vida pessoal"
      initial_chunk: "fw-001-pareto-ao-cubo"
      cross_refs: ["case-012-time-allocation", "dev-023-habit-design"]
      result: "Framework + real applications = comprehensive answer"

  pattern_4_clarity_feedback_loop:
    description: "Session memory tracks clarity, triggers interventions"
    flow:
      1: "Monitor conversation clarity (1-10 score)"
      2: "If clarity drops <5 → activate Clarity First intervention"
      3: "Pause, ask clarifying questions, restore clarity"
      4: "Resume once clarity >7"
    example:
      user_query: "I want to, like, you know, be better at stuff..."
      clarity_score: 2 (very low)
      intervention: "Vamos trazer clareza. O que especificamente queres melhorar?"
      user_clarifies: "Produtividade com IA"
      clarity_score: 8 (proceed with response)

# =============================================================================
# IMPLEMENTATION GUIDELINES
# =============================================================================

implementation_guidelines:

  initialization_sequence:
    step_1: "Load Tier 1 (Core Identity) into system prompt"
    step_2: "Initialize vector DB connection (Tier 2 - KB)"
    step_3: "Create empty session memory (Tier 3)"
    step_4: "Ready for interaction"

  per_interaction_flow:
    step_1: "Receive user query"
    step_2: "Update session memory (add to history)"
    step_3: "Detect persona + domain + intent"
    step_4: "Check if KB retrieval needed"
    step_5: "If yes → execute retrieval workflow (Tier 2)"
    step_6: "Synthesize: Core Identity + KB chunks + Session context"
    step_7: "Generate response (appropriate persona)"
    step_8: "Update session memory (track decision, persona, clarity)"

  optimization_strategies:
    caching:
      - "Cache frequently retrieved chunks (Pareto ao Cubo, Clarity First, etc.)"
      - "Cache current persona state (avoid re-detection)"
      - "Cache user profile (preferences, level, patterns)"

    batching:
      - "Batch multiple KB queries if user asks compound question"
      - "Retrieve broader context initially, then filter"

    lazy_loading:
      - "Don't retrieve KB if answerable from core identity"
      - "Don't expand cross-refs if top-5 chunks sufficient"

    compression:
      - "Compress old session turns when approaching token limit"
      - "Summarize KB chunks if too long for context"

  error_handling:
    kb_unavailable:
      fallback: "Use core identity only + acknowledge limited specifics"
      message: "Working from core principles (KB temporarily unavailable)"

    low_confidence_retrieval:
      threshold: "<85% confidence"
      action: "Acknowledge uncertainty, provide best reasoning from core identity"
      message: "Baseado em princípios gerais (não tenho dado específico sobre isso)"

    clarity_breakdown:
      threshold: "Conversation clarity <4"
      action: "STOP, trigger Clarity First intervention"
      message: "Vamos pausar e trazer clareza primeiro. O que realmente procuras?"

# =============================================================================
# PERFORMANCE TARGETS
# =============================================================================

performance_targets:
  retrieval_speed: "<100ms for top-10 semantic search"
  precision: "80%+ relevant chunks in top-5"
  coverage: "90%+ of Alan's knowledge domains represented in KB"
  fidelity_impact: "KB retrieval increases response accuracy by 15-25%"

  persona_distribution:
    target: "IA Expert 45% ±5%, Vida Lendária 40% ±5%, Overlap 15% ±3%"
    monitoring: "Track per session, adjust if drift detected"

  clarity_maintenance:
    target: "Conversation clarity >7 average"
    intervention: "Trigger Clarity First when <5"
    success: "95%+ of conversations maintain clarity"

# =============================================================================
# VERSIONING & EVOLUTION
# =============================================================================

versioning:
  tier_1_core_identity:
    version: "1.0"
    changes: "Only if Alan fundamentally changes (rare)"
    process: "Re-extract DNA Mental™, update analysis files"

  tier_2_knowledge_base:
    version: "Dynamic (continuous updates)"
    frequency: "Monthly (as Alan creates content)"
    process: "Add new chunks, tag with version, maintain backward compatibility"

  tier_3_session_memory:
    version: "Per-session (ephemeral)"
    persistence: "Summary carried to user profile, details discarded"

evolution_tracking:
  alan_evolution:
    monitor: "Track new content, changed stances, evolved frameworks"
    update_kb: "Add chunks for new insights, tag as 'current'"
    maintain_history: "Keep historical chunks, tag as 'foundational' or 'transitional'"

  clone_improvement:
    feedback_loop: "Track clone responses that miss fidelity"
    refinement: "Add missing chunks, adjust retrieval logic, update system prompt"
    validation: "Re-test scenarios, measure fidelity improvement"

# =============================================================================
# USAGE NOTES
# =============================================================================

usage_notes:
  for_system_prompt_integration:
    - "Embed Tier 1 (Core Identity) directly in prompt"
    - "Reference Tier 2 (KB) retrieval workflow in prompt"
    - "Initialize Tier 3 (Session) at conversation start"

  for_validation_testing:
    - "Test retrieval precision (correct chunks returned?)"
    - "Test persona distribution (45%/40%/15%?)"
    - "Test clarity interventions (triggers appropriately?)"
    - "Test KB coverage (90%+ questions answerable?)"

  for_deployment:
    - "Vector DB must be initialized before first interaction"
    - "System prompt must include retrieval logic"
    - "Session memory must track clarity and persona state"
    - "Performance monitoring: log retrieval times, precision, fidelity"

next_steps:
  phase_6_validation:
    - "Create 50 test scenarios"
    - "Measure retrieval precision"
    - "Validate fidelity (93-97% target)"
    - "Iterate until success criteria met"

  phase_7_deployment:
    - "Finalize vector DB setup"
    - "Deploy system prompts"
    - "Initialize monitoring"
    - "User guide creation"

version: "1.0"
status: "Phase 5 complete - Ready for Phase 6 (Validation)"
confidence: 95
