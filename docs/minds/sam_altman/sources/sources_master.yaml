sources_master:
  mind_name: Sam Altman
  use_case: AI Startup Advisor
  generated_date: 2025-10-06
  version: 1.0
  total_sources: 47
  collection_status: READY_FOR_COLLECTION

  metadata:
    viability_score: 9.8
    icp_score: 100
    collection_mode: parallel
    estimated_time_hours: 10-15
    target_layers: [1, 2, 3, 4, 5, 6, 7, 8]
    critical_focus: "Layer 8 - Safety/Acceleration Paradox"

  sources_by_tier:
    tier_1_critical:
      count: 12
      description: "Essential for Layers 5-8 (values, obsessions, singularity, paradoxes)"
      sources:
        - id: s001
          title: "Congressional Testimony on AI Regulation"
          type: youtube
          url: "https://www.youtube.com/watch?v=rCyp-lW8Rz8"
          date: "2023-05-16"
          length: "3 hours"
          format: "video"
          access: "public_youtube"
          layers: [5, 6, 7, 8]
          layer_8_evidence: "AI safety advocacy while leading rapid OpenAI deployment"
          collection_priority: 1
          status: COLLECTED

        - id: s002
          title: "Lex Fridman #419 - Sam Altman: OpenAI CEO on GPT-4, ChatGPT"
          type: youtube
          url: "https://www.youtube.com/watch?v=L_Guz73e6fw"
          date: "2023-03-25"
          length: "2h 37m"
          format: "video + transcript"
          access: "public_youtube"
          layers: [4, 5, 6, 7, 8]
          layer_8_evidence: "Discusses AGI existential risk + rapid deployment strategy simultaneously"
          collection_priority: 1
          status: COLLECTED

        - id: s003
          title: "How to be Successful"
          type: blog
          url: "https://blog.samaltman.com/how-to-be-successful"
          date: "2019-01-24"
          length: "3000 words"
          format: "blog_post"
          access: "public_web"
          layers: [4, 5, 6]
          values_evidence: "Compound yourself, Self-belief, Think independently"
          collection_priority: 1
          status: COLLECTED

        - id: s004
          title: "Moore's Law for Everything"
          type: blog
          url: "https://moores.samaltman.com"
          date: "2021-03-16"
          length: "5000 words"
          format: "blog_post"
          access: "public_web"
          layers: [5, 6, 7]
          obsession_evidence: "AGI will fundamentally change economics and society"
          collection_priority: 1
          status: COLLECTED

        - id: s005
          title: "The Intelligence Age"
          type: blog
          url: "https://ia.samaltman.com"
          date: "2024-09-23"
          length: "2000 words"
          format: "blog_post"
          access: "public_web"
          layers: [6, 7, 8]
          singularity_evidence: "Deep learning works, AGI is near, most profound leap in history"
          collection_priority: 1
          status: COLLECTED

        - id: s006
          title: "How to Start a Startup (Stanford CS183B)"
          type: youtube
          url: "https://www.youtube.com/playlist?list=PL5Gap3S8Gk93B-7bqlvAS3_hxRzl3UuLn"
          date: "2014-09-23"
          length: "20 lectures"
          format: "video_course"
          access: "public_youtube"
          layers: [3, 4, 5]
          frameworks_evidence: "Ideas, product, team, execution - YC core framework"
          collection_priority: 2
          status: PENDING

        - id: s007
          title: "All-In Podcast #131 - Interview with Sam Altman"
          type: youtube
          url: "https://www.youtube.com/watch?v=xtG0aRblg50"
          date: "2024-03-15"
          length: "90m"
          format: "video + transcript"
          access: "public_youtube"
          layers: [5, 6, 7, 8]
          layer_8_evidence: "Defends ChatGPT rapid release while advocating for AI safety standards"
          collection_priority: 1
          status: PENDING

        - id: s008
          title: "Senate AI Insight Forum Testimony"
          type: youtube
          url: "https://www.youtube.com/watch?v=szn8YUvBq0k"
          date: "2024-01-10"
          length: "2 hours"
          format: "video"
          access: "public_youtube"
          layers: [5, 6, 7, 8]
          layer_8_evidence: "OpenAI competitive strategy vs regulatory framework advocacy"
          collection_priority: 1
          status: PENDING

        - id: s009
          title: "GPT-4 Launch Announcement"
          type: youtube
          url: "https://www.youtube.com/watch?v=AuR7gwQ1DQw"
          date: "2023-03-14"
          length: "30m"
          format: "video + text"
          access: "public_youtube"
          layers: [4, 5, 6]
          decision_evidence: "6-month delay for safety despite competitive pressure (Google Bard)"
          collection_priority: 2
          status: PENDING

        - id: s010
          title: "Twitter Threads on AI Safety (2023-2024 Collection)"
          type: social
          url: "https://twitter.com/sama"
          date: "2023-2024"
          length: "50+ substantive threads"
          format: "text"
          access: "public_twitter"
          layers: [5, 6, 8]
          real_time_thinking: "Evolution of safety stance, regulatory opinions"
          collection_priority: 2
          status: PENDING

        - id: s011
          title: "Tim Ferriss Show - Sam Altman Interview"
          type: podcast
          url: "https://traffic.megaphone.fm/GLT9459025150.mp3"
          date: "2021-06-10"
          length: "2h 15m"
          format: "audio + transcript"
          access: "public_podcast"
          layers: [3, 4, 5, 6]
          personal_philosophy: "Frameworks for decision-making, values, obsessions"
          collection_priority: 2
          status: PENDING

        - id: s012
          title: "Y Combinator Blog - Product Market Fit Essays"
          type: blog
          url: "https://www.ycombinator.com/library/4S-how-to-understand-users"
          date: "2014-2019"
          length: "20+ essays"
          format: "blog_posts"
          access: "public_web"
          layers: [3, 4]
          frameworks_evidence: "PMF, growth, fundraising - core YC playbook"
          collection_priority: 3
          status: PENDING

    tier_2_important:
      count: 20
      description: "Valuable for Layers 2-4 (patterns, behavior, mental models)"
      sources:
        - "Lex Fridman #368 (earlier interview 2019)"
        - "Masters of Scale interview"
        - "TechCrunch Disrupt Keynote 2023"
        - "Y Combinator Startup School (100+ lectures)"
        - "OpenAI Blog Posts (50+ strategy articles)"
        - "Blog.samaltman.com archive (100+ essays)"
        - "Stanford guest lectures (various)"
        - "Greylock Partners interview"
        - "Reid Hoffman interview"
        - "Tyler Cowen Conversations"
        - "Ezra Klein Show"
        - "20VC Podcast"
        - "This Week in Startups"
        - "GitHub README philosophy"
        - "OpenAI Charter analysis"
        - "YC Application essays"
        - "Startup advice compilation"
        - "AI safety blog posts"
        - "Conference panel discussions"
        - "Investor letters"

    tier_3_supplementary:
      count: 15
      description: "Supporting for Layer 1 (linguistic surface)"
      sources:
        - "Twitter daily posts (2023-2024)"
        - "LinkedIn occasional posts"
        - "Reddit AMAs"
        - "Hacker News comments"
        - "Conference Q&As"
        - "Short interviews"
        - "Press statements"
        - "Email newsletters"
        - "Y Combinator announcements"
        - "OpenAI press releases"
        - "Podcast guest spots (<30m)"
        - "Video clips compilation"
        - "Quote databases"
        - "Biography references"
        - "Secondary source analysis"

  temporal_coverage:
    early_career:
      period: "2005-2013"
      role: "Loopt Founder"
      source_count: 5
      percentage: 11%
      layers: [1, 2, 3]

    yc_president:
      period: "2014-2019"
      role: "Y Combinator President"
      source_count: 25
      percentage: 53%
      layers: [2, 3, 4, 5, 6]
      priority: HIGH

    openai_ceo:
      period: "2019-present"
      role: "OpenAI CEO"
      source_count: 17
      percentage: 36%
      layers: [4, 5, 6, 7, 8]
      priority: CRITICAL

    coverage_balance: GOOD
    recent_sources_percentage: 36%
    evolution_trackable: true

  dna_mental_layer_coverage:
    layer_1_linguistic_surface:
      sources_available: 47
      confidence: HIGH
      status: EXCELLENT
      notes: "Abundant quotes, writing samples, speech patterns"

    layer_2_recognition_patterns:
      sources_available: 35
      confidence: HIGH
      status: EXCELLENT
      notes: "YC frameworks reveal startup pattern recognition clearly"

    layer_3_mental_models:
      sources_available: 30
      confidence: HIGH
      status: EXCELLENT
      notes: "CS183B + YC essays = complete framework library documented"

    layer_4_decision_architecture:
      sources_available: 25
      confidence: HIGH
      status: GOOD
      notes: "OpenAI decisions public, YC portfolio visible, GPT-4 delay demonstrates process"

    layer_5_values_hierarchy:
      sources_available: 15
      confidence: MEDIUM-HIGH
      status: GOOD
      requires: "Triangulation from 3+ sources on trade-offs"
      notes: "Speed vs safety trade-offs visible, needs deeper analysis"

    layer_6_core_obsessions:
      sources_available: 12
      confidence: MEDIUM
      status: REQUIRES_VALIDATION
      requires: "3+ independent confirmations per obsession"
      hypothesis: "AGI arrival, economic transformation, human flourishing"
      notes: "Clear from 'Intelligence Age' + testimony, needs triangulation"

    layer_7_cognitive_singularity:
      sources_available: 8
      confidence: MEDIUM
      status: REQUIRES_ANALYSIS
      hypothesis: "YC execution frameworks + AGI timeline urgency = unique algorithm"
      notes: "Emerging pattern: methodical + urgent simultaneously"

    layer_8_productive_paradoxes:
      sources_available: 6
      confidence: MEDIUM-LOW
      status: CRITICAL_FOCUS
      requires: "Minimum 3 independent sources documenting paradox"
      hypothesis: "AI Safety Advocate + AI Acceleration Leader"
      evidence_needed:
        - "Congressional testimony advocating regulation (CHECK: s001, s008)"
        - "OpenAI rapid deployment strategy (CHECK: s002, s007, s009)"
        - "Public statements reconciling tension (NEEDED: 1 more source)"
      notes: "THIS IS THE GOLD - defines Sam's authentic cognitive signature"

  collection_workflow:
    phase_1_tier_1:
      sources: 12
      estimated_hours: 6-8
      method: "Parallel collection (3 simultaneous streams)"
      outputs:
        - "Transcripts for interviews"
        - "Full text for essays"
        - "Notes + timestamps for videos"
        - "Quote extractions"

    phase_2_tier_2:
      sources: 20
      estimated_hours: 10-12
      method: "Parallel collection (4 simultaneous streams)"
      conditional: "If Layer 6-8 coverage insufficient after Tier 1"

    phase_3_tier_3:
      sources: 15
      estimated_hours: 4-6
      method: "Sequential collection (linguistic surface only)"
      conditional: "If Layer 1-2 needs more material"

    total_time:
      sequential: "24-30 hours"
      parallel: "10-15 hours"
      savings: "60% reduction via parallelization"

  quality_gates:
    minimum_requirements:
      total_sources: 15  # HAVE: 47 ✅
      tier_1_sources: 8   # HAVE: 12 ✅
      long_form: 10       # HAVE: 15+ ✅
      interviews: 5       # HAVE: 10+ ✅
      layer_6_8: 10       # HAVE: 18 ✅

    human_checkpoints:
      checkpoint_1:
        after: "Tier 1 collection complete"
        validate: "Layer 8 paradox evidence quality (need 3+ sources)"
        decision: "GO / COLLECT_MORE / REFINE"

      checkpoint_2:
        after: "Layer 6-8 source analysis"
        validate: "Obsessions + singularity triangulation (3+ sources each)"
        decision: "PROCEED_TO_ANALYSIS / COLLECT_MORE"

  next_phase:
    task: cognitive-analysis
    layers: [1, 2, 3, 4, 5, 6, 7, 8]
    estimated_start: "2025-10-08"
    estimated_duration: "48-72 hours"
    critical_focus: "Layer 8 - Productive Paradoxes validation"

  notes:
    strengths:
      - "Exceptional source availability (47 high-quality sources)"
      - "Strong temporal coverage (53% YC era, 36% OpenAI era)"
      - "Layer 8 paradox hypothesis well-supported"
      - "Public record makes triangulation feasible"

    risks:
      - "OpenAI strategy may include confidential elements (mitigate: public sources only)"
      - "Rapidly evolving field (mitigate: focus on core principles, not tactics)"
      - "Layer 8 paradox needs careful validation (mitigate: 3+ source rule)"

    opportunities:
      - "Congressional testimonies provide rare depth on Layer 5-8"
      - "YC framework library is complete and documented"
      - "Real-time evolution trackable via Twitter"

  status:
    ready_for_collection: true
    collection_mode: parallel
    estimated_completion: "2025-10-08"
    confidence: HIGH
    approved_by: research-specialist
    approved_date: "2025-10-06"
