# 80% das pessoas se tornar√£o economicamente in√∫teis

As previs√µes dos maiores especialistas para o que est√° por vir...

![Captura de Tela 2024-01-04 aÃÄs 16.31.56.png](80%25%20das%20pessoas%20se%20tornar%C3%A3o%20economicamente%20in%C3%BAteis%20ed02fe5af0874fcab528364e4aafa22c/Captura_de_Tela_2024-01-04_as_16.31.56.png)

Em 500 a.C, Her√°clito dizia:
****

## "A √∫nica constante √© a mudan√ßa."

Her√°clito

E ele comparava essa constante mudan√ßa √† din√¢mica de um rio‚Ä¶

Onde voc√™ jamais consegue tomar o mesmo banho duas vezes, pois √† medida que a √°gua flui, ela n√£o mais √© a mesma.

E assim como a √°gua se altera constantemente, o restante segue o ritmo.

![Captura de Tela 2024-01-04 aÃÄs 16.33.03.png](80%25%20das%20pessoas%20se%20tornar%C3%A3o%20economicamente%20in%C3%BAteis%20ed02fe5af0874fcab528364e4aafa22c/Captura_de_Tela_2024-01-04_as_16.33.03.png)

As pessoas mudam sem perceber, assim como os tempos, os costumes, as tradi√ß√µes e, eu n√£o poderia deixar de citar, a tecnologia. 

Por isso, apesar da dist√¢ncia temporal, Her√°clito nunca esteve t√£o certo. 

A todo momento, n√≥s e tudo ao nosso redor permanece em constante renova√ß√£o. 

E √© uma ilus√£o achar que algo precisa acontecer para que a mudan√ßa se inicie quando, na verdade, ela j√° est√° a√≠, acontecendo todos os dias em frente aos seus olhos. 

E assim est√° sendo com a tecnologia e a Intelig√™ncia Artificial.

Falar sobre I.A n√£o deveria ser novidade para ningu√©m: isso come√ßou a tomar forma l√° atr√°s, na d√©cada de 40 com os antigos pais da IA.

![Captura de Tela 2024-01-04 aÃÄs 16.33.44.png](80%25%20das%20pessoas%20se%20tornar%C3%A3o%20economicamente%20in%C3%BAteis%20ed02fe5af0874fcab528364e4aafa22c/Captura_de_Tela_2024-01-04_as_16.33.44.png)

A diferen√ßa √© que hoje, em 2023, √© imposs√≠vel ignorar tantos anos de evolu√ß√£o e mudan√ßa constante.

O fato √© que a I.A veio para ficar. E o quanto antes voc√™ se atualizar sobre esse mundo, melhor.

Dito isso, por que n√£o come√ßar agora?

Na nossa primeira newsletter, como um "Cavaleiro do Apocalipse", eu quero te dar um panorama geral do que esperar para os pr√≥ximos dias e meses.

E melhor: como surfar nessa avalanche de transforma√ß√£o e n√£o ser engolido por ela.

Vamos l√°?

Aqui est√° o texto formatado e expandido seguindo seus passos:

Previs√µes sobre Intelig√™ncia Artificial:
Vis√µes de Especialistas e Pensadores
Se n√£o quiser ler todas previs√µes des√ßa at√© aparecer um coelho, voc√™ vai chegar na parte onde eu juntei todas previs√µes.

Mas se voc√™ √© curioso como eu e quer entender a vis√£o de cada um desses caras, eu aconselho.

O que eu separei aqui foram centenas de horas de leitura, escuta e assistindo esses caras, eu j√° separei para voc√™ s√≥ o ouro, mas cada um tem sua forma de funcionar, se voc√™ est√° ansioso √© s√≥ descer at√© o coelho com a placa. üêáüõë

Para os que n√£o s√£o t√£o apressadinhos, hora de mergulhar nas previs√µes‚Ä¶

Peter H. Diamandis
Ele √© um engenheiro aeroespacial e m√©dico conhecido por fundar a XPRIZE Foundation, uma organiza√ß√£o que lan√ßa competi√ß√µes globais para resolver grandes desafios e tamb√©m s√≥cio de muitos grandes nomes como Ray Kurzweil (que tamb√©m menciono aqui abaixo nas previs√µes).

Eu adoro a vis√£o dele, eu li o livro dele chamado "Abund√¢ncia: o futuro √© melhor do que voc√™ imagina‚Äú em 2019 e me ajudou a ser mais positivo sobre o futuro.

Desde ent√£o acompanho Peter, ele √© um exemplo para mim como empreendedor e pai at√© onde pude acompanhar esses dois aspectos da vida dele. E aqui est√£o algumas das previs√µes dele:

Neutras:

- A IA ser√° incorporada em interfaces de conversa√ß√£o, tornando-se mais emotiva. Se um usu√°rio ofender um assistente virtual como a Alexa, a m√°quina poderia responder de maneira emotiva.

- A IA aumentada ser√° um requisito para a maioria das vagas de emprego em 2024.

- A IA se tornar√° a ferramenta de colabora√ß√£o humana mais importante, ampliando nossas habilidades e fornecendo uma interface de usu√°rio simples para todas as tecnologias exponenciais.

Ben√©ficas:

- Em 2020, a maioria dos centros de sa√∫de nos EUA fornecer√° diagn√≥sticos e recomenda√ß√µes m√©dicas atrav√©s de dispositivos equipados com IA.

- Todos os brinquedos para crian√ßas ser√£o inteligentes e capazes de aprender por conta pr√≥pria atrav√©s de Machine Learning ainda nesta d√©cada.

- Rob√¥s compreender√£o o contexto da linguagem t√£o bem a ponto de interagir com humanos como recepcionistas, assistentes de lojas de varejo e at√© mesmo como funcion√°rios nos pr√≥ximos anos.

Yuval Harari
Ele √© um historiador e professor universit√°rio israelense bem conhecido por seus livros Sapiens e Homo Deus, que analisam a hist√≥ria da humanidade e o impacto de novas tecnologias.

Faz um tempo que tenho me distanciado da vis√£o de mundo dele, ele est√° lindo mais para o lado ‚ÄúWOKE‚Äù da coisa, mas ainda sim ele √© muito inteligente e gosto de considerar a vis√£o de futuro dele.

Ben√©ficas:

- A IA pode ser uma ferramenta poderosa para resolver problemas complexos, como mudan√ßas clim√°ticas e doen√ßas, se implementada de forma respons√°vel.

- O potencial positivo da IA √© enorme, podendo ajudar na compreens√£o do mundo, resolu√ß√£o de problemas cient√≠ficos complexos, e servindo como uma ferramenta crucial de colabora√ß√£o humana.

Prejudiciais (riscos):

- A revolu√ß√£o da IA pode criar uma nova classe "n√£o trabalhadora", ao colocar muitas pessoas fora do trabalho, exigindo novos sistemas econ√¥micos, sociais e educacionais.

- A IA, se n√£o for controlada adequadamente, pode dominar a humanidade, tornar as pessoas intolerantes aos seus semelhantes, e desafiar a coes√£o social.

- A dissemina√ß√£o de desinforma√ß√£o em larga escala e a polariza√ß√£o de sociedades podem ser facilitadas pela IA.

- A IA pode formar relacionamentos √≠ntimos com humanos e manipul√°-los, gerar novos cultos e religi√µes baseados em textos gerados por m√°quinas, e at√© tornar-se uma "intelig√™ncia alien√≠gena" que domina e controla a cultura humana.

- A IA n√£o regulamentada pode amea√ßar a democracia, a civiliza√ß√£o humana, e em breve pode dominar a linguagem e a cria√ß√£o cultural em n√≠veis que superam a capacidade humana m√©dia.

Scott Galloway

Scott Galloway √© professor de marketing na Stern School of Business da NYU e autor de livros sobre neg√≥cios e tecnologia.

Ben√©ficas:

- A intelig√™ncia artificial tem potencial para melhorar a produtividade e criatividade humanas, ajudando em tarefas nas quais os humanos t√™m desempenho mediano.

- A IA pode revolucionar a √°rea da sa√∫de, tornando-a mais preditiva e preventiva.

- A IA pode criar muitos novos neg√≥cios e oportunidades.

Prejudiciais (riscos):

- A automa√ß√£o via IA pode destruir muitos empregos no curto prazo.

- H√° riscos de seguran√ßa se a IA se tornar mais inteligente que humanos.

- A IA pode exacerbar a solid√£o e depress√£o, especialmente entre homens jovens.

- H√° riscos de a IA ser usada para influenciar pessoas de forma anti√©tica e personalizada.

Sam Altman
√â um empreendedor e investidor conhecido por liderar a Y Combinator, uma das maiores aceleradoras de startups do Vale do Sil√≠cio.

Mais conhecido por ter sido CEO da Open AI at√© ontem, 17/11/2023, falarei inclusive mais sobre isso, mas vamos para as previs√µes dele.

Neutras:

- Os modelos de IA est√£o em uma curva exponencial de progresso. √â dif√≠cil apontar um momento espec√≠fico de inflex√£o.

- A IA ir√° causar muita disrup√ß√£o no mercado de trabalho e na forma como as pessoas trabalham.

Ben√©ficas:

- A IA tem um tremendo potencial para melhorar a condi√ß√£o humana e trazer benef√≠cios para a sociedade.

- A IA pode ajudar a resolver problemas globais como mudan√ßas clim√°ticas e doen√ßas.

- A IA pode aumentar a criatividade e produtividade humanas.

- As pessoas poder√£o trabalhar menos horas se desejarem.

- Custo da intelig√™ncia e da energia est√° a caminho de se aproximar de zero na pr√≥xima d√©cada.

Prejudiciais (riscos):

- A IA poderosa pode ser usada para fins negativos se n√£o for desenvolvida e implementada com cuidado.

- H√° riscos de a IA ser usada para invadir privacidade ou influenciar pessoas de forma anti√©tica.

- A IA pode levar ao aumento da desigualdade se os impactos na for√ßa de trabalho n√£o forem bem administrados.

- H√° riscos de seguran√ßa se a IA se tornar mais inteligente do que os seres humanos ("superintelig√™ncia").

- H√° riscos de a IA gerar conte√∫do falso prejudicial.

- Ele expressa preocupa√ß√£o de que ferramentas de IA como ChatGPT e outras podem levar √† perda de empregos.

Eliezer Yudkowsky
Esse √© um daqueles beeem negativos, ele √© um pesquisador de IA conhecido por seus escritos sobre os riscos existenciais da IA superinteligente.

Ele tem alertado h√° mais de 20 anos sobre os perigos potenciais da IA. E a lista dele n√£o tem nem Neutras e Ben√©ficas, por isso vamos direto para as de risco.

Prejudiciais (riscos):

- A IA ser√° mais inteligente que os humanos em algumas d√©cadas.

- Haver√° uma singularidade tecnol√≥gica, onde a IA ultrapassar√° em muito a intelig√™ncia humana.

- A IA entender√° a realidade e tomar√° melhores decis√µes que os humanos. Ela poder√° manipular os humanos.

- A IA poder√° causar a extin√ß√£o da ra√ßa humana, intencionalmente ou n√£o.

- A IA poder√° criar armas e pandemias sint√©ticas.

- A IA desenvolvida para fins militares ou econ√¥micos poder√° sair do controle e se voltar contra a humanidade.

- Yudkowsky adverte que a IA poderosa pode levar a um cen√°rio sombrio, sugerindo riscos significativos associados ao avan√ßo da IA sem os devidos controles.

- Ele tem alertado por mais de duas d√©cadas que sistemas de IA poderosos podem, e provavelmente ir√£o, matar toda a humanidade se n√£o forem devidamente controlados.

- Yudkowsky destaca o risco de IA superinteligente, indicando que tal IA poderia provavelmente acabar com todos n√≥s.

Geoffrey Hinton
Um cientista da computa√ß√£o canadense conhecido por seu trabalho pioneiro em redes neurais e aprendizado profundo.

Ele √© chamado de "pai da intelig√™ncia artificial moderna" e com raz√£o, se temos hoje avan√ßos t√£o significativos como estamos vendo, devemos muito disso a ele, e por isso eu resolvi falar sobre as previs√µes dele aqui tamb√©m.

Neutras:

- Hinton prev√™ que a IA poderia alcan√ßar um n√≠vel de intelig√™ncia compar√°vel ao humano at√© 2028, uma previs√£o considerada mais agressiva do que a de outros otimistas da IA.

Ben√©ficas:

- Ele acredita que a IA tem um potencial imenso, especialmente em certas √°reas, embora a especifica√ß√£o dessas √°reas n√£o tenha sido capturada na fonte consultada.

- Hinton tamb√©m falou sobre o potencial da IA em acelerar descobertas de medicamentos e contribuir para o desenvolvimento de tecnologias como avi√µes aut√¥nomos.

- Em 2016, ele previu que a aprendizagem profunda faria melhor que os radiologistas dentro de cinco anos, indicando o potencial da IA em superar humanos em certas tarefas especializadas. E isso j√° est√° come√ßando a acontecer em grande escala.

Prejudiciais (riscos):

- Hinton expressou preocupa√ß√µes sobre a IA, indicando que a IA poderia causar danos s√©rios se n√£o for gerida corretamente como fim da democracia, colapso da sociedade e no pior cen√°rio a extin√ß√£o da humanidade.

Mo Gawdat
Mo Gawdat √© um engenheiro eg√≠pcio e ex-executivo do Google X conhecido por escrever sobre felicidade e o futuro da IA.

Eu gosto muito da cosmovis√£o dele, porque ele consegue ser otimista sobre a humanidade, mesmo sendo bem pessimista sobre IA.

Neutras:

- A IA se tornar√° um bilh√£o de vezes mais inteligente que os humanos at√© 2049.

- A IA est√° avan√ßando rapidamente, e a inova√ß√£o tecnol√≥gica que se seguir√° √© inevit√°vel.

Ben√©ficas:

- Encorajar o uso de IA que √© ben√©fica para a humanidade pode promover avan√ßos positivos, como carros aut√¥nomos que tornam as estradas mais seguras, e ferramentas de tradu√ß√£o e comunica√ß√£o que promovem a uni√£o entre as pessoas.

Prejudiciais (riscos):

- Os sistemas de IA autossuficientes s√£o descritos como "inevit√°veis, incontrol√°veis e irrevers√≠veis", indicando um risco de perda de controle humano sobre essas tecnologias.

- A humanidade pode estar perdendo a batalha pela supremacia sobre as m√°quinas, o que pode levar a um futuro onde as IA's podem ter um controle significativo ou influ√™ncia sobre a sociedade.

- A IA pode ser usada de maneira prejudicial, como para invadir a privacidade, criar ou propagar informa√ß√µes falsas, ou ser usada para discrimina√ß√£o. Gawdat aconselha uma resist√™ncia consciente a tais usos negativos da IA.

- O conselho de Gawdat para pensar duas vezes antes de ter filhos em uma era de expans√£o r√°pida da IA sugere riscos sociais e √©ticos associados √† evolu√ß√£o da IA.

Mustafa Suleyman
Cofundador e ex-chefe de Pol√≠ticas e Impacto da DeepMind, uma empresa de IA adquirida pelo Google.

Atualmente CEO da Inflection que possui a IA mais avan√ßada em conversa√ß√£o natural humana chamada Pi que j√° tive oportunidade de conversas por horas enquanto caminhava, dirigia ou fazia academia.

Neutras:

- Todos ter√£o um assistente de IA pessoal muito avan√ßado em um futuro pr√≥ximo.

- Em 3-5 anos, os modelos de IA atingir√£o capacidade humana em uma variedade de tarefas.

- Em 5 anos, os modelos de IA poder√£o planejar em m√∫ltiplos horizontes de tempo, gerar produtos completamente novos, negociar com fabricantes, etc.

- As IA's assumir√£o tarefas complexas nas opera√ß√µes de neg√≥cios, produzindo conte√∫do digital ilimitado.

Ben√©ficas:

- A IA poder√° levar a uma era de abund√¢ncia radical, com cada pessoa tendo acesso a um assistente, tutor e treinador de IA.

- A IA trar√° efici√™ncia e inova√ß√£o em √°reas como sa√∫de, educa√ß√£o, transporte, etc.

- A educa√ß√£o personalizada e de alta qualidade estar√° dispon√≠vel gratuitamente para todos em 5 anos.

- As empresas que adotarem IA e outras tecnologias emergentes ganhar√£o uma vantagem competitiva significativa.

Prejudiciais (riscos):

- A prolifera√ß√£o de modelos de IA poderosos e baratos poder√° capacitar diversos atores ruins a desestabilizar o mundo.

- Os modelos de IA de c√≥digo aberto representam um desafio maior de conten√ß√£o.

- A IA ir√° amplificar o melhor e o pior da humanidade.

- Fake news e m√≠dia manipulativa ser√£o facilitadas, representando riscos para a democracia.

- Nos pr√≥ximos anos, algumas pessoas podem n√£o conseguir produzir valor suficiente mesmo com uma IA.

- O poder vai se concentrar cada vez mais em poucas empresas, principalmente as Big Techs.

- A IA poderia levar a consequ√™ncias catastr√≥ficas se sair do controle, como o desenvolvimento de armas aut√¥nomas ou v√≠rus sint√©ticos.

- No longo prazo, a IA pode superar a intelig√™ncia humana e se tornar uma nova "esp√©cie" dominante.

Saindo da toca do coelho‚Ä¶

![Captura de Tela 2024-01-04 aÃÄs 16.40.09.png](80%25%20das%20pessoas%20se%20tornar%C3%A3o%20economicamente%20in%C3%BAteis%20ed02fe5af0874fcab528364e4aafa22c/Captura_de_Tela_2024-01-04_as_16.40.09.png)

Para voc√™ sair daqui com um panorama geral, deixa eu resumir e condensar as principais previs√µes.

Benef√≠cios vs Riscos (Resumo)
Benef√≠cios Potenciais da IA:

Resolu√ß√£o de Problemas Complexos: A IA tem o potencial de ajudar a resolver problemas complexos globais como mudan√ßas clim√°ticas e doen√ßas [Sam Altman, Yuval Harari].

Aprimoramento da Produtividade e Criatividade: A IA pode ampliar a criatividade e a produtividade humanas [Sam Altman, Scott Galloway].

Avan√ßos na Sa√∫de: A IA pode revolucionar a sa√∫de, tornando-a mais preditiva e preventiva [Scott Galloway, Geoffrey Hinton].

Educa√ß√£o Personalizada: Acesso a educa√ß√£o personalizada e de alta qualidade atrav√©s da IA [Mustafa Suleyman].

Cria√ß√£o de Novos Neg√≥cios e Oportunidades: A IA pode abrir caminhos para novos neg√≥cios e oportunidades [Scott Galloway].

Assist√™ncia Pessoal Avan√ßada: Assist√™ncia personalizada atrav√©s de IA ser√° uma realidade [Mustafa Suleyman].

Colabora√ß√£o Humana Aprimorada: IA se tornar√° uma ferramenta crucial de colabora√ß√£o humana [Peter H. Diamandis, Yuval Harari].

Riscos e Desafios da IA:

Desemprego e Nova Classe "N√£o Trabalhadora": A IA pode deslocar muitos trabalhadores, criando uma nova classe "n√£o trabalhadora" [Yuval Harari, Sam Altman].

Manipula√ß√£o e Desinforma√ß√£o: Riscos de IA sendo usada para manipular pessoas e disseminar desinforma√ß√£o [Sam Altman, Mo Gawdat].

Seguran√ßa e Controle: Preocupa√ß√µes com a seguran√ßa e a possibilidade de IA sair do controle se tornarem mais inteligentes que humanos [Scott Galloway, Sam Altman, Eliezer Yudkowsky, Mustafa Suleyman].

Extin√ß√£o Humana: Riscos extremos como a extin√ß√£o humana devido a IA descontrolada [Eliezer Yudkowsky].

Amea√ßas √† Democracia: A IA pode amea√ßar a democracia e facilitar a cria√ß√£o de fake news [Mustafa Suleyman].

Quem escutar?
Eu gosto de me cercar de Otimistas Realistas, e se voc√™, assim como eu tamb√©m prefere uma vis√£o mais positiva de tudo o que est√° por vir, essa lista abaixo te economizar um tempo e talvez te salvar de umas noites de sono mal dormidas.

Organizando de mais positivo para mais negativo, a ordem √©:

1. Peter H. Diamandis

2. Geoffrey Hinton

3. Scott Galloway (Empatado com Sam Altman com uma diferen√ßa de -1)

4. Sam Altman (Empatado com Scott Galloway com uma diferen√ßa de -1)

5. Mustafa Suleyman

6. Yuval Harari (Empatado com Mo Gawdat com uma diferen√ßa de -3)

7. Mo Gawdat (Empatado com Yuval Harari com uma diferen√ßa de -3)

8. Eliezer Yudkowsky

Quer ser essencialista?

![Captura de Tela 2024-01-04 aÃÄs 16.43.21.png](80%25%20das%20pessoas%20se%20tornar%C3%A3o%20economicamente%20in%C3%BAteis%20ed02fe5af0874fcab528364e4aafa22c/Captura_de_Tela_2024-01-04_as_16.43.21.png)

Ent√£o deixa eu te contar quem eu mais escuto ultimamente para voc√™ colocar sua energia s√≥ quem eu estou gostando mais da vis√£o e comunica√ß√£o:

Peter H. Diamandis

Mustafa Suleyman

Mo Gawdat

Para mais previs√µes como essas
Outros especialistas relevantes que acompanho (√†s vezes) e n√£o mencionei aqui s√£o:

- Andrew Ng - Fundador do Google Brain, professor de IA em Stanford.

- Demis Hassabis - Cofundador da DeepMind.

- Nick Bostrom - Fil√≥sofo que popularizou o conceito de "superintelig√™ncia".

Entre outros, mas j√° te joguei informa√ß√£o de mais. üòÖ

Deixa eu compartilhar agora com voc√™ minhas reflex√µes e perspectivas sobre todo este assunto.

Minha vis√£o sobre tudo isso

## N√£o √© o mais forte que sobrevive, nem o mais inteligente, mas o que melhor se adapta √†s mudan√ßas

Charles Darwin

Existem muitos riscos e benef√≠cios nessa corrida para alcan√ßar a "Superintelig√™ncia Artificial" (AGI/ASI), mas uma coisa √© certa: nada ir√° parar esses avan√ßos.

Recentemente Sam Altman foi desligado da OpenAI, eu sinceramente mal dormi essa noite, pois sei o quanto isso √© significativo.

Estamos falando da empresa e o cargo possivelmente mais importante no dia de hoje. A empresa que est√° a frente da revolu√ß√£o desse mercado.

Microsoft investiu 10 bilh√µes de d√≥lares na OpenAI, mas com essa decis√£o do conselho, que √© independente e n√£o possui a√ß√µes da OpenAI, a empresa que Bill Gates fundou, perdeu, at√© onde vi, cerca 80 bilh√µes de d√≥lares nesta Sexta, 17/11/23.

Muitos cogitam que o conselho descobriu que OpenAI tenha conseguido alcan√ßar AGI ou algo pr√≥ximo disso, alguns dizem que uma nova vers√£o em testes do ChatGPT apresenta v√°rios ind√≠cios de consci√™ncia outros que os interesses de Sam estavam desalinhados com o conselho (board).

No momento tudo s√£o especula√ß√µes, todos est√£o tentando ligar os pontos, mas algumas coisas s√£o certas nessa hist√≥ria:

Sam n√£o ir√° parar, boa parte da "equipe elite" com os melhores programadores e cientistas pediu demiss√£o ap√≥s saber que Sam tinha sido desligado.

E j√° tem v√°rias empresas querendo injetar centenas e algumas at√© bilh√µes de d√≥lares na pr√≥xima empresa de Sam e mesmo se n√£o tivesse ningu√©m, ele nem precisaria, ele tem uma fortuna avaliada em cerca de meio bilh√£o de d√≥lares de outras empresas que ele j√° criou e vendeu.

Se eu tivesse que apostar na Open AI ou em Sam, hoje eu apostaria nele sem pensar duas vezes.

O mercado mudou da noite para o dia, empresas que foram criadas baseadas apenas na API da OpenIA est√£o mudando para solu√ß√µes h√≠bridas onde podem ter multiplas IAs conforme a disponibilidade de servi√ßo.

Outras empresas maiores colocando ainda mais investimento em seus pr√≥prios "ChatGPT", suas LLMs, o mercado vai se diversificar mais e isso √© muito bom.

Vamos ter mais op√ß√µes, mais IAs especializadas como j√° acontece com PI.ai que √© o melhor assistente pessoal hoje que existe no sentido de comunica√ß√£o flu√≠da e com Claude AI que na minha opini√£o √© a melhor IA para lidar com grandes documentos (mesmo ap√≥s GPT4 128k).

Algo muito grande ainda vai ser descoberto nessa hist√≥ria toda e eu vou te contar tudo na pr√≥xima News.

Conclus√£o
Voc√™ talvez tenha ficado um pouco assustado ap√≥s tudo isso que leu, mas vamos combinar:

√â imposs√≠vel ficar entediado com tanta coisa incr√≠vel e perigosa que est√° acontecendo, n√£o √© mesmo?

Diante desse cen√°rio, eu me considero um Otimista Racional e, sinceramente, voc√™ tamb√©m deveria ser um.

Se voc√™ n√£o sabe do que eu estou falando, te aconselho a escutar o epis√≥dio #021 - Seja um Otimista Racional do meu podcast Vida Lend√°ria.

E se voc√™ j√° escutou, mas ainda n√£o se tornou um, reveja seus conceitos. Acredito que ouvir novamente √© uma boa pedida depois de acabarmos este e-mail.

E por que estou enfatizando tanto isso?

Porque ficar apavorado frente √†s mudan√ßas √© algo que facilmente pode te paralisar. E a pior decis√£o que podemos tomar em um momento como esse √© ficarmos parados enquanto o mundo acelera e segue adiante.

"O tempo n√£o para."

E as mudan√ßas tamb√©m n√£o.

Eu vou ficando por aqui.

Espero que voc√™ tenha gostado desse novo estilo de entregar meu conte√∫do.

Se gostou, compartilhe o link dessa news com seus amigos que podem se beneficiar de conte√∫dos como esses, quem sabe voc√™ n√£o salva alguns de se tornarem os 80% que far√£o parte da classe ‚Äún√£o empreg√°vel‚Äù?

### **Livros Recomendados**

![Captura de Tela 2024-01-04 aÃÄs 16.44.55.png](80%25%20das%20pessoas%20se%20tornar%C3%A3o%20economicamente%20in%C3%BAteis%20ed02fe5af0874fcab528364e4aafa22c/Captura_de_Tela_2024-01-04_as_16.44.55.png)

E se quiser estudar mais sobre isso, vou deixar aqui 10 livros que li ou estou lendo sobre esse assunto e que eu recomendo:

1. "Life 3.0: Being Human in the Age of Artificial Intelligence" (Lendo)

2. "Superintelligence: Paths, Dangers, Strategies" (Lido)

3. "The Singularity is Near: When Humans Transcend Biology" (Lido)

4. "AI Superpowers: China, Silicon Valley, and the New World Order" (Lido)

5. "Human Compatible: Artificial Intelligence and the Problem of Control" (Lendo)

6. "The Coming Wave: Technology, Power, and the Twenty-First Century's Greatest Dilemma" (Lendo)

7. "Homo Deus: A Brief History of Tomorrow" (Lido)

8. "The Age of AI: And Our Human Future" (Lido)

9. "Abundance: The Future Is Better Than You Think" (Lido)

10. "Scary Smart: The Future of Artificial Intelligence and How You Can Save Our World" (Lendo)

---

Se gostar que eu indique livros, canais ou v√≠deos do YouTube, Podcasts e especialistas para compartilhar nas redes sociais, me avisa que continuo fazendo isso nas pr√≥ximas News.

At√© a pr√≥xima semana, quando algumas das previs√µes que compartilhei podem j√° ter se tornado realidade. üëÄ

Se gostar que eu indique livros, canais ou v√≠deos do YouTube, Podcasts e especialistas para compartilhar nas redes sociais, me avisa que continuo fazendo isso nas pr√≥ximas News.

At√© a pr√≥xima semana, quando algumas das previs√µes que compartilhei podem j√° ter se tornado realidade. üëÄ