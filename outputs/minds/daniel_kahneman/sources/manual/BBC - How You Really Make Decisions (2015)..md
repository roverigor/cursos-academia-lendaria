## Documentário BBC: How You Really Make Decisions

Nós gostamos de pensar que, como espécie, somos muito inteligentes. Gostamos de pensar que somos criaturas sábias, racionais. Eu acho que todos nós gostamos de pensar em nós mesmos como o Sr. Spock, até certo ponto. Você pode achar que todas as suas decisões são conscientes, mas talvez tenhamos que pensar novamente. É principalmente uma ilusão, e devemos simplesmente despertar para esse fato.

Em cada decisão que você toma, há uma batalha em sua mente entre a intuição e a lógica. É um conflito que se desenrola em todos os aspectos da sua vida: o que você come, no que você acredita, quem você ama e, mais poderosamente, nas decisões que você toma sobre dinheiro. No momento em que o dinheiro entra em cena, as regras mudam. Os cientistas agora têm uma nova maneira de entender essa batalha em sua mente, como ela molda as decisões que você toma, no que você acredita e como transformou nossa compreensão da própria natureza humana.

Sentado no banco de trás deste táxi em Nova York está o Professor Danny Kahneman. Ele é considerado um dos psicólogos mais influentes vivos hoje. Nos últimos 40 anos, ele desenvolveu _insights_ extraordinários sobre a forma como tomamos decisões. Eu acho que não faz mal ter uma visão realista da natureza humana e de como a mente funciona. Seus _insights_ vêm principalmente de enigmas.

Tomemos, por exemplo, o curioso enigma dos taxistas de Nova York e seus hábitos de trabalho altamente ilógicos. O movimento varia de acordo com o clima. Em dias de chuva, todos querem um táxi, mas em dias de sol, como hoje, as corridas são difíceis de encontrar. Logicamente, eles deveriam passar muito tempo dirigindo em dias de chuva, porque é muito fácil encontrar passageiros em dias de chuva. E se eles vão tirar um momento de lazer, deve ser em dias de sol. Mas acontece que não é isso que muitos deles fazem. Muitos fazem o oposto, trabalhando longas horas em dias lentos de sol e parando cedo quando está chuvoso e movimentado. Em vez de pensar logicamente, os taxistas são impulsionados por um desejo de ganhar uma quantia de dinheiro por dia, faça chuva ou faça sol. Assim que atingem essa meta, eles voltam para casa.

Eles veem ficar abaixo da meta como uma perda e ficar acima da meta como um ganho. E eles se importam mais em prevenir a perda do que em obter o ganho. Portanto, quando atingem sua meta em um dia chuvoso, eles param, o que realmente não faz sentido. Se estivessem tentando maximizar sua renda, eles deixariam seu lazer para os dias de sol e dirigiriam o dia todo nos dias de chuva.

Foi esse tipo de falha no raciocínio que Kahneman percebeu que poderia revelar algo profundo sobre o funcionamento interno da mente. E ele começou a criar uma série de enigmas e perguntas que se tornaram testes psicológicos clássicos. É um experimento simples, é um jogo muito atraente, então não há nada extenuante. Ele propõe problemas onde você pode reconhecer em si mesmo que sua intuição está indo para o lado errado. O tipo de enigma onde a resposta que intuitivamente vem à mente e que parece óbvia está, na verdade, errada.

Aqui está um que eu acho que funciona com quase todo mundo. Eu quero que você imagine um cara chamado Steve. Você diz às pessoas que Steve é uma alma dócil e organizada, com paixão por detalhes e muito pouco interesse em pessoas. Ele tem um bom olho para detalhes. E então você diz às pessoas que ele foi sorteado aleatoriamente em um censo da população americana. Qual é a probabilidade de ele ser um fazendeiro ou um bibliotecário? Você não acha que é mais provável que Steve tenha acabado trabalhando como bibliotecário ou fazendeiro? Ele parece mais provável de ser, bem, provavelmente um bibliotecário. A palavra "bibliotecário" salta imediatamente à mente, porque ele se assemelha ao protótipo de um bibliotecário. Na verdade, essa é provavelmente a resposta errada, porque, pelo menos nos Estados Unidos, existem 20 vezes mais fazendeiros homens do que bibliotecários homens. Então, provavelmente há mais almas dóceis e organizadas que são fazendeiros do que almas dóceis e organizadas que são bibliotecários.

Este tipo de enigma parecia revelar uma discrepância entre a intuição e a lógica. Outro exemplo é: imagine um dicionário. Eu vou tirar uma palavra ao acaso. Qual é mais provável que a palavra que você escolher aleatoriamente tenha a letra R na **primeira posição** ou tenha a letra R na **terceira posição**? As pessoas pensam na primeira posição, porque é mais fácil pensar em exemplos com R na primeira posição. Na verdade, há quase três vezes mais palavras com R como terceira letra do que palavras que começam com R. Mas não é isso que nossa intuição nos diz.

Esses eram os tipos de exemplos que tínhamos, muitos deles. O interesse de Kahneman no erro humano foi despertado pela primeira vez na década de 1970, quando ele e seu colega Amos Tversky começaram a analisar seus próprios erros. Estava tudo em nós mesmos, ou seja, todos os erros que estudamos eram erros que nós éramos propensos a cometer. Kahneman e Tversky encontraram um tesouro desses enigmas. Eles revelaram um catálogo de erros humanos e abriram uma caixa de Pandora de erros. Mas o que é realmente interessante sobre esses erros é que eles não são acidentais. Eles têm uma forma, uma estrutura, que distorce nosso julgamento. O que os torna interessantes é que não são erros aleatórios, são **vieses**. A diferença entre um viés e um erro aleatório é que **um viés é previsível**, é um erro sistemático que é previsível.

Os enigmas de Kahneman provocam a resposta errada de novo e de novo, o que é provavelmente mais provável. É um padrão de erro humano que afeta cada um de nós. Sozinhos, eles podem parecer pequenos, mas ao vasculhar nossos erros cotidianos, Kahneman iniciou uma revolução em nossa compreensão do pensamento humano. Uma revolução tão profunda e abrangente que ele foi agraciado com um Prêmio Nobel.

Durante anos, os psicólogos tentaram desmembrar os momentos em que as pessoas tomam decisões. Grande parte do foco tem sido em nossa mente racional, nossa capacidade de lógica. Mas Kahneman viu a mente de forma diferente. Ele viu um papel muito mais poderoso para o outro lado de nossas mentes: **a intuição**. E no cerne do pensamento humano, há um conflito entre lógica e intuição que leva a erros.

Kahneman e Tversky iniciaram essa tendência de ver a mente de forma diferente. Ilusões de tomada de decisão, são esses pontos onde nossas intuições simplesmente nos fazem decidir coisas que não fazem sentido. O trabalho de Kahneman e Tversky tem sido realmente revolucionário e desencadeou uma onda de experimentação e observação para entender o significado desses erros. As pessoas realmente não apreciavam, e há apenas 40 anos, que a mente realmente não funcionava como um computador. Pensávamos que éramos criaturas muito deliberativas e conscientes que pesavam os custos e benefícios da ação, assim como o Sr. Spock faria. Agora é um corpo de trabalho bastante coerente sobre os lugares onde a intuição se desvia das regras da lógica.

E o corpo de evidências está crescendo. Algumas das melhores pistas para o funcionamento de nossas mentes vêm não quando acertamos, mas quando erramos.

Em um canto deste campus, o Professor Chris Chabris está prestes a começar uma briga. É parte de um experimento que mostra um erro bastante chocante que qualquer um de nós poderia cometer. Um erro em que você não percebe o que está acontecendo bem na frente dos seus olhos. Além da briga, o experimento também envolve uma perseguição. Foi inspirado por um incidente em Boston em 1995, quando um jovem policial, Kenny Connelly, estava em perseguição de um suspeito de assassinato. Acontece que este policial, enquanto perseguia o suspeito, passou direto por outros policiais que estavam agredindo outro suspeito, o que, é claro, os policiais não devem fazer em nenhuma circunstância. Quando a polícia tentou investigar este caso de brutalidade policial, ele disse: "Eu não vi nada acontecendo lá. Tudo o que eu vi foi o suspeito que eu estava perseguindo." E ninguém conseguia acreditar nisso. E ele foi processado por perjúrio e obstrução da justiça. Todos estavam convencidos de que Connelly estava mentindo. Todos, exceto Chris Chabris. Ele se perguntou se nossa capacidade de prestar atenção é tão limitada que qualquer um de nós poderia passar por uma briga violenta sem sequer notar. E é algo que ele está colocando à prova.

No experimento, os sujeitos são convidados a se concentrar cuidadosamente em uma tarefa cognitiva. Eles devem contar o número de vezes que o corredor bate na cabeça com cada mão. Será que eles, como o policial de Boston, ficarão tão cegos por sua atenção limitada que falharão completamente em notar a briga? 45 segundos ou um minuto após o início da corrida, houve a briga. E eles podiam realmente ver a briga de longe, e ela estava a cerca de 6 metros de distância deles quando se aproximaram mais. A briga está bem no campo de visão deles, e pelo menos parcialmente visível desde a passarela. Parece inacreditável que alguém não notasse algo tão aparentemente óbvio.

Eles completaram o percurso de 3 minutos e então dissemos: "Você notou algo incomum?" Às vezes, eles teriam notado a briga. Eles diriam: "Sim, eu vi alguns caras brigando." Mas uma grande porcentagem de pessoas disse: "Não vimos nada de incomum." E quando perguntamos especificamente se eles viram alguém brigando, eles ainda disseram não. Na verdade, quase **50% das pessoas no experimento falharam completamente em notar a briga**.

Nós fizemos isso à noite, fizemos à luz do dia. Mesmo quando fizemos à luz do dia, muitas pessoas correram pela briga e não a notaram.

O que aconteceu com Connelly foi que, quando você está realmente prestando atenção em uma coisa e focando muita energia mental nela, você pode perder coisas que outras pessoas vão achar completamente óbvias. E, de fato, foi o que os jurados disseram após o julgamento de Connelly. Eles disseram: "Não podíamos acreditar que ele poderia perder algo assim. Não fazia sentido. Ele tinha que estar mentindo."

É um fenômeno perturbador chamado **cegueira por desatenção** (_inattentional blindness_) que pode nos afetar a todos. Algumas pessoas disseram coisas como: "Isso abala minha fé na minha própria mente", ou "Agora eu não sei no que acreditar", ou "Eu vou ficar confuso de agora em diante". Mas não tenho certeza se esse sentimento realmente permanece com elas por muito tempo. Elas vão sair do experimento, caminhar até o próximo lugar que vão, ou algo assim, e vão ter tanta cegueira por desatenção quando estiverem andando na rua naquela tarde quanto tinham antes.

Este experimento revela um dilema poderoso sobre nossas mentes. Nós deslizamos pelo mundo, felizmente inconscientes da maioria do que fazemos e do pouco que realmente sabemos. Nossas mentes, apesar de toda a sua genialidade, a parte de nossa mente que chamamos de nós mesmos é extremamente limitada.

Então, como conseguimos navegar pela complexidade da vida diária?

Todos os dias, cada um de nós toma algo entre dois e dez mil decisões. Quando você pensa em nossa vida diária, é realmente uma longa sequência de decisões. Tomamos decisões provavelmente em uma frequência que está próxima da frequência com que respiramos. A cada minuto, a cada segundo, você está decidindo onde mover suas pernas, onde mover seus olhos e onde mover seus membros. E quando você está comendo, você está tomando todo tipo de decisões. E, no entanto, a vasta maioria dessas decisões nós tomamos sem sequer perceber.

Foi o _insight_ de Danny Kahneman que temos **dois sistemas na mente** para tomar decisões. Duas maneiras de pensar: **rápido e lento**. Duas maneiras de operar: uma é o pensamento rápido, um modo automático e sem esforço. E esse é o que estamos na maior parte do tempo.

Este modo automático e rápido de pensar ele chamou de **Sistema 1**. É poderoso, sem esforço e responsável pela maior parte do que fazemos. O Sistema 1 é o que acontece na maior parte do tempo. O mundo ao seu redor fornece todos os tipos de estímulos e você responde a eles. Tudo o que você vê e que você entende: "Isto é uma árvore", "Aquilo é um helicóptero lá atrás", "Aquilo é a Estátua da Liberdade". Toda essa percepção visual vem do Sistema 1.

O outro modo é lento, deliberativo, lógico e racional. Este é o **Sistema 2**, e é a parte que você pensa ser você, a voz na sua cabeça.

O primeiro exemplo dos dois sistemas é realmente o 2+2 de um lado e 17×24 do outro. O que é 2+2? **4**. Rápido, Sistema 1, está sempre engrenado, produzindo respostas instantâneas. O que é 2+2? **4**. O número vem à sua mente. É automático. Você não pretende que isso aconteça. Apenas acontece com você. É quase como um reflexo.

Mas quando temos que prestar atenção a um problema complicado, engajamos o Sistema 2, que é lento, mas lógico. Se você consegue fazer isso de cabeça, você terá que seguir as regras e fazer isso sequencialmente. E isso não é automático de forma alguma. Isso envolve **trabalho**. Envolve **esforço**. Envolve **concentração**. 22×17. Haverá sintomas fisiológicos. Sua frequência cardíaca irá acelerar. Suas pupilas irão dilatar. Muitas mudanças ocorrerão enquanto você estiver realizando esta computação.

O Sistema 2 pode ser inteligente, mas também é lento, limitado e **preguiçoso**. Se eu andar muito rápido, eu não consigo pensar. [Experimento de contar para trás de 100 por 7]. Isso exige, curiosamente, o mesmo tipo de função executiva que o pensamento. Se você é esperado para fazer algo que exige muito esforço, você vai parar até de andar.

Tudo o que você está ciente em sua própria mente é parte deste sistema lento e deliberativo, o Sistema 2. No que lhe diz respeito, ele é a estrela do _show_. Na verdade, o Sistema 2 é o outro ator. Eu o descrevo como um personagem menor que pensa que é a estrela, porque, na verdade, a maior parte do que acontece em nossa mente é **automático**, está no domínio que eles chamam de Sistema 1. O Sistema 1 é um pedaço, um pedacinho, de um cérebro antigo. E é notável. Não conseguiríamos sobreviver sem ele, porque o Sistema 2 **explodiria** se o Sr. Spock tivesse que tomar todas as decisões por nós. Seria muito lento e exigente, e nossas cabeças explodiriam.

E este vasto domínio oculto é responsável por muito mais do que você possivelmente acreditaria. Ter uma opinião. Você tem uma opinião imediatamente. Se você gosta ou não, se você é a favor de algo ou não, gostar de alguém... muitas vezes é algo sobre o qual você não tem controle. Mais tarde, quando lhe são pedidas razões, você inventa razões. E muito do que o Sistema 2 faz é fornecer razões, fornece **racionalizações** que não são necessariamente as verdadeiras razões para nossas crenças, nossas emoções e nossas intenções, e para o que fazemos.

Você tem dois sistemas de pensamento que o guiam pela vida: o rápido e intuitivo **Sistema 1** que é incrivelmente poderoso e faz a maior parte da condução, e o lento e lógico **Sistema 2** que é inteligente, mas um pouco preguiçoso. O problema é que há uma pequena batalha entre eles sobre qual está conduzindo suas decisões.

É aqui que os erros se infiltram: quando usamos o sistema errado para tomar uma decisão.

As pessoas pensam que estão prestes a usar o Sistema 2, lento e sensato, para tomar uma decisão racional sobre quanto pagariam por uma garrafa de champanhe. Mas o que elas não sabem é que a decisão delas será tomada totalmente sem o conhecimento delas, pelo seu piloto automático rápido e oculto, o **Sistema 1**.

E com a ajuda de um saco de bolinhas de pingue-pongue, podemos influenciar essa decisão. [Experimento da Âncora]. Primeiro, eles têm que escolher uma bola. O número diz 10. Eles pensam que é um número aleatório, mas na verdade, está manipulado. Todas as bolas estão marcadas com o número baixo 10. Este experimento é sobre a criação irrefletida de hábitos. É sobre como tomamos uma decisão e depois outras decisões a seguem, como se a primeira decisão fosse realmente significativa. O que fazemos de propósito é dar às pessoas uma primeira decisão que é claramente sem sentido. "Você estaria disposto a pagar 10 libras por esta boa garrafa de champanhe vintage?" "Eu estaria."

Esta primeira decisão é sem sentido, baseada em um número aparentemente aleatório. Mas o que ela faz é alojar o número baixo 10 na cabeça deles. Agora, a pergunta real, onde perguntamos a eles quanto eles realmente pagariam pelo champanhe: "Qual é a quantia máxima que você acha que estaria disposto a pagar?" O resultado é uma gama de ofertas bastante baixas.

Mas o que acontece se nós **prepararmos** (_prime_) as pessoas com um número muito mais alto, 65 em vez de 10? Qual é o máximo que você estaria disposto a pagar por esta garrafa de champanhe? [Respostas: 40, 45, 50].

A lógica desapareceu. O preço que as pessoas estão dispostas a pagar é influenciado por nada mais do que um número escrito em uma bola de pingue-pongue. Isso sugere que, quando chegamos a tomar decisões, **não avaliamos a decisão em si**. Em vez disso, o que fazemos é tentar olhar para outras decisões semelhantes que tomamos no passado, e tomamos essas decisões como se fossem boas decisões, e dizemos a nós mesmos: "Ah, eu já tomei essa decisão antes. Claramente, eu não preciso ir lá e resolver esta decisão. Deixe-me apenas usar o que eu fiz antes e repeti-lo, talvez com algumas modificações."

Este **efeito de ancoragem** vem do conflito entre nossos dois sistemas de pensamento. O Sistema 1 rápido é um mestre em pegar atalhos para produzir a decisão mais rápida possível. Se você faz uma pergunta, e a pergunta é difícil, mas há uma pergunta relacionada que é um pouco mais simples, você simplesmente vai responder à outra pergunta e nem mesmo perceber. Então, o sistema faz todos os tipos de atalhos para nos fornecer a informação de uma maneira mais rápida. Podemos tomar decisões, e o sistema está aceitando alguns erros.

Nós tomamos decisões usando o Sistema 1 rápido quando realmente deveríamos estar usando o Sistema 2 lento, e é por isso que cometemos os erros que cometemos, **erros sistemáticos conhecidos como vieses cognitivos**.

Desde que Kahneman começou a investigar as falhas em nosso pensamento, mais de **150 vieses cognitivos** foram identificados. Estamos repletos desses erros sistemáticos, e eles afetam todos os aspectos de nossas vidas diárias. A Wikipédia tem uma lista muito grande de vieses, e estamos encontrando novos o tempo todo.

Um dos vieses que eu acho que é o mais importante é o chamado **viés do presente** (_present bias_), o fato de que nos concentramos no **agora** e não pensamos muito no futuro. É o viés que causa coisas como excessos na alimentação, tabagismo, enviar mensagens de texto ao dirigir e sexo desprotegido.

Outro é chamado de **efeito halo**, e esta é a ideia de que, se você gosta de alguém ou de uma organização, você é levado a pensar que **todos os seus aspectos são bons**. Se você não gosta, tudo é ruim. As pessoas ficam bastante desconfortáveis com a ideia de que Hitler amava crianças. Ele amava. Isso não o torna uma boa pessoa, mas nos sentimos desconfortáveis em ver uma característica atraente em uma pessoa que consideramos má. Somos propensos a pensar que o que gostamos é totalmente bom e o que não gostamos é totalmente ruim. Isso é um viés.

Outro favorito particular meu é o viés de se **apegar a coisas que nós mesmos criamos**. Nós o chamamos de **efeito IKEA**. Você tem **aversão à perda** (_loss aversion_) e **aversão ao risco** (_risk aversion_), viés do presente, **efeito holofote** (_spotlight effect_), e o efeito holofote é a ideia de que pensamos que outras pessoas nos dão muita atenção quando na verdade não dão. Viés de confirmação, superconfiança, é um grande. Mas o que está claro é que existem muitos deles. Existem muitas maneiras de errarmos. É uma maneira de fazer as coisas certas e muitas maneiras de fazer as coisas erradas, e somos capazes de muitas delas.

Esses vieses explicam tantas coisas que fazemos errado: nossos gastos impulsivos, confiar nas pessoas erradas, não ver o ponto de vista da outra pessoa, sucumbir à tentação. Estamos tão repletos desses vieses que é difícil acreditar que algum dia tomemos uma decisão racional.

Mas não são apenas nossas decisões cotidianas que são afetadas. O que acontece se você é um especialista treinado em tomar decisões que são uma questão de vida ou morte? Você ainda está destinado a cometer esses erros sistemáticos?

Nos arredores de Washington D.C., a Horizon obteve acesso para espionar os espiões. Bem-vindos ao exercício analítico número quatro. O ex-analista de inteligência Donald Kretz está executando um jogo de espionagem ultra-realista. Este exercício ocorrerá em uma cidade fictícia de Vastopolis. Participam uma mistura de analistas de inteligência treinados e alguns novatos. Devido a uma ameaça emergente, uma Força-Tarefa de Terrorismo foi montada. Eu serei o líder da Força-Tarefa de Terrorismo e recrutei todos vocês para serem nossos analistas de terrorismo. O desafio que os analistas enfrentam é frustrar uma ameaça terrorista contra uma cidade dos EUA. A ameaça neste momento não foi determinada. Cabe a você descobrir o tipo de terrorismo e quem é o responsável por planejar isso.

Os analistas enfrentam várias tarefas. Eles devem primeiro investigar quaisquer grupos que possam representar uma ameaça. A tarefa deles é escrever um relatório. O assunto neste caso é o **Network of Dread**. O prefeito pediu isso em 15 minutos a partir de agora. Assim como no mundo real, os analistas têm acesso a uma enorme quantidade de dados que chegam de agências governamentais, mídias sociais, telefones celulares e serviços de emergência.

O Network of Dread acaba por ser um conhecido grupo terrorista internacional. Eles têm um histórico, a capacidade e o pessoal para realizar um ataque. Um cenário que está surgindo é um evento de bioterrorismo, o que significa que é um ataque de terrorismo biológico que ocorrerá contra a cidade. Se houver uma ameaça emergente, eles são o candidato provável. Então você passa para a próxima tarefa.

Agora é 9 de abril. Este é outro pedido de informação, desta vez sobre algo ou alguém chamado **Masters of Chaos**. Os Masters of Chaos são um grupo de _cyber hackers_, um bando local de desajustados sem histórico de violência.

E enquanto os analistas continuam a vasculhar os dados recebidos, nos bastidores, Kretz está monitorando cada movimento deles. Nesta sala, podemos monitorar o que os analistas estão fazendo durante todo o exercício. Montamos uma base de conhecimento na qual inserimos dados ao longo do dia. Alguns deles estão relacionados à nossa ameaça terrorista. Muitos deles não estão. Em meio à riqueza de dados sobre o conhecido grupo terrorista, o Network of Dread, também estão chegando evidências de um roubo em um laboratório de biologia universitário e de alguém que hackeou os computadores de uma empresa de frete local. Cada uma dessas mensagens representa essencialmente uma peça do quebra-cabeça, mas é um quebra-cabeça do qual você não tem a tampa da caixa, então você não tem a imagem com antecedência. Além disso, o que temos é um monte de peças de quebra-cabeça que nem sequer pertencem a este quebra-cabeça.

O exercício faz parte de uma série de experimentos para investigar se agentes de inteligência especializados são tão propensos a erros de viés cognitivo quanto o resto de nós, ou se seu treinamento e _expertise_ os tornam imunes. Eu tenho uma espécie de ponto de vista interno sobre este problema. Trabalhei vários anos como analista de inteligência. As apostas são incrivelmente altas. Erros podem ser muitas vezes uma questão de vida ou morte.

Avançamos agora. A data é 21 de maio. Se os analistas conseguirem pensar racionalmente, eles devem ser capazes de resolver o enigma. Mas o perigo é que eles cairão na armadilha montada por Kretz e prestarão atenção apenas ao grupo terrorista estabelecido, o Network of Dread. O julgamento deles pode ser nublado por um viés chamado **viés de confirmação** (_confirmation bias_). O viés de confirmação é o viés mais prevalente de todos, e é onde tendemos a procurar informações que apoiem o que já acreditamos. O viés de confirmação pode facilmente levar as pessoas a ignorar as evidências bem na frente dos seus olhos.

E Kretz é capaz de monitorar se o viés entra em ação. "Ainda vemos que eles estão procurando por Network of Dread. Isso é uma indicação de que podemos ter um viés de confirmação operando."

O Network of Dread é o grupo grande. Eles fizeram isso antes, então você esperaria que eles fizessem de novo. E eu acho que estamos começando a ver alguns vieses aqui. Os analistas querem desesperadamente chegar à resposta correta, mas são afetados pelos mesmos vieses que o resto de nós. Até agora, a maioria dos nossos analistas parece acreditar que o Network of Dread é responsável por planejar este ataque. E isso está completamente errado.

É hora de os analistas se colocarem em risco e decidirem quem são os terroristas e o que eles estão planejando. Eles sabem que o Network of Dread é um grupo terrorista. Eles sabem que o Masters of Chaos é um grupo de _cyber hacking_. O ataque é na fábrica ou no abastecimento de água. A questão é: algum dos analistas conseguiu desenterrar as pistas relevantes e encontrar a verdadeira ameaça?

Neste caso, a ameaça real é devido ao grupo cibernético, os Masters of Chaos, que se tornam cada vez mais radicalizados ao longo do cenário e decidem descontar sua raiva na sociedade. Eles foram convencidos a mudar de crime cibernético para terrorismo biológico. Eles sucumbirão ao viés de confirmação e simplesmente culparão os suspeitos habituais? Eles farão essa conexão? Eles processarão essa evidência e a avaliarão de acordo? Ou o viés de confirmação os levará a acreditar que é um tipo de grupo terrorista mais tradicional?

"Eu acredito que os Masters of Chaos são, na verdade, os responsáveis." "É uma ameaça interna." "E o tempo acabou. Por favor, salvem esses relatórios."

No final do exercício, Kretz revela a verdadeira identidade dos terroristas. "Temos uma mensagem prioritária da Prefeitura. O ataque terrorista foi frustrado. O ataque bioterrorista planejado pelos Masters of Chaos contra Vastopolis foi frustrado. O prefeito expressa seus agradecimentos por um trabalho bem feito."

De 12 sujeitos, **11 deles deram a resposta errada**. A única pessoa a identificar a verdadeira ameaça foi, na verdade, uma **novata**. Todos os especialistas treinados caíram no viés de confirmação.

Não é tipicamente o caso que simplesmente ser treinado como analista lhe dê as ferramentas necessárias para superar o viés cognitivo. Você pode aprender técnicas para melhorar a memória. Você pode aprender técnicas para focar melhor. Mas técnicas para eliminar o viés cognitivo simplesmente não funcionam. E para analistas de inteligência no mundo real, as implicações de cometer erros a partir desses vieses são drásticas.

Relatórios e estudos governamentais ao longo da última década citaram especialistas que acreditam que o viés cognitivo pode ter desempenhado um papel em várias falhas de inteligência muito significativas. E, no entanto, continua sendo um problema pouco estudado.

Mas a área de nossas vidas em que esses erros sistemáticos têm o impacto mais explosivo é no mundo do **dinheiro**. No momento em que o dinheiro entra em cena, as regras mudam. Muitos de nós pensamos que estamos no nosso estado mais racional quando se trata de decisões sobre dinheiro. Gostamos de pensar que sabemos como identificar uma pechincha, fazer um bom negócio, vender nossa casa na hora certa, investir com sabedoria. Pensar sobre dinheiro da maneira certa é uma das coisas mais desafiadoras para a natureza humana. Mas se não somos tão racionais quanto gostamos de pensar e há uma força oculta em ação moldando nossas decisões, estamos nos iludindo?

O dinheiro traz consigo um modo de pensar. Ele mudou a forma como reagimos ao mundo. Quando se trata de dinheiro, os vieses cognitivos causam estragos nas nossas melhores intenções. Há muitos erros que as pessoas cometem quando se trata de dinheiro.

O _insight_ de Kahneman sobre nossos erros com dinheiro iria revolucionar nossa compreensão da economia. É tudo sobre uma diferença crucial em como nos sentimos quando ganhamos ou perdemos, e nossa prontidão para assumir um risco. Nossa disposição para assumir uma aposta é muito diferente, dependendo se estamos enfrentando uma perda ou um ganho.

[Experimento de Ganho vs. Perda]. Aqui estão dois cenários. No primeiro caso, você recebe 10 libras que não são suas. Então você tem que fazer uma escolha sobre quanto mais você poderia ganhar. Você pode escolher uma opção segura, caso em que eu lhe darei 5 adicionais, ou você pode assumir um risco. Eu vou jogar esta moeda. Se der cara, você ganha 10. Mas se der coroa, você não ganha mais nada. Você escolheria a opção segura e ganharia 5 libras extras, ou assumiria um risco e talvez ganhasse 10 extras ou nada? A maioria das pessoas, confrontada com esta escolha, opta pela certeza das 5 extras. Em um quadro mental de ganho, as pessoas são naturalmente bastante **cautelosas**.

Mas e quanto a perder? Somos igualmente cautelosos quando confrontados com uma perda potencial? [Segundo Cenário]. Desta vez, você recebe 20 libras, e novamente você deve fazer uma escolha. Você escolheria aceitar uma **perda segura de 5 libras** ou assumiria um **risco**? Eu vou jogar esta moeda. Se der cara, você não perde nada, mas se der coroa, você perde 10 libras. Na verdade, o resultado é exatamente o mesmo em ambos os casos. Você enfrenta uma escolha entre terminar com 15 libras certas ou jogar uma moeda para obter 10 ou 20.

Mas a surpresa crucial aqui é que, quando a escolha é enquadrada em termos de **perda**, a maioria das pessoas **assume um risco**. Nosso Sistema 2 lento provavelmente poderia descobrir que o resultado é o mesmo em ambos os casos, mas é muito limitado e muito preguiçoso. Em vez disso, o Sistema 1 rápido faz uma estimativa aproximada baseada na mudança. E o Sistema 1 não gosta de perder.

Se você perdesse 10 libras na rua hoje e depois encontrasse 10 libras amanhã, você estaria financeiramente inalterado. Mas, na verdade, nós reagimos às mudanças. Então, a dor da perda de 10 libras é muito maior. Dói mais. Na verdade, você provavelmente teria que encontrar 20 libras para compensar a dor que sente ao perder 10. No cerne disso está um viés chamado **aversão à perda** (_loss aversion_), que afeta muitas de nossas decisões financeiras. As pessoas pensam em termos de ganhos e perdas e, no pensamento delas, tipicamente, as **perdas são mais significativas do que os ganhos**. Temos até uma ideia de por quanto. Cerca de um **fator de dois**, ou um pouco mais do que dois.

Essa é uma _insight_ vital sobre o comportamento humano. Tão importante que levou a um Prêmio Nobel e à fundação de um novo ramo da economia. Quando pensamos que estamos ganhando, não assumimos riscos. Mas quando somos confrontados com uma perda, francamente, somos um pouco **imprudentes**.

Mas a aversão à perda não afeta apenas as pessoas que fazem apostas casuais de 5 libras. Ela pode afetar qualquer pessoa a qualquer momento, incluindo aqueles que trabalham no complexo sistema de altas finanças, no qual trilhões de dólares são negociados. Em nosso ambiente complexo atual, agora temos os meios, bem como o motivo, para cometer erros muito sérios.

O alicerce da economia é que as pessoas pensam racionalmente. Elas calculam riscos, recompensas e decidem de acordo. Mas nem sempre somos racionais. Raramente nos comportamos como o Sr. Spock. Na maioria de nossas decisões, usamos o Sistema 1 rápido, intuitivo, mas ocasionalmente não confiável. E em um mercado financeiro global, isso pode levar a problemas muito sérios. Eu acho que o que a crise financeira fez foi simplesmente dizer: "Sabe, as pessoas são muito mais vulneráveis a armadilhas psicológicas do que realmente entendíamos antes." Basicamente, a psicologia humana é muito falha para esperar que pudéssemos evitar uma crise.

Compreender essas armadilhas levou a um novo ramo da economia: a **Economia Comportamental**. Graças a psicólogos como Richard Thaler, ela está começando a se estabelecer em Wall Street. Ela leva em conta a maneira como realmente tomamos decisões, em vez de como dizemos que as tomamos. A crise financeira, eu acho, foi um problema tão grande quanto foi porque certos traços psicológicos, como otimismo, superconfiança e viés de confirmação, desempenharam um papel muito grande em uma parte da economia onde erros graves poderiam ser cometidos.

Mas enquanto nosso sistema financeiro presumir que somos racionais, nossa economia permanecerá vulnerável. Estou bastante certo de que, se os reguladores tivessem ouvido os economistas comportamentais mais cedo, teríamos projetado um sistema financeiro muito diferente, e não teríamos tido o incrível aumento no mercado imobiliário e não teríamos tido esta catástrofe financeira. E assim, quando Kahneman recebeu seu Prêmio Nobel, não foi por psicologia, foi por **economia**.

A grande questão é: o que podemos fazer sobre esses erros sistemáticos? Podemos esperar encontrar uma maneira de contornar nossos vieses de pensamento rápido e tomar melhores decisões? Para responder a isso, precisamos saber as origens evolutivas de nossos erros.

Perto da costa de Porto Rico é provavelmente o melhor lugar do mundo para descobrir. A pequena ilha de **Cayo Santiago**. Estamos agora no barco indo para Cayo Santiago. Esta é uma ilha cheia de mil **macacos _rhesus_**. Quando você chega, parece um pouco que você está indo para o _Jurassic Park_. Você não tem certeza do que vai ver. Você verá seu primeiro macaco, e estará confortável. É uma ilha dedicada à pesquisa com macacos.

A coisa realmente especial sobre Cayo Santiago é que os animais aqui, porque cresceram nos últimos sete anos perto de humanos, eles estão completamente **habituados**. E isso significa que podemos chegar perto deles e mostrar-lhes coisas, e ver como eles tomam decisões. Podemos fazer isso aqui de uma forma que nunca poderíamos fazer em qualquer outro lugar. É realmente único.

Laurie Santos está aqui para descobrir se os macacos cometem os mesmos erros em suas decisões que nós cometemos. A maior parte do trabalho que fazemos é comparar humanos e outros primatas, tentando perguntar: o que é especial nos humanos? Nós realmente queremos entender qual é a origem evolutiva de algumas de nossas estratégias mais estúpidas, alguns dos pontos onde erramos. Se pudermos entender de onde vieram, é aí que obteremos alguma _insight_.

Se Santos puder nos mostrar que os macacos têm os mesmos vieses cognitivos que nós, isso sugeriria que eles evoluíram há muito tempo. Uma estratégia mental tão antiga seria quase impossível de mudar. Começamos este trabalho na época do colapso financeiro. Então, quando estávamos pensando em quais estratégias estúpidas poderíamos procurar em macacos, era bastante óbvio que algumas das estratégias econômicas humanas que estavam nas notícias poderiam ser a primeira coisa a procurar. E uma das coisas em particular que queríamos examinar era se os macacos tinham **aversão à perda**.

Mas os macacos, por mais inteligentes que sejam, ainda não começaram a usar dinheiro. E foi aí que começamos. Dissemos: "Bem, como podemos sequer fazer esta pergunta se os macacos cometem erros financeiros?" E então decidimos fazê-lo introduzindo os macacos à sua própria nova moeda, e apenas deixá-los comprar sua comida.

De volta ao seu laboratório em Yale, ela apresentou a um grupo de macacos seu próprio mercado, dando-lhes fichas redondas e brilhantes que eles podiam trocar por comida. Uma das primeiras coisas que nos perguntamos foi se eles entenderam que uma loja diferente vendia comida diferente a preços diferentes. O que descobrimos é que, neste caso, os macacos são bastante **racionais**. Então, quando eles têm a escolha de um cara que vende 3 bens por uma ficha, eles realmente compram mais daquele cara.

Tendo ensinado aos macacos o valor do dinheiro, o próximo passo foi ver se os macacos, como os humanos, sofrem daquele viés mais crucial, a aversão à perda. Então, o que fizemos foi introduzir os macacos a comerciantes que davam perdas ou ganhos em relação ao que mostravam. Eu poderia fazer o macaco pensar que ele está recebendo um bônus simplesmente fazendo-o negociar com um comerciante que começa com uma única uva, mas então, quando o macaco paga, este comerciante realmente lhe dá uma uva extra. Então, ela lhe dá um **bônus**, e o macaco recebe duas, mas ele pensa que recebeu a segunda como um bônus.

Podemos então comparar o que os macacos fazem com aquele cara versus um cara que dá perdas aos macacos. Este é um cara que finge que vai vender três uvas, mas então, quando o macaco realmente paga, ele tira uma das uvas e dá ao macaco apenas duas.

A grande questão então é como os macacos reagem quando confrontados com uma escolha entre a perda e o ganho. Ela já se encontrou com esses dois caras antes. Você pode ver que ela escolhe a opção de **bônus**, até espera pacientemente por seu pedaço adicional a ser adicionado aqui, e então pega o bônus, evitando a pessoa que lhe dá perdas.

Então, **os macacos odeiam perder tanto quanto as pessoas**.

E, crucialmente, Santos descobriu que os macacos também são **mais propensos a assumir riscos** quando confrontados com uma **perda**. Isso sugere que os macacos enquadram suas decisões exatamente da mesma forma que nós. Eles não estão pensando apenas no absoluto. Eles estão pensando em relação ao que esperam. E quando estão recebendo menos do que esperam, quando estão recebendo perdas, eles se tornam mais **buscadores de risco** (_risk seeking_).

O fato de compartilharmos este viés com esses macacos sugere que é uma **estratégia antiga**, gravada em nosso DNA há mais de **35 milhões de anos**. E o que aprendemos com os macacos é que, se este viés é realmente tão antigo, se realmente tivemos esta estratégia pelos últimos 35 milhões de anos, simplesmente decidir superá-lo **simplesmente não vai funcionar**. Precisamos de maneiras melhores de nos fazer evitar algumas dessas armadilhas. Cometer erros, ao que parece, é apenas parte do que é ser humano.

Estamos presos ao nosso **"estranho interior"** intuitivo. O desafio que isso representa é profundo. Se é da natureza humana cometer esses erros previsíveis e não podemos mudar isso, o que podemos fazer então?

Precisamos nos aceitar como somos. A coisa legal sobre ser um humano versus um macaco é que temos um **"self" deliberativo** que pode refletir sobre nossos vieses. O Sistema 2 em nós percebeu pela primeira vez que existe um Sistema 1. E com essa percepção, podemos moldar a forma como estabelecemos políticas. Podemos moldar a forma como estabelecemos situações para permitir que nós mesmos tomemos melhores decisões. Esta é a primeira vez na evolução que isso acontece.

Se queremos evitar erros, temos que **remodelar o ambiente** que construímos ao nosso redor, em vez de esperar mudar a nós mesmos.

Alcançamos muito, apesar de todos esses vieses. Se estivermos cientes deles, provavelmente podemos fazer coisas como projetar nossas instituições, nossos regulamentos e nossos próprios ambientes pessoais e vidas profissionais para **minimizar o efeito desses vieses** e nos ajudar a pensar em como superá-los.

Somos limitados, não somos perfeitos, somos irracionais em todos os tipos de maneiras, mas podemos construir o mundo que é compatível com isso e nos levar a tomar melhores decisões em vez de piores decisões.

Ao aceitar nosso "estranho interior", podemos chegar a uma melhor compreensão de nossas próprias mentes. Eu acho que é importante em geral estar ciente de onde as crenças vêm. Se pensamos que temos razões para o que acreditamos, isso é frequentemente um erro. Nossas crenças, e nossos desejos e nossas esperanças, nem sempre estão **ancorados em razões**. Eles estão ancorados em outra coisa que vem de dentro e é diferente.