# Lesson 1.1: O Mesmo Prompt, 4 C√©rebros Diferentes

**M√≥dulo:** 1 - O TESTE DE REALIDADE
**Dura√ß√£o:** 30 minutos
**Tipo:** Hands-on (laborat√≥rio pr√°tico)
**N√≠vel:** Fundamento 1 - Iniciante

---

## ‚ö†Ô∏è AVISO IMPORTANTE ANTES DE COME√áAR

> **Rafael, leia isso com aten√ß√£o:**
>
> Esta aula usa modelos e pre√ßos de **outubro 2025** como exemplos (GPT-5, Claude Sonnet 4.5, Gemini 2.0, DeepSeek V3).
>
> **Mas olha s√≥... no mundo de IA, isso aqui muda R√ÅPIDO.**
>
> Semana que vem pode lan√ßar modelo novo. M√™s que vem pre√ßos podem cair. Ano que vem pode surgir modelo que ningu√©m imaginava.
>
> **Ent√£o por que voc√™ t√° aprendendo isso?**
>
> Porque **a L√ìGICA √© a mesma**:
> - Escolher modelo certo pra tarefa certa
> - Calcular custo √ó performance
> - Justificar escolha pro cliente
>
> **O que muda:** Nomes, pre√ßos, n√∫meros
>
> **O que N√ÉO muda:** Como voc√™ pensa, decide, precifica
>
> Use os exemplos como REFER√äNCIA de racioc√≠nio. Quando aplicar com clientes reais, **sempre confira pre√ßos atualizados** em `resources/tabela-comparativa-llms-2025.md`

---

## üéØ O QUE VOC√ä VAI DESCOBRIR

Olha s√≥... voc√™ j√° passou por isso:

Voc√™ escreve um prompt **PERFEITO** no ChatGPT. Funciona lindamente. A√≠ voc√™ copia o mesmo prompt pro Gemini.

**E ele faz uma merda completamente diferente.**

Voc√™ n√£o entende. Voc√™ fica irritado. Voc√™ pensa: "mas √© o MESMO PROMPT, caramba!"

E a√≠ que t√°...

**N√£o √© o prompt que t√° errado. √â que voc√™ t√° usando o C√âREBRO errado pra tarefa errada.**

---

## üî• PROBLEMA REAL DO CLIENTE

> **Rafael (cliente real da Ag√™ncia Lend√°ria):**
>
> "Jos√©, constru√≠ um agente de agendamento. Testei com GPT-4, funciona 100%. Mas o cliente disse que t√° caro demais ‚Äî R$ 1.500/m√™s s√≥ de API. Mudei pro Gemini pra reduzir custo. Sabe o que aconteceu?"
>
> **"Ele come√ßou a INVENTAR hor√°rios que n√£o existem na agenda."**
>
> "Marcou reuni√£o pra pessoa √†s 14h quando a agenda dizia que tinha compromisso nesse hor√°rio. Cliente perdeu uma reuni√£o importante. Cancelou o projeto."
>
> "Qual foi meu erro?"

---

## üí° A REVELA√á√ÉO QUE MUDA TUDO

Vem comigo...

Imagina que voc√™ √© um t√©cnico de futebol. Voc√™ tem 4 jogadores:

- **Neymar** (Claude): G√™nio criativo, caro, faz milagres mas precisa de sal√°rio alto
- **Casemiro** (GPT5): Estrat√©gico, disciplinado, bom custo-benef√≠cio
- **Promessa da base** (Gemini): Muito barato, r√°pido, mas erra em momentos de press√£o
- **M√°quina** (DeepSeek): Eficiente, direto, mas trava em situa√ß√µes complexas

**Voc√™ N√ÉO escala os 4 pra mesma posi√ß√£o.**

Voc√™ n√£o coloca Casemiro de atacante. Voc√™ n√£o coloca Neymar de zagueiro.

**Cada um tem um PAPEL espec√≠fico baseado em suas caracter√≠sticas.**

E a√≠ que t√° o pulo do gato: **LLMs tamb√©m.**

---

## üß† FUNDAMENTO CONCEITUAL

### Por Que LLMs Diferentes Respondem Diferente ao Mesmo Prompt?

Vamos ao rigor t√©cnico (sem perder o did√°tico):

**1. Arquitetura de Treinamento Diferente** *(Out 2025)*
- **GPT-5:** Treinado com foco em **racioc√≠nio multimodal** e **precis√£o factual** (texto + imagem + √°udio)
- **Gemini 2.0:** Treinado com foco em **velocidade extrema** e **multimodalidade nativa** (v√≠deo inclu√≠do)
- **Claude Sonnet 4.5:** Treinado com foco em **√©tica** e **seguir instru√ß√µes √† risca** (Constitutional AI v4)
- **DeepSeek V3:** Treinado com foco em **efici√™ncia computacional** (MoE - Mixture of Experts)

**2. Dados de Treinamento Diferentes**
- **GPT-5:** Dataset massivo at√© abril 2025, curadoria OpenAI (qualidade premium, vi√©s OpenAI)
- **Gemini 2.0:** Dataset Google at√© setembro 2025 (web inteira + YouTube + Google Scholar)
- **Claude Sonnet 4.5:** Dataset Anthropic at√© agosto 2025 (curadoria √©tica rigorosa)
- **DeepSeek V3:** Dataset open source at√© julho 2025 (comunidade t√©cnica global)

**3. Tokens e Contexto** *(Capacidades out 2025)*
- **GPT-5:** 128k tokens (~96 mil palavras de contexto)
- **Gemini 2.0 Flash:** 1M tokens (~750 mil palavras - CONTEXTO MASSIVO)
- **Claude Sonnet 4.5:** 200k tokens (~150 mil palavras)
- **DeepSeek V3:** 64k tokens (~48 mil palavras)

**Traduzindo:**

Imagine que voc√™ pede pra 4 pessoas resumirem um livro de 500 p√°ginas:

- **GPT-4** l√™ tudo, anota tudo, resume com precis√£o cir√∫rgica (mas cobra R$ 50 pelo trabalho)
- **Gemini** l√™ tudo rapidinho, resume bem mas √†s vezes "pula cap√≠tulos" (cobra R$ 5)
- **Claude** l√™ tudo, segue SUA instru√ß√£o √† risca, se voc√™ disse "resuma em 3 par√°grafos", vai ser 3 (cobra R$ 30)
- **DeepSeek** l√™ metade do livro, resume bem o que leu mas pode errar contexto do final (cobra R$ 2)

**Voc√™ contrata quem pra cada tipo de tarefa?**

---

## üõ†Ô∏è LABORAT√ìRIO PR√ÅTICO

### Setup Inicial (5 min)

**Voc√™ vai precisar:**
1. Conta OpenRouter (https://openrouter.ai) ‚Äî $5 inicial
2. API Key do OpenRouter (vai acessar os 4 modelos com 1 chave s√≥)
3. n8n Cloud (gratuito pra teste)

**Por que OpenRouter?**

Sem OpenRouter:
```
‚ùå 4 contas diferentes (Google AI, OpenAI, Anthropic, DeepSeek)
‚ùå 4 API keys pra gerenciar
‚ùå 4 cobran√ßas diferentes
‚ùå Complexidade desnecess√°ria
```

Com OpenRouter:
```
‚úÖ 1 conta s√≥
‚úÖ 1 API key
‚úÖ 1 cobran√ßa
‚úÖ Troca de modelo = mudar 1 linha de c√≥digo
```

**Simples assim.**

---

### Experimento: O Agente de Agendamento

**Tarefa Real:** Criar agente que verifica disponibilidade na agenda e marca reuni√£o.

**Prompt Base (vai usar nos 4 modelos):**

```markdown
Voc√™ √© um assistente de agendamento profissional.

TAREFA:
1. Verifique a agenda do usu√°rio para o dia solicitado
2. Identifique hor√°rios LIVRES (sem compromissos)
3. Sugira 3 op√ß√µes de hor√°rio para reuni√£o de 1 hora
4. NUNCA sugira hor√°rios ocupados
5. Se n√£o houver hor√°rios livres, diga isso claramente

AGENDA DO DIA 20/10/2025:
- 09:00-10:30: Reuni√£o de equipe
- 11:00-12:00: Call com cliente
- 14:00-15:30: Workshop interno
- 16:00-17:00: 1-on-1 com gestor

PERGUNTA DO USU√ÅRIO:
"Preciso marcar uma reuni√£o de 1 hora hoje (20/10). Quais hor√°rios dispon√≠veis?"

RESPONDA:
```

---

### TESTE 1: GPT-5 mini (OpenAI) *(Out 2025)*

**Configura√ß√£o n8n:**
- Model: `openai/gpt-5-mini`
- Temperature: 0.2 (precis√£o)
- Max tokens: 500
- **Custo:** $0.25/M input, $2/M output (~R$ 0.0055/intera√ß√£o)

**Resposta GPT-5 mini:**
```
Com base na sua agenda de 20/10/2025, sugiro 3 hor√°rios dispon√≠veis para reuni√£o de 1 hora:

1. **10:30-11:30** (entre reuni√£o de equipe e call com cliente - h√° 30 min de buffer)
   ‚ö†Ô∏è Aten√ß√£o: Janela apertada, considere 10:45-11:45 para ter margem

2. **12:00-13:00** (ap√≥s call com cliente, antes do almo√ßo)

3. **15:30-16:30** (ap√≥s workshop, antes do 1-on-1)
   ‚ö†Ô∏è Nota: Sobrep√µe 30 min com 1-on-1 √†s 16h. Sugiro ajustar para 15:30-16:00 (30 min) ou realocar o 1-on-1.

**Hor√°rios que N√ÉO recomendo:**
- 08:00-09:00 (muito cedo, sem contexto de in√≠cio de expediente)
- Ap√≥s 17:00 (sem visibilidade de compromissos seguintes)

Qual hor√°rio prefere?
```

**An√°lise:**
‚úÖ Precis√£o cir√∫rgica
‚úÖ Identificou conflito potencial (10:30-11:30 apertado)
‚úÖ Sugeriu alternativa (15:30-16:00 sem conflito)
‚úÖ Custo: R$ 0.0055 por resposta (80% mais barato que GPT-5 padr√£o)

**Quando usar:** Produ√ß√£o geral confi√°vel, bom custo-benef√≠cio

---

### TESTE 2: Gemini 2.0 Flash (Google) *(Out 2025)*

**Configura√ß√£o n8n:**
- Model: `google/gemini-2.0-flash`
- Temperature: 0.2
- Max tokens: 500
- **Custo:** $0.10/M input, $0.40/M output (~R$ 0.00125/intera√ß√£o)

**Resposta Gemini 2.0 Flash:**
```
Claro! Aqui est√£o 3 hor√°rios dispon√≠veis hoje (20/10):

1. 08:00-09:00 (in√≠cio do dia)
2. 13:00-14:00 (ap√≥s almo√ßo)
3. 17:00-18:00 (final do expediente)

Qual hor√°rio funciona melhor pra voc√™?
```

**An√°lise:**
‚úÖ Resposta r√°pida (<1s - VELOCIDADE EXTREMA)
‚úÖ Custo baix√≠ssimo (R$ 0.00125 por resposta - 77% mais barato que GPT-5 mini)
‚ö†Ô∏è **N√ÉO verificou conflitos reais** (sugeriu hor√°rios gen√©ricos)
‚ö†Ô∏è **Ignorou a agenda fornecida** (n√£o processou o contexto adequadamente)
‚ùå Pode gerar ERRO CR√çTICO em produ√ß√£o se usado sem valida√ß√£o

**Quando usar:** Alto volume (>10k msgs/m√™s), tarefas n√£o-cr√≠ticas, FAQ simples

---

### TESTE 3: Claude Haiku 4.5 (Anthropic) *(Out 2025)*

**Configura√ß√£o n8n:**
- Model: `anthropic/claude-haiku-4.5`
- Temperature: 0.2
- Max tokens: 500
- **Custo:** $1/M input, $5/M output (~R$ 0.015/intera√ß√£o)

**Resposta Claude Haiku 4.5:**
```
Analisando sua agenda de 20/10/2025, identifiquei os seguintes hor√°rios LIVRES para reuni√£o de 1 hora:

**Op√ß√£o 1:** 10:30-11:30
- Entre "Reuni√£o de equipe" (termina 10:30) e "Call com cliente" (inicia 11:00)
- ‚ö†Ô∏è CONFLITO: Sobra apenas 30 minutos, n√£o 1 hora
- N√£o recomendo

**Op√ß√£o 2:** 12:00-13:00
- Ap√≥s "Call com cliente" (termina 12:00)
- Antes de "Workshop interno" (inicia 14:00)
- ‚úÖ VI√ÅVEL: 1 hora completa dispon√≠vel

**Op√ß√£o 3:** 17:00-18:00
- Ap√≥s "1-on-1 com gestor" (termina 17:00)
- ‚úÖ VI√ÅVEL: 1 hora completa dispon√≠vel

**Op√ß√£o 4 (alternativa):** 08:00-09:00
- Antes de "Reuni√£o de equipe" (inicia 09:00)
- ‚úÖ VI√ÅVEL se voc√™ inicia expediente √†s 08:00

**Recomenda√ß√£o:** Hor√°rio 12:00-13:00 (melhor para produtividade, evita fadiga p√≥s-almo√ßo).

Qual hor√°rio prefere?
```

**An√°lise:**
‚úÖ Seguiu instru√ß√µes √Ä RISCA (caracter√≠stica Claude)
‚úÖ Identificou conflito (10:30-11:30 n√£o d√° 1h)
‚úÖ Ofereceu 4 op√ß√µes (al√©m das 3 solicitadas)
‚úÖ Deu recomenda√ß√£o fundamentada
‚úÖ Performance Sonnet 4 a 1/3 do custo (R$ 0.015/resposta)
‚úÖ 2x mais r√°pido que Sonnet 4.5

**Quando usar:** Tarefas cr√≠ticas que exigem ZERO margem de interpreta√ß√£o + custo controlado

---

### TESTE 4: DeepSeek V3 (Open Source) *(Out 2025)*

**Configura√ß√£o n8n:**
- Model: `deepseek/deepseek-v3`
- Temperature: 0.2
- Max tokens: 500
- **Custo:** $0.028/M input, $0.112/M output (~R$ 0.00035/intera√ß√£o)

**Resposta DeepSeek:**
```
Hor√°rios dispon√≠veis para reuni√£o de 1 hora em 20/10/2025:

1. 12:00-13:00
2. 17:00-18:00
3. 08:00-09:00

Escolha o que preferir.
```

**An√°lise:**
‚úÖ Resposta correta e direta
‚úÖ Custo ULTRA baixo (R$ 0.00035 - 94% mais barato que GPT-5 mini)
‚úÖ R√°pido (1-2s)
‚úÖ Eficiente para tarefas diretas
‚ö†Ô∏è Sem detalhamento ou justificativas
‚ö†Ô∏è Pode ter dificuldade com nuances complexas

**Quando usar:** Ultra volume (20k+ msgs/m√™s), tarefas simples repetitivas, custo √© prioridade m√°xima

---

## üìä COMPARA√á√ÉO FINAL (OUT 2025)

| Modelo | Precis√£o | Custo/req (BRL) | Velocidade | Quando Usar |
|--------|----------|-----------------|------------|-------------|
| **GPT-5 mini** | ‚≠ê‚≠ê‚≠ê‚≠ê | R$ 0,0055 | 2-4s | Produ√ß√£o geral confi√°vel |
| **Claude Haiku 4.5** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | R$ 0,015 | 1-3s | Tarefas cr√≠ticas + custo controlado |
| **Gemini 2.0 Flash** | ‚≠ê‚≠ê‚≠ê | R$ 0,00125 | <1s | Alto volume, velocidade extrema |
| **DeepSeek V3** | ‚≠ê‚≠ê‚≠ê‚≠ê | R$ 0,00035 | 1-2s | Ultra volume, custo m√≠nimo |

**üí° Modelos adicionais dispon√≠veis (Out 2025):**
- **GPT-5** (padr√£o): R$ 0,028/req - Precis√£o m√°xima
- **Claude Sonnet 4.5**: R$ 0,045/req - Rigor √©tico premium
- **Gemini 2.5 Pro**: R$ 0,031/req - Criatividade avan√ßada
- **Mistral Medium 3**: R$ 0,006/req - Equil√≠brio custo-performance

*Ver tabela completa em:* `resources/tabela-comparativa-llms-2025.md`

---

## üéØ APLICA√á√ÉO PR√ÅTICA: QUANDO USAR CADA UM

### Cen√°rio 1: Agente de Agendamento (Cliente M√©dico)
**Requisito:** ZERO margem de erro (compromete pacientes)
**Escolha:** Claude Haiku 4.5 ou GPT-5 mini *(Out 2025)*
**Justificativa:** Precis√£o > custo
**Custo API mensal:** ~R$ 225/m√™s (500 msgs/m√™s √ó R$ 0,015 Claude Haiku)
**Precifica√ß√£o cliente:** R$ 6.000 setup + R$ 1.500/m√™s
**Lucro operacional:** R$ 1.275/m√™s (ap√≥s API)

---

### Cen√°rio 2: Agente de Follow-up de Vendas
**Requisito:** Enviar 500 emails/dia personalizados
**Escolha:** DeepSeek V3 (triagem) + Claude Haiku 4.5 (emails importantes) *(Out 2025)*
**Justificativa:** H√≠brido = custo otimizado
**Custo API mensal:**
- DeepSeek V3: 12.000 msgs √ó R$ 0,00035 = R$ 4,20
- Claude Haiku 4.5: 3.000 msgs √ó R$ 0,015 = R$ 45
- **Total:** R$ 49,20/m√™s (89% redu√ß√£o vs modelo √∫nico)
**Precifica√ß√£o cliente:** R$ 5.000 setup + R$ 1.200/m√™s
**Lucro operacional:** R$ 1.150/m√™s (ap√≥s API)

---

### Cen√°rio 3: Agente de Atendimento (E-commerce)
**Requisito:** Responder d√∫vidas simples em tempo real
**Escolha:** Gemini 2.0 Flash (90% das d√∫vidas) + GPT-5 mini (casos complexos) *(Out 2025)*
**Justificativa:** Velocidade + custo baixo
**Custo API mensal:**
- Gemini 2.0 Flash: 18.000 msgs √ó R$ 0,00125 = R$ 22,50
- GPT-5 mini: 2.000 msgs √ó R$ 0,0055 = R$ 11
- **Total:** R$ 33,50/m√™s
**Precifica√ß√£o cliente:** R$ 4.500 setup + R$ 1.000/m√™s
**Lucro operacional:** R$ 966/m√™s (ap√≥s API)

---

## üí∞ A CONTA QUE O RAFAEL N√ÉO FEZ

Lembra do Rafael l√° no in√≠cio? Cliente cancelou porque Gemini errou agendamento?

**Erro dele:** Escolher modelo por CUSTO, n√£o por REQUISITO.

**C√°lculo correto (Out 2025):**

**Cen√°rio A (Gemini 2.0 Flash puro):**
- Volume: 300 agendamentos/m√™s
- Custo API: 300 msgs √ó R$ 0,00125 = **R$ 0,38/m√™s**
- Taxa de erro: 15% (45 falhas/m√™s)
- Cliente cancelou ap√≥s 1 erro cr√≠tico (paciente perdeu consulta)
- Investimento total at√© cancelamento: R$ 6.000 (setup)
- Receita obtida: R$ 1.500 (1 m√™s apenas)
- Custo desenvolvimento: R$ 2.500 (tempo do Rafael)
- **PREJU√çZO: R$ 7.000** + reputa√ß√£o manchada

**Cen√°rio B (Claude Haiku 4.5 adequado):**
- Volume: 300 agendamentos/m√™s
- Custo API: 300 msgs √ó R$ 0,015 = **R$ 4,50/m√™s**
- Taxa de erro: <1% (0-3 falhas/m√™s, n√£o cr√≠ticas)
- Cliente satisfeito, renovou por 12 meses
- Receita total: R$ 6.000 (setup) + (R$ 1.500 √ó 12 manuten√ß√£o) = **R$ 24.000**
- Custo API anual: R$ 4,50 √ó 12 = R$ 54
- Custo desenvolvimento: R$ 2.500 (mesmo tempo)
- Lucro l√≠quido: R$ 24.000 - R$ 54 - R$ 2.500 = **R$ 21.446**

**Diferen√ßa:** R$ 28.446 por ter escolhido modelo CERTO.

**Observa√ß√£o cr√≠tica:**
> "Mas Jos√©, a diferen√ßa de custo de API foi s√≥ R$ 4,12/m√™s!"
>
> Exato. **Rafael perdeu R$ 28 mil por tentar economizar R$ 50/ano em API.**
>
> Isso √© gest√£o de IA. Simples assim.

---

## üß© EXPANS√ÉO FILOS√ìFICA

E talvez ‚Äî s√≥ talvez ‚Äî o que voc√™ acabou de aprender vai muito al√©m de "escolher o modelo certo".

Porque no fundo, voc√™ n√£o t√° aprendendo a usar IA.

**Voc√™ t√° aprendendo a PENSAR como gestor.**

Um gestor n√£o escolhe funcion√°rio mais barato. Ele escolhe o CERTO pra fun√ß√£o.

Voc√™ n√£o contrata um PhD em f√≠sica pra fazer cafezinho. E n√£o contrata estagi√°rio pra fazer cirurgia card√≠aca.

**√â sobre matching: tarefa √ó capacidade √ó custo.**

E quando voc√™ domina isso, voc√™ n√£o √© mais "aquele cara que mexe com IA".

Voc√™ √© **o profissional que entrega resultado previs√≠vel usando as ferramentas certas**.

---

## ‚úÖ CHECKLIST DE CONCLUS√ÉO

Antes de avan√ßar pra Lesson 1.2, confirme:

- [ ] Criei conta OpenRouter e testei API key
- [ ] Testei o mesmo prompt nos 4 modelos
- [ ] Entendi POR QUE cada um respondeu diferente
- [ ] Identifiquei 1 caso de uso real do meu neg√≥cio
- [ ] Escolhi qual modelo usar nesse caso (e sei justificar)

---

## üìé RECURSOS

- **Tabela comparativa OpenRouter:** `resources/tabela-comparativa-llms-openrouter.pdf`
- **Template n8n:** `templates/n8n-teste-4-modelos.json`
- **Calculadora de custo:** `resources/calculadora-precificacao.xlsx`

---

## ‚û°Ô∏è PR√ìXIMA LESSON

**Lesson 1.2:** A Conta que o Cliente N√£o V√™

Voc√™ vai aprender a fazer o c√°lculo COMPLETO de precifica√ß√£o (setup + manuten√ß√£o + lucro) e montar 3 pacotes t√©cnicos que o cliente entende.

---

*Lesson criada com voz de Jos√© Carlos Amorim (MMOS) | Fidelidade: 90%+*
