# Aula 2.2 - Processamento em Massa: 1000 Documentos em 1 Comando

**M√≥dulo:** 2 - Arsenal Pr√°tico  
**Dura√ß√£o:** 15 minutos  
**N√≠vel Bloom:** Apply  
**Instrutor:** Jos√© Carlos Amorim

---

## üéØ GOAL

Criar scripts que processam **centenas ou milhares de arquivos automaticamente** - tipo extrair dados de 500 PDFs de contratos ou converter 1000 planilhas em formato √∫nico.

**Resultado concreto:** Script que processa 100 PDFs em batch, extrai informa√ß√µes chave e gera relat√≥rio consolidado em CSV.

---

## üìç POSITION

Voc√™ coletou 500 empresas via scraping (aula 2.1). √ìtimo! Mas agora tem outro problema:

**Sabe aquele momento** que voc√™ recebe 200 notas fiscais em PDF todo m√™s e precisa extrair: data, valor, fornecedor para relat√≥rio financeiro?

Manual = **8 horas** (abrir PDF, copiar dados, colar em planilha, repetir 200x)

**Ou:** 500 contratos PDF que vencem em datas diferentes e voc√™ precisa de planilha com "Contrato X vence dia Y"?

Manual = **20 horas** de trabalho ma√ßante

**Hoje isso acaba.**

Processamento em massa = fazer o computador repetir tarefa chata 1000x em minutos enquanto voc√™ toma caf√©.

---

## üîÑ STEPS

### PASSO 1: Anatomia do Processamento Batch (3min)

#### O QUE √â BATCH PROCESSING

**Batch = Lote**. Processar lote inteiro de arquivos de uma vez.

**Estrutura b√°sica:**
```python
for arquivo in lista_arquivos:
    # 1. Abrir arquivo
    # 2. Extrair dados
    # 3. Processar/transformar
    # 4. Salvar resultado
    # Loop ‚Üí pr√≥ximo arquivo
```

**Componentes essenciais:**
- **Loop:** Percorre todos arquivos
- **Try/Except:** Se 1 arquivo quebrar, continua processando outros
- **Progress Bar:** Saber em que ponto est√° (10/1000 processados)
- **Logging:** Registrar erros para debug depois

---

### PASSO 2: Processar PDFs em Massa (5min)

#### CASO REAL: Extrair Dados de 100 Contratos PDF

**PROMPT PARA CLAUDE:**

```
Preciso de script Python para processar m√∫ltiplos PDFs em batch:

Tarefa: Extrair dados de 100 contratos PDF e gerar CSV consolidado

Estrutura dos PDFs:
- Cada contrato tem: Cliente, Valor Total, Data Vencimento, N√∫mero Contrato
- Informa√ß√µes est√£o em texto corrido (n√£o tabela estruturada)

Requisitos:
1. Processar pasta inteira (/contratos/*.pdf)
2. Para cada PDF extrair texto completo
3. Buscar padr√µes regex:
   - Cliente: linha com "CONTRATANTE: [nome]"
   - Valor: linha com "R$ [valor]"
   - Vencimento: data no formato DD/MM/YYYY
4. Salvar em CSV: nome_arquivo, cliente, valor, vencimento
5. Progress bar (mostrar 1/100, 2/100...)
6. Se PDF corrompido ou sem dados, logar erro e continuar
7. Ao final: resumo (X processados, Y com erro)

Usar: PyPDF2 para extra√ß√£o, tqdm para progress bar
```

**CLAUDE GERA:**

```python
import os
import re
import csv
from PyPDF2 import PdfReader
from tqdm import tqdm

# Configura√ß√µes
PASTA_PDFS = "./contratos"
OUTPUT_CSV = "contratos_processados.csv"

def extrair_dados_pdf(pdf_path):
    """Extrai dados de um PDF de contrato"""
    try:
        reader = PdfReader(pdf_path)
        texto_completo = ""
        
        # Extrair texto de todas p√°ginas
        for page in reader.pages:
            texto_completo += page.extract_text()
        
        # Regex patterns
        cliente = re.search(r'CONTRATANTE:\s*([^\n]+)', texto_completo)
        valor = re.search(r'R\$\s*([\d.,]+)', texto_completo)
        vencimento = re.search(r'(\d{2}/\d{2}/\d{4})', texto_completo)
        
        return {
            'arquivo': os.path.basename(pdf_path),
            'cliente': cliente.group(1).strip() if cliente else 'N/A',
            'valor': valor.group(1) if valor else 'N/A',
            'vencimento': vencimento.group(1) if vencimento else 'N/A'
        }
        
    except Exception as e:
        return {'erro': str(e), 'arquivo': os.path.basename(pdf_path)}

def processar_batch():
    # Listar todos PDFs
    pdfs = [f for f in os.listdir(PASTA_PDFS) if f.endswith('.pdf')]
    
    print(f"üìä {len(pdfs)} PDFs encontrados\n")
    
    resultados = []
    erros = []
    
    # Progress bar
    for pdf in tqdm(pdfs, desc="Processando"):
        pdf_path = os.path.join(PASTA_PDFS, pdf)
        resultado = extrair_dados_pdf(pdf_path)
        
        if 'erro' in resultado:
            erros.append(resultado)
        else:
            resultados.append(resultado)
    
    # Salvar CSV
    if resultados:
        with open(OUTPUT_CSV, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=['arquivo', 'cliente', 'valor', 'vencimento'])
            writer.writeheader()
            writer.writerows(resultados)
        
        print(f"\n‚úÖ {len(resultados)} contratos processados ‚Üí {OUTPUT_CSV}")
    
    # Mostrar erros
    if erros:
        print(f"\n‚ö†Ô∏è {len(erros)} arquivos com erro:")
        for erro in erros[:5]:  # Mostrar s√≥ primeiros 5
            print(f"  - {erro['arquivo']}: {erro['erro']}")

if __name__ == "__main__":
    processar_batch()
```

**INSTALAR:**
```bash
pip3 install PyPDF2 tqdm
```

**EXECUTAR:**
```bash
python3 processar_contratos.py
```

**OUTPUT:**
```
üìä 100 PDFs encontrados

Processando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:45<00:00, 2.22it/s]

‚úÖ 97 contratos processados ‚Üí contratos_processados.csv
‚ö†Ô∏è 3 arquivos com erro:
  - contrato_042.pdf: PDF corrupted
  - contrato_089.pdf: No pattern found
```

**CSV gerado:**
```csv
arquivo,cliente,valor,vencimento
contrato_001.pdf,Empresa XYZ Ltda,R$ 150.000,15/12/2025
contrato_002.pdf,Jo√£o Silva MEI,R$ 8.500,01/03/2026
...
```

**ROI:** 100 contratos manual (5min cada) = 8h ‚Üí Script = 45 segundos ‚úÖ

---

### PASSO 3: Converter Formatos em Massa (3min)

#### CASO: 500 CSVs para JSON

**PROMPT:**
```
Script para converter 500 CSVs em JSON mantendo estrutura:

Input: /dados/*.csv
Output: /dados_json/*.json

Requisitos:
1. Cada CSV vira 1 JSON
2. Primeira linha = headers (chaves JSON)
3. Progress bar
4. Skip arquivos vazios
```

**C√≥digo (resumido):**
```python
import pandas as pd
from tqdm import tqdm

for csv_file in tqdm(csvs):
    df = pd.read_csv(csv_file)
    json_file = csv_file.replace('.csv', '.json').replace('dados/', 'dados_json/')
    df.to_json(json_file, orient='records', indent=2)
```

**Converte 500 CSVs em ~2 minutos** üöÄ

---

### PASSO 4: Progress Bars & Error Handling (2min)

#### POR QUE PROGRESS BAR √â CR√çTICO

Processar 1000 arquivos sem feedback = ansiedade.

*"Est√° travado? Quanto falta? Devo cancelar?"*

**Progress bar resolve:**
```python
from tqdm import tqdm

for item in tqdm(lista_grande, desc="Processando"):
    # seu c√≥digo aqui
```

**Output:**
```
Processando: 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 450/1000 [02:15<02:45, 3.32it/s]
```

Voc√™ v√™:
- % completo (45%)
- Items processados (450/1000)
- Tempo decorrido (2:15)
- Tempo estimado restante (2:45)
- Velocidade (3.32 items/segundo)

**Sanidade mental preservada** ‚úÖ

#### ERROR HANDLING ESSENCIAL

**Sem try/except:**
```python
for arquivo in lista:
    processar(arquivo)  # Se 1 falhar ‚Üí TRAVA TUDO
```

**Com try/except:**
```python
sucessos = []
erros = []

for arquivo in lista:
    try:
        resultado = processar(arquivo)
        sucessos.append(resultado)
    except Exception as e:
        erros.append({'arquivo': arquivo, 'erro': str(e)})
        continue  # Continua processando pr√≥ximo
```

**Resultado:** 997 processados, 3 com erro ‚Üí **MUITO melhor** que 0 processados por causa de 3 ruins.

---

### PASSO 5: Casos de Uso Avan√ßados (2min)

#### 1. EXTRAIR TABELAS DE 100 PDFs

```python
# Usa tabula-py para PDFs com tabelas estruturadas
import tabula

dfs = tabula.read_pdf_with_template(pdf_path, template_path)
# Salva todas tabelas consolidadas
```

**Uso:** Relat√≥rios mensais com mesma estrutura

#### 2. RENOMEAR 1000 ARQUIVOS EM PADR√ÉO

```python
# De: IMG_0001.jpg, IMG_0002.jpg...
# Para: 2025-01-15_produto_001.jpg

import os
from datetime import datetime

data = datetime.now().strftime('%Y-%m-%d')

for idx, arquivo in enumerate(arquivos, 1):
    novo_nome = f"{data}_produto_{idx:03d}.jpg"
    os.rename(arquivo, novo_nome)
```

**Uso:** Organizar fotos de produtos para loja

#### 3. PROCESSAR IMAGENS EM BATCH

```python
from PIL import Image

for img_path in imagens:
    img = Image.open(img_path)
    # Redimensionar para thumbnail
    img.thumbnail((300, 300))
    img.save(img_path.replace('.jpg', '_thumb.jpg'))
```

**Uso:** Gerar thumbnails de 500 fotos para site

---

## üéì S√çNTESE

**O que voc√™ dominou:**

1. **Batch processing = Loop + Try/Except + Progress + Log**
   - Processar 100, 1000, 10000 arquivos automaticamente
   
2. **Casos de uso reais:**
   - PDFs: Extrair dados de contratos/NFs/relat√≥rios
   - CSVs: Converter formatos, consolidar planilhas
   - Imagens: Redimensionar, renomear, comprimir

3. **Components essenciais:**
   - `tqdm` ‚Üí Progress bar (sanidade mental)
   - `try/except` ‚Üí Error handling (1 erro n√£o trava tudo)
   - Logging ‚Üí Saber quais arquivos falharam

4. **ROI exponencial:**
   - Manual: 1000 arquivos x 3min cada = 50 horas
   - Script: 1000 arquivos = 10 minutos
   - **Economia: 50 horas por execu√ß√£o**

5. **Regex = superpoder** para extrair padr√µes de texto n√£o estruturado

**Skills desbloqueadas:**
- ‚úÖ Processar centenas de PDFs
- ‚úÖ Converter formatos em massa
- ‚úÖ Progress bars + error handling
- ‚úÖ Consolidar dados fragmentados

---

## üöÄ PR√ìXIMOS PASSOS

**Desafio:**

Pensa em 1 tarefa repetitiva que voc√™ faz com m√∫ltiplos arquivos:
- Baixar 50 relat√≥rios e consolidar dados?
- Renomear 200 fotos para padr√£o espec√≠fico?
- Extrair valores de 100 PDFs de notas fiscais?

Cria script de batch processing para isso.

**Pr√≥xima aula (2.3):**
"API Simples: Conecte Sistemas sem Zapier"

Processou 1000 PDFs? Agora precisa enviar resultado automaticamente para seu CRM. Vamos criar APIs REST simples.

**Coleta (scraping) ‚Üí Processa (batch) ‚Üí Integra (API). Voc√™ est√° dominando o ciclo completo.** üí™

---

## üí≠ REFLEX√ÉO FINAL

**Porque no fundo...**

A diferen√ßa entre escalar e n√£o escalar n√£o √© trabalhar mais. √â **automatizar o que se repete**.

Voc√™ acabou de aprender a fazer computador repetir tarefa chata 1000x mais r√°pido que voc√™.

Pr√≥xima vez que pegar tarefa manual repetitiva, n√£o pensa: *"Vou fazer as 1000"*.

Pensa: *"Vou fazer 1 com Claude Code. Depois boto pra rodar nas 1000."*

**Esse mindset shift vale mais que o curso inteiro.** üöÄ

---

**Instrutor:** Jos√© Carlos Amorim  
**Dura√ß√£o:** 15 minutos  
**Framework:** GPS + Did√°tica Lend√°ria + ESPIRAL EXPANSIVA

