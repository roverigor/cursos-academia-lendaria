# Aula 11.2 - Integração Enterprise na Prática

**Módulo:** 11 - API e Integrações Enterprise
**Duração:** 25 minutos
**Tipo:** Projeto Prático + Código

---

## Objetivo da Aula

Implementar uma integração enterprise funcional usando Gemini API como "NotebookLM programático".

---

## Roteiro de Gravação

### INTRODUÇÃO (0:00 - 1:30)

**[CENA: Instrutor em câmera]**

Teoria acabou. Vamos construir.

Nesta aula, você vai implementar:
1. Sistema de chat sobre documentos
2. Geração automática de resumos
3. Integração com Slack/Teams
4. Dashboard de uso

Código funcional. Pronto para produção.

---

### PARTE 1: SETUP DO PROJETO (1:30 - 5:00)

**[CENA: Screencast - terminal + IDE]**

#### Estrutura do Projeto:

```
enterprise-notebook/
├── app/
│   ├── __init__.py
│   ├── main.py           # FastAPI app
│   ├── services/
│   │   ├── __init__.py
│   │   ├── notebook.py   # Serviço principal
│   │   ├── gemini.py     # Wrapper Gemini API
│   │   └── tts.py        # Text-to-speech
│   ├── api/
│   │   ├── __init__.py
│   │   ├── routes.py     # Endpoints REST
│   │   └── webhooks.py   # Slack/Teams hooks
│   └── models/
│       ├── __init__.py
│       └── schemas.py    # Pydantic models
├── tests/
│   └── test_notebook.py
├── requirements.txt
├── docker-compose.yml
└── README.md
```

**[DEMONSTRAR - criar estrutura]**

---

#### Instalação:

```bash
# Criar ambiente
python -m venv venv
source venv/bin/activate  # Linux/Mac
# .\venv\Scripts\activate  # Windows

# Instalar dependências
pip install fastapi uvicorn google-generativeai \
            google-cloud-texttospeech python-multipart \
            pydantic python-dotenv httpx

# Arquivo .env
echo "GOOGLE_API_KEY=sua_chave_aqui" > .env
echo "GOOGLE_CLOUD_PROJECT=seu_projeto" >> .env
```

---

### PARTE 2: SERVIÇO DE NOTEBOOK (5:00 - 12:00)

**[CENA: Screencast - código]**

#### Wrapper do Gemini:

```python
# app/services/gemini.py

import google.generativeai as genai
from typing import List, Dict, Optional
import os

class GeminiClient:
    """Cliente para interação com Gemini API"""

    def __init__(self):
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY não configurada")

        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-1.5-pro')

    def create_grounded_chat(
        self,
        documents: List[str],
        system_prompt: Optional[str] = None
    ):
        """
        Cria chat grounded nos documentos fornecidos.

        Args:
            documents: Lista de textos dos documentos
            system_prompt: Prompt de sistema customizado

        Returns:
            Chat session configurada
        """
        context = "\n\n---\n\n".join([
            f"DOCUMENTO {i+1}:\n{doc}"
            for i, doc in enumerate(documents)
        ])

        default_prompt = f"""
        Você é um assistente de análise documental especializado.

        SEU CONHECIMENTO:
        Você tem acesso APENAS aos seguintes documentos:

        {context}

        REGRAS:
        1. Responda APENAS com base nos documentos acima
        2. Se a informação não estiver nos documentos, diga claramente
        3. Cite o número do documento quando relevante
        4. Seja preciso, factual e objetivo
        5. Para perguntas complexas, estruture a resposta

        FORMATO:
        - Use markdown quando apropriado
        - Para listas, use bullets
        - Para dados, use tabelas
        """

        prompt = system_prompt or default_prompt

        chat = self.model.start_chat(history=[])
        # Enviar contexto como primeira mensagem (invisível ao usuário)
        chat.send_message(prompt)

        return chat

    def generate_summary(
        self,
        documents: List[str],
        style: str = "executive"
    ) -> str:
        """
        Gera resumo dos documentos.

        Args:
            documents: Lista de textos
            style: Estilo do resumo (executive, detailed, bullets)

        Returns:
            Texto do resumo
        """
        styles = {
            "executive": "Resumo executivo de 1-2 parágrafos",
            "detailed": "Resumo detalhado de 1-2 páginas",
            "bullets": "Lista de bullet points com os principais pontos"
        }

        context = "\n\n".join(documents)

        prompt = f"""
        Analise os documentos abaixo e gere: {styles.get(style, styles['executive'])}

        DOCUMENTOS:
        {context}

        RESUMO:
        """

        response = self.model.generate_content(prompt)
        return response.text

    def generate_podcast_script(
        self,
        documents: List[str],
        duration_minutes: int = 10
    ) -> str:
        """
        Gera script de podcast estilo NotebookLM.

        Args:
            documents: Lista de textos
            duration_minutes: Duração desejada

        Returns:
            Script formatado
        """
        context = "\n\n".join(documents)

        prompt = f"""
        Você é um roteirista de podcast. Crie um script de {duration_minutes}
        minutos com dois hosts discutindo o conteúdo abaixo.

        CONTEÚDO:
        {context}

        REGRAS:
        - Tom conversacional e engajante
        - Intercale entre os hosts naturalmente
        - Inclua insights e conexões interessantes
        - Mantenha factual (baseado no conteúdo)

        FORMATO:
        HOST 1 (Ana): [fala]
        HOST 2 (Bruno): [fala]
        ...

        SCRIPT:
        """

        response = self.model.generate_content(prompt)
        return response.text
```

---

#### Serviço Principal:

```python
# app/services/notebook.py

from typing import List, Dict, Optional
from .gemini import GeminiClient
from .tts import TTSService
import hashlib
import json

class NotebookService:
    """
    Serviço que replica funcionalidades do NotebookLM.
    """

    def __init__(self):
        self.gemini = GeminiClient()
        self.tts = TTSService()
        self.notebooks: Dict[str, dict] = {}  # Em produção: use banco de dados

    def create_notebook(
        self,
        name: str,
        documents: List[str]
    ) -> str:
        """
        Cria um novo notebook.

        Args:
            name: Nome do notebook
            documents: Lista de textos dos documentos

        Returns:
            ID do notebook criado
        """
        # Gerar ID único
        notebook_id = hashlib.md5(
            f"{name}_{len(documents)}".encode()
        ).hexdigest()[:12]

        # Criar chat grounded
        chat = self.gemini.create_grounded_chat(documents)

        # Armazenar
        self.notebooks[notebook_id] = {
            "id": notebook_id,
            "name": name,
            "documents": documents,
            "document_count": len(documents),
            "chat": chat,
            "queries": []
        }

        return notebook_id

    def query(self, notebook_id: str, question: str) -> dict:
        """
        Faz pergunta ao notebook.

        Args:
            notebook_id: ID do notebook
            question: Pergunta do usuário

        Returns:
            Resposta estruturada
        """
        notebook = self.notebooks.get(notebook_id)
        if not notebook:
            raise ValueError(f"Notebook {notebook_id} não encontrado")

        # Enviar pergunta
        response = notebook["chat"].send_message(question)

        # Registrar query
        notebook["queries"].append({
            "question": question,
            "answer": response.text
        })

        return {
            "notebook_id": notebook_id,
            "question": question,
            "answer": response.text,
            "sources_count": notebook["document_count"]
        }

    def generate_summary(
        self,
        notebook_id: str,
        style: str = "executive"
    ) -> str:
        """Gera resumo do conteúdo do notebook."""
        notebook = self.notebooks.get(notebook_id)
        if not notebook:
            raise ValueError(f"Notebook {notebook_id} não encontrado")

        return self.gemini.generate_summary(
            notebook["documents"],
            style
        )

    def generate_audio_overview(
        self,
        notebook_id: str,
        duration_minutes: int = 10
    ) -> str:
        """
        Gera audio overview (similar ao NotebookLM).

        Returns:
            Path do arquivo de áudio gerado
        """
        notebook = self.notebooks.get(notebook_id)
        if not notebook:
            raise ValueError(f"Notebook {notebook_id} não encontrado")

        # Gerar script
        script = self.gemini.generate_podcast_script(
            notebook["documents"],
            duration_minutes
        )

        # Converter para áudio
        audio_path = self.tts.synthesize(
            script,
            output_file=f"audio_{notebook_id}.mp3"
        )

        return audio_path

    def get_stats(self, notebook_id: str) -> dict:
        """Retorna estatísticas do notebook."""
        notebook = self.notebooks.get(notebook_id)
        if not notebook:
            raise ValueError(f"Notebook {notebook_id} não encontrado")

        return {
            "id": notebook_id,
            "name": notebook["name"],
            "document_count": notebook["document_count"],
            "query_count": len(notebook["queries"]),
            "last_queries": notebook["queries"][-5:]
        }
```

---

### PARTE 3: API REST (12:00 - 17:00)

**[CENA: Screencast - código + testes]**

#### Endpoints:

```python
# app/api/routes.py

from fastapi import APIRouter, UploadFile, File, HTTPException
from typing import List
from pydantic import BaseModel
from ..services.notebook import NotebookService

router = APIRouter(prefix="/api/v1", tags=["notebooks"])
service = NotebookService()


class CreateNotebookRequest(BaseModel):
    name: str
    documents: List[str]


class QueryRequest(BaseModel):
    question: str


class SummaryRequest(BaseModel):
    style: str = "executive"


class AudioRequest(BaseModel):
    duration_minutes: int = 10


# Criar notebook
@router.post("/notebooks")
async def create_notebook(request: CreateNotebookRequest):
    """Cria um novo notebook com os documentos fornecidos."""
    try:
        notebook_id = service.create_notebook(
            name=request.name,
            documents=request.documents
        )
        return {
            "status": "created",
            "notebook_id": notebook_id,
            "message": f"Notebook '{request.name}' criado com {len(request.documents)} documentos"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# Upload de arquivos
@router.post("/notebooks/upload")
async def create_notebook_from_files(
    name: str,
    files: List[UploadFile] = File(...)
):
    """Cria notebook a partir de arquivos uploadados."""
    documents = []
    for file in files:
        content = await file.read()
        # Em produção: usar parser adequado para cada tipo
        documents.append(content.decode('utf-8'))

    notebook_id = service.create_notebook(name, documents)

    return {
        "status": "created",
        "notebook_id": notebook_id,
        "files_processed": len(files)
    }


# Query
@router.post("/notebooks/{notebook_id}/query")
async def query_notebook(notebook_id: str, request: QueryRequest):
    """Faz uma pergunta ao notebook."""
    try:
        result = service.query(notebook_id, request.question)
        return result
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


# Resumo
@router.post("/notebooks/{notebook_id}/summary")
async def generate_summary(notebook_id: str, request: SummaryRequest):
    """Gera resumo do conteúdo do notebook."""
    try:
        summary = service.generate_summary(notebook_id, request.style)
        return {
            "notebook_id": notebook_id,
            "style": request.style,
            "summary": summary
        }
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


# Audio Overview
@router.post("/notebooks/{notebook_id}/audio")
async def generate_audio(notebook_id: str, request: AudioRequest):
    """Gera audio overview do notebook."""
    try:
        audio_path = service.generate_audio_overview(
            notebook_id,
            request.duration_minutes
        )
        return {
            "notebook_id": notebook_id,
            "audio_url": f"/static/{audio_path}",
            "duration_minutes": request.duration_minutes
        }
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


# Estatísticas
@router.get("/notebooks/{notebook_id}/stats")
async def get_notebook_stats(notebook_id: str):
    """Retorna estatísticas de uso do notebook."""
    try:
        stats = service.get_stats(notebook_id)
        return stats
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
```

---

#### App Principal:

```python
# app/main.py

from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from .api.routes import router as api_router
from .api.webhooks import router as webhook_router

app = FastAPI(
    title="Enterprise Notebook API",
    description="API estilo NotebookLM para uso enterprise",
    version="1.0.0"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Arquivos estáticos (para áudios)
app.mount("/static", StaticFiles(directory="static"), name="static")

# Rotas
app.include_router(api_router)
app.include_router(webhook_router)


@app.get("/")
async def root():
    return {
        "name": "Enterprise Notebook API",
        "version": "1.0.0",
        "docs": "/docs"
    }


@app.get("/health")
async def health():
    return {"status": "healthy"}
```

---

### PARTE 4: INTEGRAÇÃO SLACK (17:00 - 22:00)

**[CENA: Screencast - Slack + código]**

#### Webhook para Slack:

```python
# app/api/webhooks.py

from fastapi import APIRouter, Request, HTTPException
import httpx
import os
from ..services.notebook import NotebookService

router = APIRouter(prefix="/webhooks", tags=["integrations"])
service = NotebookService()

SLACK_WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL")


@router.post("/slack/command")
async def slack_command(request: Request):
    """
    Recebe comandos do Slack.
    Configurar em: api.slack.com/apps
    """
    form_data = await request.form()

    command = form_data.get("command")
    text = form_data.get("text", "")
    user = form_data.get("user_name")
    channel = form_data.get("channel_name")

    # Parsear comando
    parts = text.split(" ", 1)
    action = parts[0] if parts else ""
    query = parts[1] if len(parts) > 1 else ""

    # Processar ações
    if action == "query":
        # Formato: /notebook query notebook_id pergunta
        query_parts = query.split(" ", 1)
        notebook_id = query_parts[0]
        question = query_parts[1] if len(query_parts) > 1 else ""

        try:
            result = service.query(notebook_id, question)
            return {
                "response_type": "in_channel",
                "blocks": [
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": f"*Pergunta:* {question}\n\n*Resposta:*\n{result['answer']}"
                        }
                    }
                ]
            }
        except ValueError as e:
            return {
                "response_type": "ephemeral",
                "text": f"Erro: {str(e)}"
            }

    elif action == "summary":
        notebook_id = query
        try:
            summary = service.generate_summary(notebook_id, "bullets")
            return {
                "response_type": "in_channel",
                "blocks": [
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": f"*Resumo do Notebook {notebook_id}:*\n\n{summary}"
                        }
                    }
                ]
            }
        except ValueError as e:
            return {
                "response_type": "ephemeral",
                "text": f"Erro: {str(e)}"
            }

    elif action == "help":
        return {
            "response_type": "ephemeral",
            "text": """
*Comandos disponíveis:*
• `/notebook query <id> <pergunta>` - Faz pergunta ao notebook
• `/notebook summary <id>` - Gera resumo
• `/notebook help` - Mostra esta ajuda
            """
        }

    return {
        "response_type": "ephemeral",
        "text": "Comando não reconhecido. Use `/notebook help`"
    }


async def send_slack_notification(message: str, channel: str = None):
    """Envia notificação para Slack."""
    if not SLACK_WEBHOOK_URL:
        return

    async with httpx.AsyncClient() as client:
        await client.post(
            SLACK_WEBHOOK_URL,
            json={"text": message, "channel": channel}
        )
```

**[DEMONSTRAR - configurar Slack app, testar comando]**

---

### PARTE 5: DEPLOY (22:00 - 24:00)

**[CENA: Terminal + docker]**

#### Docker Compose:

```yaml
# docker-compose.yml

version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - GOOGLE_CLOUD_PROJECT=${GOOGLE_CLOUD_PROJECT}
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL}
    volumes:
      - ./static:/app/static
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Opcional: Redis para cache
  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
```

---

#### Dockerfile:

```dockerfile
# Dockerfile

FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

---

#### Deploy:

```bash
# Build e run local
docker-compose up --build

# Testar
curl http://localhost:8000/health

# Criar notebook
curl -X POST http://localhost:8000/api/v1/notebooks \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Teste",
    "documents": ["Documento 1: conteúdo aqui", "Documento 2: mais conteúdo"]
  }'

# Query
curl -X POST http://localhost:8000/api/v1/notebooks/{id}/query \
  -H "Content-Type: application/json" \
  -d '{"question": "O que está nos documentos?"}'
```

---

### FECHAMENTO (24:00 - 25:00)

**[CENA: Instrutor em câmera]**

Você construiu um sistema enterprise funcional:

1. **API REST** completa para notebooks
2. **Chat grounded** em documentos
3. **Geração de resumos** e audio
4. **Integração Slack** com comandos
5. **Deploy containerizado**

**Código completo:** Disponível nos recursos do curso

**Quando API oficial do NotebookLM sair:**
- Trocar implementação do GeminiClient
- Manter mesma interface
- Zero mudança no resto do sistema

**Próximo módulo:** Maestria e Certificação — seu projeto final.

---

## Arquivos de Referência

```
REPOSITÓRIO COMPLETO:
═══════════════════════════════════════════════════════════════

resources/
├── enterprise-notebook/
│   ├── app/
│   │   ├── services/
│   │   │   ├── gemini.py
│   │   │   ├── notebook.py
│   │   │   └── tts.py
│   │   ├── api/
│   │   │   ├── routes.py
│   │   │   └── webhooks.py
│   │   └── main.py
│   ├── requirements.txt
│   ├── docker-compose.yml
│   ├── Dockerfile
│   └── README.md
```

---

## Notas de Produção

**Elementos visuais:**
- Código com syntax highlighting
- Terminal em ação
- Slack funcionando
- Docker logs

**Tom:**
- Hands-on e técnico
- Código funcional
- Pronto para produção
