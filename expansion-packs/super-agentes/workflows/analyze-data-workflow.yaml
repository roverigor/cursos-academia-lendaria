# Analyze Data Workflow
# Import data and analyze database contents safely (Story 1.4)

workflow:
  id: "analyze-data"
  name: "Analyze and Import Data"
  description: "Import CSV files, apply seed data, and analyze database contents with validation"
  version: "1.0.0"
  type: "sequential"

metadata:
  author: "DB Sage"
  created_date: "2025-10-27"
  story: "expansion-packs/super-agentes/docs/stories/1.4.analyze-data-workflow.md"

steps:
  - id: "operation_type"
    name: "Select Data Operation"
    type: "elicit"
    elicit:
      question: "Data operation:"
      options:
        - label: "Import CSV file"
          value: "import_csv"
        - label: "Apply seed data"
          value: "seed"
        - label: "Analyze existing data"
          value: "analyze"
      output_var: "operation_type"

  # CSV Import Path
  - id: "csv_details"
    condition: "{{operation_type}} == 'import_csv'"
    type: "elicit"
    elicit:
      fields:
        - name: "csv_path"
          label: "CSV file path"
          type: "string"
          required: true
        - name: "target_table"
          label: "Target table"
          type: "string"
          required: true
      output_vars: ["csv_path", "target_table"]

  - id: "csv_import"
    condition: "{{operation_type}} == 'import_csv'"
    type: "task"
    task: "db-load-csv"
    inputs:
      table: "{{target_table}}"
      csv_file: "{{csv_path}}"

  # Seed Data Path
  - id: "seed_details"
    condition: "{{operation_type}} == 'seed'"
    type: "elicit"
    elicit:
      fields:
        - name: "seed_path"
          label: "Seed file path"
          type: "string"
          required: true
      output_vars: ["seed_path"]

  - id: "seed_apply"
    condition: "{{operation_type}} == 'seed'"
    type: "task"
    task: "db-seed"
    inputs:
      path: "{{seed_path}}"

  # Analysis Path
  - id: "analysis_type"
    condition: "{{operation_type}} == 'analyze'"
    type: "elicit"
    elicit:
      question: "Analysis type:"
      options:
        - label: "Table statistics"
          value: "stats"
        - label: "Data distribution"
          value: "distribution"
        - label: "Integrity checks"
          value: "integrity"
        - label: "Recent activity"
          value: "recent"
      output_var: "analysis_type"

  # Table Statistics Analysis
  - id: "run_stats"
    condition: "{{operation_type}} == 'analyze' AND {{analysis_type}} == 'stats'"
    type: "execute"
    description: "Analyze table sizes and row counts"
    command: |
      echo "=== TABLE STATISTICS ==="
      echo ""
      psql "$SUPABASE_DB_URL" -c "
        SELECT
          schemaname,
          tablename,
          pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,
          pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) AS table_size,
          pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename) -
                         pg_relation_size(schemaname||'.'||tablename)) AS index_size,
          n_live_tup AS live_rows,
          n_dead_tup AS dead_rows
        FROM pg_stat_user_tables
        WHERE schemaname = 'public'
        ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
        LIMIT 20;"
      echo ""
      echo "✅ Statistics complete"

  # Distribution Analysis - Elicit Parameters
  - id: "distribution_params"
    condition: "{{operation_type}} == 'analyze' AND {{analysis_type}} == 'distribution'"
    type: "elicit"
    elicit:
      fields:
        - name: "dist_table"
          label: "Table name"
          type: "string"
          required: true
        - name: "dist_column"
          label: "Column to analyze"
          type: "string"
          required: true
      output_vars: ["dist_table", "dist_column"]

  # Distribution Analysis - Run Query
  - id: "run_distribution"
    condition: "{{operation_type}} == 'analyze' AND {{analysis_type}} == 'distribution'"
    type: "execute"
    description: "Analyze data distribution for column"
    command: |
      echo "=== DATA DISTRIBUTION: {{dist_table}}.{{dist_column}} ==="
      echo ""

      # Value distribution
      psql "$SUPABASE_DB_URL" -c "
        SELECT
          {{dist_column}} AS value,
          COUNT(*) AS count,
          ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER (), 2) AS percentage
        FROM {{dist_table}}
        WHERE {{dist_column}} IS NOT NULL
        GROUP BY {{dist_column}}
        ORDER BY count DESC
        LIMIT 20;"

      echo ""
      echo "--- NULL Analysis ---"
      psql "$SUPABASE_DB_URL" -c "
        SELECT
          COUNT(*) FILTER (WHERE {{dist_column}} IS NULL) AS null_count,
          COUNT(*) FILTER (WHERE {{dist_column}} IS NOT NULL) AS non_null_count,
          ROUND(100.0 * COUNT(*) FILTER (WHERE {{dist_column}} IS NULL) / COUNT(*), 2) AS null_percentage
        FROM {{dist_table}};"

      echo ""
      echo "✅ Distribution analysis complete"

  # Integrity Checks Analysis
  - id: "run_integrity"
    condition: "{{operation_type}} == 'analyze' AND {{analysis_type}} == 'integrity'"
    type: "execute"
    description: "Check for orphaned records and referential integrity"
    command: |
      echo "=== INTEGRITY CHECKS ==="
      echo ""

      echo "--- Foreign Key Violations ---"
      psql "$SUPABASE_DB_URL" -c "
        SELECT
          tc.table_name,
          kcu.column_name,
          ccu.table_name AS foreign_table_name,
          ccu.column_name AS foreign_column_name
        FROM information_schema.table_constraints AS tc
        JOIN information_schema.key_column_usage AS kcu
          ON tc.constraint_name = kcu.constraint_name
          AND tc.table_schema = kcu.table_schema
        JOIN information_schema.constraint_column_usage AS ccu
          ON ccu.constraint_name = tc.constraint_name
          AND ccu.table_schema = tc.table_schema
        WHERE tc.constraint_type = 'FOREIGN KEY'
          AND tc.table_schema = 'public'
        ORDER BY tc.table_name, kcu.column_name;"

      echo ""
      echo "--- Tables Without Primary Keys ---"
      psql "$SUPABASE_DB_URL" -c "
        SELECT
          t.table_name
        FROM information_schema.tables t
        LEFT JOIN information_schema.table_constraints tc
          ON t.table_name = tc.table_name
          AND tc.constraint_type = 'PRIMARY KEY'
        WHERE t.table_schema = 'public'
          AND t.table_type = 'BASE TABLE'
          AND tc.constraint_name IS NULL
        ORDER BY t.table_name;"

      echo ""
      echo "--- Duplicate Check (tables with potential duplicates) ---"
      psql "$SUPABASE_DB_URL" -c "
        SELECT
          schemaname,
          tablename,
          n_live_tup AS total_rows,
          n_dead_tup AS dead_rows,
          CASE
            WHEN n_live_tup > 0 THEN ROUND(100.0 * n_dead_tup / n_live_tup, 2)
            ELSE 0
          END AS dead_row_percentage
        FROM pg_stat_user_tables
        WHERE schemaname = 'public'
          AND n_dead_tup > 0
        ORDER BY n_dead_tup DESC
        LIMIT 10;"

      echo ""
      echo "✅ Integrity checks complete"

  # Recent Activity Analysis - Elicit Parameters
  - id: "recent_params"
    condition: "{{operation_type}} == 'analyze' AND {{analysis_type}} == 'recent'"
    type: "elicit"
    elicit:
      fields:
        - name: "recent_table"
          label: "Table name"
          type: "string"
          required: true
        - name: "recent_limit"
          label: "Number of records to show"
          type: "number"
          default: 10
        - name: "time_column"
          label: "Timestamp column (e.g., created_at)"
          type: "string"
          default: "created_at"
      output_vars: ["recent_table", "recent_limit", "time_column"]

  # Recent Activity Analysis - Run Query
  - id: "run_recent"
    condition: "{{operation_type}} == 'analyze' AND {{analysis_type}} == 'recent'"
    type: "execute"
    description: "Show recent activity in table"
    command: |
      echo "=== RECENT ACTIVITY: {{recent_table}} ==="
      echo ""

      # Check if column exists
      COLUMN_EXISTS=$(psql "$SUPABASE_DB_URL" -t -c "
        SELECT COUNT(*)
        FROM information_schema.columns
        WHERE table_name = '{{recent_table}}'
          AND column_name = '{{time_column}}'
          AND table_schema = 'public';")

      if [ "$COLUMN_EXISTS" -eq 0 ]; then
        echo "❌ Error: Column '{{time_column}}' not found in table '{{recent_table}}'"
        echo ""
        echo "Available timestamp columns:"
        psql "$SUPABASE_DB_URL" -c "
          SELECT column_name, data_type
          FROM information_schema.columns
          WHERE table_name = '{{recent_table}}'
            AND table_schema = 'public'
            AND data_type IN ('timestamp', 'timestamp with time zone', 'timestamp without time zone')
          ORDER BY ordinal_position;"
        exit 1
      fi

      echo "--- Most Recent Records ---"
      psql "$SUPABASE_DB_URL" -c "
        SELECT *
        FROM {{recent_table}}
        ORDER BY {{time_column}} DESC
        LIMIT {{recent_limit}};"

      echo ""
      echo "--- Activity by Time Period ---"
      psql "$SUPABASE_DB_URL" -c "
        SELECT
          DATE_TRUNC('day', {{time_column}}) AS day,
          COUNT(*) AS records
        FROM {{recent_table}}
        WHERE {{time_column}} > NOW() - INTERVAL '30 days'
        GROUP BY day
        ORDER BY day DESC
        LIMIT 30;"

      echo ""
      echo "✅ Recent activity analysis complete"

outputs:
  operation_complete:
    type: "boolean"
    description: "Operation completed successfully"
    value: true

global_error_handling:
  on_error: "abort"
