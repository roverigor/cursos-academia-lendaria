# Query Database Workflow
# Run SQL queries with safety guardrails and performance insights (Story 1.2)

workflow:
  id: "query-database"
  name: "Query Database with Safety and Performance"
  description: "Execute SQL queries with transaction safety, dangerous operation detection, and performance analysis"
  version: "1.0.0"
  type: "sequential"

metadata:
  author: "DB Sage"
  created_date: "2025-10-27"
  last_modified: "2025-10-27"
  tags:
    - database
    - query
    - sql
    - performance
    - db-sage
  story: "expansion-packs/super-agentes/docs/stories/1.2.query-database-workflow.md"

# Workflow inputs
inputs:
  query_source:
    type: "string"
    description: "Query source: inline, file, or template"
    required: false

  sql_query:
    type: "string"
    description: "SQL query or file path"
    required: false

steps:
  # ========== STEP 1: Query Input Method ==========
  - id: "step_1_query_input"
    name: "Select Query Input Method"
    type: "elicit"
    elicit:
      question: "How do you want to provide the SQL query?"
      options:
        - label: "Inline SQL (type or paste)"
          value: "inline"
          description: "Enter SQL directly"
        - label: "SQL File (path)"
          value: "file"
          description: "Execute SQL from file"
        - label: "Quick Template"
          value: "template"
          description: "Common query patterns"
      default: "inline"
      output_var: "query_source"
    error_handling:
      strategy: "fail"

  # ========== STEP 2A: Inline SQL Input ==========
  - id: "step_2a_inline_sql"
    name: "Enter Inline SQL"
    type: "elicit"
    condition: "{{query_source}} == 'inline'"
    elicit:
      fields:
        - name: "sql"
          label: "SQL Query (can be multi-line)"
          type: "text"
          multiline: true
          required: true
          placeholder: "SELECT * FROM users WHERE created_at > NOW() - INTERVAL '7 days';"
      output_vars:
        - "sql"
    outputs:
      sql_content: "{{sql}}"
    error_handling:
      strategy: "fail"

  # ========== STEP 2B: File Path Input ==========
  - id: "step_2b_file_input"
    name: "Enter SQL File Path"
    type: "elicit"
    condition: "{{query_source}} == 'file'"
    elicit:
      fields:
        - name: "file_path"
          label: "SQL File Path"
          type: "string"
          required: true
          placeholder: "queries/my_query.sql"
          validation: "Must be a valid file path"
      output_vars:
        - "file_path"
    outputs:
      sql_file: "{{file_path}}"
    error_handling:
      strategy: "fail"
      message: "File not found or not readable"

  # ========== STEP 2C: Template Selection ==========
  - id: "step_2c_template_select"
    name: "Select Query Template"
    type: "elicit"
    condition: "{{query_source}} == 'template'"
    elicit:
      question: "Select a query template:"
      options:
        - label: "Count Rows in Table"
          value: "count"
          description: "SELECT COUNT(*) FROM table_name"
        - label: "Recent Records"
          value: "recent"
          description: "SELECT * FROM table ORDER BY created_at DESC LIMIT N"
        - label: "Aggregation (GROUP BY)"
          value: "aggregation"
          description: "GROUP BY with COUNT/SUM/AVG"
        - label: "Join with Filter"
          value: "join"
          description: "JOIN tables with WHERE clause"
      output_var: "template_type"
    error_handling:
      strategy: "fail"

  # ========== STEP 2D: Fill Template Parameters ==========
  - id: "step_2d_template_params"
    name: "Fill Template Parameters"
    type: "elicit"
    condition: "{{query_source}} == 'template'"
    elicit:
      fields:
        - name: "table_name"
          label: "Table Name"
          type: "string"
          required: true

        - name: "limit"
          label: "Limit (for recent/aggregation)"
          type: "number"
          default: 10
          condition: "{{template_type}} in ['recent', 'aggregation']"

        - name: "group_column"
          label: "Group By Column"
          type: "string"
          condition: "{{template_type}} == 'aggregation'"

        - name: "join_table"
          label: "Table to Join"
          type: "string"
          condition: "{{template_type}} == 'join'"

        - name: "filter_column"
          label: "Filter Column (WHERE)"
          type: "string"
          required: false

        - name: "filter_value"
          label: "Filter Value"
          type: "string"
          required: false

      output_vars:
        - "table_name"
        - "limit"
        - "group_column"
        - "join_table"
        - "filter_column"
        - "filter_value"

  # ========== STEP 2E: Generate SQL from Template ==========
  - id: "step_2e_generate_sql"
    name: "Generate SQL from Template"
    type: "execute"
    condition: "{{query_source}} == 'template'"
    command: |
      case "{{template_type}}" in
        count)
          SQL="SELECT COUNT(*) as total_rows FROM {{table_name}};"
          ;;
        recent)
          SQL="SELECT * FROM {{table_name}} ORDER BY created_at DESC LIMIT {{limit}};"
          ;;
        aggregation)
          SQL="SELECT {{group_column}}, COUNT(*) as count, AVG(id) as avg_id FROM {{table_name}} GROUP BY {{group_column}} ORDER BY count DESC LIMIT {{limit}};"
          ;;
        join)
          SQL="SELECT a.*, b.* FROM {{table_name}} a JOIN {{join_table}} b ON a.id = b.{{table_name}}_id LIMIT {{limit}};"
          ;;
      esac

      echo "$SQL"
    outputs:
      sql_content: "{{output}}"

  # ========== STEP 3: Transaction Mode Selection ==========
  - id: "step_3_transaction_mode"
    name: "Select Transaction Mode"
    type: "elicit"
    elicit:
      question: "Select transaction mode:"
      help_text: |
        Transaction modes:
        - Auto: Wraps in BEGIN/COMMIT (safe, auto-rollback on error)
        - Manual: File has own transaction control
        - Read-only: Cannot modify data (safest for queries)

      options:
        - label: "Auto (Recommended - wraps in BEGIN/COMMIT)"
          value: "auto"
          description: "Automatic rollback on error"
        - label: "Manual (File has own transactions)"
          value: "manual"
          description: "Use when script controls transactions"
        - label: "Read-only (Cannot modify data)"
          value: "readonly"
          description: "Safest for SELECT queries"
      default: "readonly"
      output_var: "transaction_mode"
    error_handling:
      strategy: "fail"

  # ========== STEP 4: Safety Check for Dangerous Operations ==========
  - id: "step_4_safety_check"
    name: "Check for Dangerous Operations"
    type: "execute"
    description: "Detect potentially destructive SQL patterns"
    command: |
      SQL_TO_CHECK="${{sql_content}}{{sql_file}}"

      # Read file if using file mode
      if [ -f "{{sql_file}}" ]; then
        SQL_TO_CHECK=$(cat "{{sql_file}}")
      fi

      # Dangerous patterns
      DANGEROUS="DROP TABLE|TRUNCATE|DELETE.*WHERE.*1.*=.*1|UPDATE.*WHERE.*1.*=.*1|DROP DATABASE|ALTER TABLE.*DROP"

      if echo "$SQL_TO_CHECK" | grep -Eiq "$DANGEROUS"; then
        echo "⚠️  WARNING: Potentially DESTRUCTIVE operation detected!"
        echo ""
        echo "Detected dangerous patterns in SQL:"
        echo "$SQL_TO_CHECK" | grep -Ei "$DANGEROUS" | head -5
        echo ""
        echo "dangerous_operation_detected=true"
        exit 0
      else
        echo "✅ No dangerous operations detected"
        echo "dangerous_operation_detected=false"
        exit 0
      fi
    outputs:
      dangerous_detected: "{{output}}"
    error_handling:
      strategy: "warn"

  # ========== STEP 5: Confirm Dangerous Operation ==========
  - id: "step_5_confirm_dangerous"
    name: "Confirm Destructive Operation"
    type: "elicit"
    condition: "{{dangerous_detected}} contains 'true'"
    elicit:
      question: |
        ⚠️  DESTRUCTIVE OPERATION DETECTED ⚠️

        This SQL may DELETE, DROP, or TRUNCATE data.

        Are you absolutely sure you want to proceed?

      options:
        - label: "YES - I UNDERSTAND THE RISKS"
          value: "confirmed"
          description: "Proceed with destructive operation"
        - label: "NO - Cancel Operation"
          value: "cancel"
          description: "Abort and review SQL"
      default: "cancel"
      output_var: "dangerous_confirmed"
    error_handling:
      strategy: "fail"
      message: "Operation cancelled for safety"

  # ========== STEP 6: Abort if Not Confirmed ==========
  - id: "step_6_check_confirmation"
    name: "Verify Dangerous Operation Confirmation"
    type: "execute"
    condition: "{{dangerous_confirmed}} == 'cancel'"
    command: |
      echo "❌ Operation cancelled by user"
      echo ""
      echo "Review your SQL and try again if needed."
      exit 1
    error_handling:
      strategy: "abort"

  # ========== STEP 7: Execute SQL Query ==========
  - id: "step_7_execute_sql"
    name: "Execute SQL Query"
    type: "task"
    task: "db-run-sql"
    description: "Execute SQL with timing and error handling"

    inputs:
      sql: "{% if query_source == 'file' %}{{sql_file}}{% else %}{{sql_content}}{% endif %}"
      transaction_mode: "{{transaction_mode}}"

    environment:
      TRANSACTION_MODE: "{{transaction_mode}}"

    error_handling:
      strategy: "fail"
      message: |
        ❌ SQL execution failed

        Check:
        1. SQL syntax is correct
        2. Tables/columns exist
        3. User has required permissions
        4. Database connection is active

        Output saved to: /tmp/dbsage_sql_output.txt

    outputs:
      execution_success: true
      execution_time: "{{execution_time}}"
      rows_affected: "{{rows_affected}}"

  # ========== STEP 8: Performance Analysis Option ==========
  - id: "step_8_performance_option"
    name: "Offer Performance Analysis"
    type: "elicit"
    condition: "{{execution_time}} > 100"
    elicit:
      question: |
        Query took {{execution_time}}ms

        Run EXPLAIN ANALYZE for performance insights?

      help_text: "Shows execution plan, buffer usage, and identifies performance bottlenecks"

      options:
        - label: "Yes - Run EXPLAIN ANALYZE"
          value: "yes"
          description: "Analyze query performance"
        - label: "No - Skip analysis"
          value: "no"
          description: "Continue without analysis"
      default: "no"
      output_var: "run_explain"
    error_handling:
      strategy: "warn"

  # ========== STEP 9: Run EXPLAIN ANALYZE ==========
  - id: "step_9_explain_analyze"
    name: "Run EXPLAIN ANALYZE"
    type: "task"
    task: "db-explain"
    condition: "{{run_explain}} == 'yes'"
    description: "Analyze query execution plan and performance"

    inputs:
      sql: "{{sql_content}}"

    error_handling:
      strategy: "warn"
      message: "EXPLAIN ANALYZE failed, but query executed successfully"

    outputs:
      explain_plan: "{{output}}"

  # ========== STEP 10: Optimization Suggestion ==========
  - id: "step_10_optimization_suggest"
    name: "Suggest Query Optimization"
    type: "execute"
    condition: "{{execution_time}} > 1000"
    description: "Suggest optimization for slow queries (>1s)"
    command: |
      echo ""
      echo "⚠️  SLOW QUERY DETECTED (>1000ms)"
      echo ""
      echo "Query took {{execution_time}}ms"
      echo ""
      echo "Recommendations:"
      echo "  1. Run *explain \"<your query>\" to see execution plan"
      echo "  2. Run *optimize-queries for interactive optimization"
      echo "  3. Check for missing indexes on WHERE/JOIN columns"
      echo "  4. Consider EXPLAIN (ANALYZE, BUFFERS) for buffer analysis"
      echo ""
      echo "Common issues:"
      echo "  - Sequential scans on large tables → Add indexes"
      echo "  - Row estimate mismatches → Run ANALYZE table_name"
      echo "  - High buffer reads → Add indexes or optimize query"
      echo ""
    error_handling:
      strategy: "warn"

  # ========== STEP 11: Success Summary ==========
  - id: "step_11_success_summary"
    name: "Display Success Summary"
    type: "execute"
    description: "Show execution summary and next steps"
    command: |
      echo ""
      echo "════════════════════════════════════════"
      echo "✅ QUERY EXECUTED SUCCESSFULLY"
      echo "════════════════════════════════════════"
      echo ""
      echo "Query Details:"
      echo "  Source: {{query_source}}"
      echo "  Transaction Mode: {{transaction_mode}}"

      {% if rows_affected %}
      echo "  Rows Affected: {{rows_affected}}"
      {% endif %}

      {% if execution_time %}
      echo "  Execution Time: {{execution_time}}ms"
      {% endif %}

      echo ""
      echo "Output: /tmp/dbsage_sql_output.txt"
      echo ""

      {% if execution_time > 1000 %}
      echo "Performance Note:"
      echo "  ⚠️ Query is slow (>1s) - consider optimization"
      echo ""
      {% endif %}

      echo "Next Steps:"
      echo "  *explain \"<query>\"    - Analyze query performance"
      echo "  *optimize-queries      - Interactive optimization session"
      echo "  *query                 - Run another query"
      echo ""

# Workflow outputs
outputs:
  query_executed:
    type: "boolean"
    description: "Query executed successfully"
    source: "step_7_execute_sql.execution_success"

  execution_time:
    type: "number"
    description: "Query execution time in milliseconds"
    source: "step_7_execute_sql.execution_time"

  rows_affected:
    type: "number"
    description: "Number of rows affected by query"
    source: "step_7_execute_sql.rows_affected"

  output_file:
    type: "string"
    description: "Path to query output file"
    value: "/tmp/dbsage_sql_output.txt"

  performance_analyzed:
    type: "boolean"
    description: "Whether EXPLAIN ANALYZE was run"
    source: "step_9_explain_analyze.completed"

# Global error handling
global_error_handling:
  on_error: "abort"
  notification:
    enabled: true
    channels:
      - console
  rollback_on_error: true

# Security settings
security:
  authorization_required: false
  audit_logging: true
  dangerous_operation_confirmation: true
  redact_secrets: true
